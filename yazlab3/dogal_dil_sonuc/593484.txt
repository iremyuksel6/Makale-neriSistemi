parallel formul decisiontre classif algorithm classif decis tree algorithm use extens data mine mani domain retail target market fraud detect etc highli parallel algorithm construct classif decis tree desir deal larg data set reason amount time algorithm build classif decis tree natur concurr difficult parallel due inher dynam natur comput paper present parallel formul classif decis tree learn algorithm base induct describ two basic parallel formul one base synchron tree construct approach base partit tree construct approach discuss advantag disadvantag use method propos hybrid method employ good featur method also provid analysi cost comput commun propos hybrid method moreov experiment result ibm sp2 demonstr excel speedup scalabl b introduct classif import data mine problem classif problem input dataset call train set consist number exampl number attribut attribut either continu attribut valu order categor attribut valu un order one categor attribut call class label classifi attribut object use train dataset build model class label base attribut model use classifi new data train dataset applic domain includ retail target market fraud detect design telecommun servic plan sever classif model like neural network 17 genet algorithm 11 decis tree 20 propos decis tree probabl popular sinc obtain reason accuraci 9 rel inexpens comput current classif algorithm c45 20 sliq 18 base id3 classif decis tree algorithm 20 data mine domain data process tend larg henc highli desir design comput effici well scalabl algorithm one way reduc comput complex build decis tree classifi use larg train dataset use small sampl train data method yield classif accuraci decis tree classifi use entir data set 24 5 6 7 order get reason accuraci reason amount time parallel algorithm may requir classif decis tree construct algorithm natur concurr node gener children classif tree gener concurr furthermor comput gener successor classif tree node also decompos perform data decomposit train data nevertheless parallel algorithm construct classif tree challeng follow reason first shape tree highli irregular determin runtim furthermor amount work associ node also vari data depend henc static alloc scheme like suffer major load imbal second even though successor node process concurr use train data associ parent node data dynam partit alloc differ processor perform comput differ node high cost data movement data partit appropri perform bad due loss local paper present parallel formul classif decis tree learn algorithm base induct describ two basic parallel formul one base synchron tree construct approach base partit tree construct approach discuss advantag disadvantag use method propos hybrid method employ good featur method also provid analysi cost comput commun propos hybrid method moreov experiment result ibm sp2 demonstr excel speedup scalabl 2 relat work 21 sequenti decisiontre classif algorithm exist inductionbas algorithm like c45 20 cdp 1 sliq 18 sprint 21 use hunt method 20 basic algorithm recurs descript hunt method construct decis tree set train case class denot fc 1 g case 1 contain case belong singl class c j decis tree leaf identifi class c j case 2 contain case belong mixtur class test chosen base singl attribut one mutual exclus outcom g note mani implement n chosen 2 lead binari decis tree partit subset contain case outcom chosen test decis tree consist decis node identifi test one outlook tempf humid windi class sunni sunni sunni 85 85 fals dont play sunni 72 95 fals dont play sunni 69 70 fals play overcast 72 90 true play overcast 83 78 fals play overcast overcast 81 75 fals play rain 71 80 true dont play rain rain rain 68 80 fals play rain 70 96 fals play tabl 1 small train data set qui93 play dont play play play play dont play dont play play sunni overcast rain outlook sunni overcast rain play outlook humid nonleaf node expand leaf node nonexpand leaf node initi classif tree b intermedi classif tree c final classif tree figur 1 demonstr hunt method branch possibl outcom tree build machineri appli recurs subset train case case 3 contain case decis tree leaf class associ leaf must determin inform exampl c45 choos frequent class parent node attribut valu class play dont play overcast 4 0 tabl 2 class distribut inform attribut outlook attribut valu binari test class play dont play tabl 3 class distribut inform attribut humid tabl 1 show train data set four data attribut two class figur 1 show hunt method work train data set case 2 hunt method test base singl attribut chosen expand current node choic attribut normal base entropi gain attribut entropi attribut calcul class distribut inform discret attribut class distribut inform valu attribut requir tabl 2 show class distribut inform data attribut outlook root decis tree shown figur 1 continu attribut binari test involv distinct valu attribut consid tabl 3 show class distribut inform data attribut humid class distribut inform attribut gath ere attribut evalu term either entropi 20 gini index 4 best attribut select test node expans c45 algorithm gener classificationdecis tree given train data set recurs partit data decis tree grown use depthfirst strategi algorithm consid possibl test split data set select test give best inform gain discret attribut one test outcom mani number distinct valu attribut consid continu attribut binari test involv everi distinct valu attribut consid order gather entropi gain binari test effici train data set belong node consider sort valu continu attribut entropi gain binari cut base distinct valu calcul one scan sort data process repeat continu attribut recent propos classif algorithm sliq 18 sprint 21 avoid costli sort node presort continu attribut begin ning sprint continu attribut maintain sort attribut list list entri contain valu attribut correspond record id best attribut split node classif tree determin attribut list split accord split decis hash tabl order number train case map record id record belong accord split decis entri attribut list move classif tree node accord inform retriev probe hash tabl sort order maintain entri move presort order decis tree usual built two step first initi tree built till leaf node belong singl class second prune done remov overfit train data typic time spent prune larg dataset small fraction less 1 initi tree gener therefor paper focu initi tree gener prune part comput 22 parallel decisiontre classif algorithm sever parallel formul classif rule learn propos centli pearson present approach combin nodebas decomposit attributebas decomposit 19 shown nodebas decomposit task parallel alon sever probelm one problem processor util begin due small number expand tree node anoth problem mani processor becom idl later stage due load imbal attributebas decomposit use remedi first problem number expand node smaller avail number processor multipl processor assign node attribut distribut among processor approach relat natur partit tree construct approach discuss paper partit tree construct approach actual data sampl partit horizont parti tion wherea approach attribut partit vertic partit 8 gener approach parallel c45 discuss dynam task distribut dtd scheme master processor alloc subtre decis tree idl slave processor scheme requir commun among processor suffer load imbal dtd becom similar partit tree construct approach discuss paper number avail node decis tree exce number processor dprec scheme distribut data set evenli build decis tree one node time scheme ident synchron tree construct approach discuss paper suffer high commun overhead dpatt scheme distribut attribut scheme advantag loadbalanc requir minim commun howev scheme scale well increas number processor result 8 show effect differ parallel scheme vari significantli data set use kufrin propos approach call parallel decis tree pdt 15 approach similar dprec scheme 8 synchron tree construct approach discuss paper data set partit among proce sor pdt approach design one processor host processor remain processor worker processor host processor data set receiv frequenc statist gain calcul worker processor host processor determin split base collect statist notifi split decis worker processor worker processor collect statist local data follow instruct host processor pdt approach suffer high commun overhead like dprec scheme synchron tree construct approach pdt approach addit commun bottleneck everi worker processor send collect statist host processor roughli time host processor send split decis work processor time parallel implement sprint 21 scalparc 13 use method partit work ident one use synchron tree construct approach discuss paper serial sprint 21 sort continu attribut begin keep separ attribut list record identifi split phase decis tree node maintain sort order without requir sort record order split attribut list accord split decis sprint creat hash tabl record map record identifi node goe base split decis parallel implement sprint attribut list split evenli among processor split point node decis tree found parallel howev order split attribut list full size hash tabl requir processor order construct hash tabl alltoal broadcast 16 perform make algorithm unscal respect runtim memori requir reason processor requir memori store hash tabl commun overhead alltoal broadcast n number record data set recent propos scalparc 13 improv upon sprint employ distribut 7hash tabl effici implement split phase sprint scalparc hash tabl split among processor effici person commun use updat hash tabl make scalabl respect memori runtim requir goil aluru ranka propos concaten parallel strategi effici parallel solut divid conquer problem 10 strategi mix data parallel task parallel use solut parallel divid conquer algorithm data parallel use enough subtask geneart task parallel use ie processor work independ subtask strategi similar principl partit tree construct approach discuss paper concaten parallel strategi use problem workload determin base size subtask task parallel employ howev problem classificatoin decis tree workload determin base size data particular node tree henc one time load balanc use strategi well suit particular divid conquer problem 3 parallel formul section give two basic parallel formul classif decis tree construct hybrid scheme combin good featur approach focu present discret attribut handl continu attribut discuss section 34 parallel formul assum n train case randomli distribut p processor initi processor np case 31 synchron tree construct approach approach processor construct decis tree synchron send receiv class distribut inform local data major step approach shown 1 select node expand accord decis tree expans strategi eg depthfirst breadthfirst call node current node begin root node select current node 2 data attribut collect class distribut inform local data current node 3 exchang local class distribut inform use global reduct 16 among processor 4 simultan comput entropi gain attribut processor select best attribut child node expans 5 depend branch factor tree desir creat child node number partit attribut valu split train case accordingli class distribut inform class distribut inform figur 2 synchron tree construct approach depthfirst expans strategi 6 repeat step 15 node avail expans figur 2 show overal pictur root node alreadi expand current node leftmost child root shown top part figur four processor cooper expand node two child node next leftmost node child node select current node bottom figur four processor cooper expand node advantag approach requir movement train data item howev algorithm suffer high commun cost load imbal node decis tree collect class distribut inform processor need synchron exchang distribut inform node shallow depth commun overhead rel small number train data item process rel larg decis tree grow deepen number train set item node decreas consequ comput class distribut inform node decreas averag branch factor decis tree k number data item child node averag 1 th number data item parent howev size commun decreas much number attribut consid goe one henc tree deepen commun overhead domin overal process time problem due load imbal even though processor start number train data item number item belong node decis tree vari substanti among processor exampl processor 1 might data item leaf node none leaf node b processor 2 might data item node b none node node select current node processor 2 work similarli node b select current node processor 1 work load imbal reduc node frontier expand simultan ie one pass data processor use comput class distribut inform node frontier note improv also reduc number time commun done reduc messag startup overhead reduc overal volum commun rest paper assum synchron tree construct algorithm classif tree expand breadthfirst manner node level process time 32 partit tree construct approach approach whenev feasibl differ processor work differ part classif tree particular one processor cooper expand node processor partit expand successor node consid case group processor pn cooper expand node n algorithm consist follow step processor pn cooper expand node n use method describ section 31 node n expand successor node processor group pn also partit successor node assign processor follow case 1 number successor node greater jp n j 1 partit successor node jp n j group total number train case correspond node group roughli equal assign processor one node group 2 shuffl train data processor data item belong node respons 3 expans subtre root node group proce complet independ processor serial algorithm case 2 otherwis number successor node less jp n j 1 assign subset processor node number processor assign node proport number train case correspond node data item data item figur 3 partit tree construct approach 2 shuffl train case subset processor train case belong node respons 3 processor subset assign differ node develop subtre ind pendent processor subset contain one processor use sequenti algorithm expand part classif tree root node assign processor subset contain one processor proceed follow step recurs begin processor work togeth expand root node classif tree end whole classif tree construct combin subtre processor figur 3 show exampl first top figur four processor cooper expand root node like synchron tree construct 1approach next middl figur set four processor partit three part leftmost child assign processor 0 1 node assign processor 2 3 respect set processor proceed independ expand assign node par ticular processor 2 processor 3 proceed expand part tree use serial algorithm group contain processor 0 1 split leftmost child node three node three new node partit two part shown bottom figur leftmost node assign processor 0 two assign processor 1 processor 0 1 also independ work respect subtre advantag approach processor becom sole respons node develop subtre classif tree independ without commun overhead howev number disadvantag approach first disadvantag requir data movement node expans one processor becom respons entir subtre commun cost particularli expens expans upper part classif tree note number node frontier exce number processor commun cost becom zero second disadvantag poor load balanc inher algorithm assign node processor done base number train case successor node howev number train case associ node necessarili correspond amount work need process subtre root node exampl train case associ node happen class label expans need 33 hybrid parallel formul hybrid parallel formul element scheme synchron tree construct approach section 31 incur high commun overhead frontier get larger partit tree construct approach section 32 incur cost load balanc step hybrid scheme keep continu first approach long commun cost incur first formul high cost becom high processor well current frontier classif tree partit two part descript assum number processor power 2 processor connect hypercub configur algorithm appropri modifi p power 2 also algorithm map parallel architectur simpli embed virtual hypercub architectur precis hybrid formul work follow ffl databas train case split equal among p processor thu n total number train case processor np train case local begin processor assign one partit root node classif tree alloc partit ffl node frontier tree belong one partit process togeth use synchron tree construct approach section 31 ffl depth tree within partit increas volum statist gather level also increas discuss section 31 point level reach commun cost becom prohibit point processor partit divid two partit current set frontier node split alloc partit way number train case partit roughli equal load balanc done describ follow hypercub two partit natur correspond sub cube first correspond processor within two subcub exchang relev train case transfer subcub exchang processor within subcub collect train case partit number train case processor vari 0 2lambdan load balanc step done within subcub processor equal number data item ffl process within partit proce asynchron step repeat one partit particular subtre process repeat complet classif tree grown ffl group processor partit becom idl partit join partit work number processor done simpli give half train case locat processor donor partit processor receiv partit comput frontier depth 3 figur 4 comput frontier comput phase key element algorithm criterion trigger partit current set processor correspond frontier classif tree partit done frequent hybrid scheme approxim partit tree construct approach thu incur much data movement cost partit done late suffer high cost commun statist gener node frontier like synchron tree construct approach one possibl split accumul cost commun becom equal cost move record around split phase precis split done partit 1 partit 2 figur 5 binari partit tree reduc commun cost commun movingcost loadbalanc exampl hybrid algorithm figur 4 show classif tree frontier depth 3 far partit done processor work cooper node frontier next frontier depth 4 partit trigger node processor partit two partit shown figur 5 detail analysi hybrid algorithm present section 4 34 handl continu attribut note handl continu attribut requir sort processor contain np train case one approach handl continu attribut perform parallel sort step attribut node decis tree construct parallel sort complet processor comput best local valu split simpl global commun among processor determin global best split valu howev step parallel sort would requir substanti data exchang among processor exchang inform similar natur exchang class distribut inform except much higher volum henc even case use use scheme similar hybrid approach discuss section 33 effici way handl continu attribut without incur high cost repeat sort use presort techniqu use algorithm sliq 18 sprint 21 scalparc 13 algorithm requir one presort step need construct hash tabl level classif tree parallel formul algorithm content hash tabl need avail global requir commun among processor definit total number train sampl total number processor number processor cooper work tree expans number categor attribut c number class averag number distinct valu discret attribut present level decis tree start time commun latenc kggk94 w perword transfer time commun latenc kggk94 tabl 4 symbol use analysi exist parallel formul scheme 21 13 perform commun similar natur synchron tree construct approach discuss section 31 commun formul 21 13 reduc use hybrid scheme section 33 anoth complet differ way handl continu attribut discret preprocess step 12 case parallel formul present previou subsect directli applic without modif anoth approach toward discret discret everi node tree two exampl approach first exampl found 3 quantil 2 use discret continu attribut second exampl approach discret node spec 23 cluster techniqu use spec shown effici term runtim also shown perform essenti ident sever wide use tree classifi term classif accuraci 23 parallel discret everi node tree similar natur parallel comput entropi gain discret attribut method discret requir global commun among processor respons node particular parallel formul cluster step spec essenti ident parallel formul discret case discuss previou subsect 23 4 analysi hybrid algorithm section provid analysi hybrid algorithm propos section 33 give detail analysi case discret attribut present analysi case continu attribut found 23 detail studi commun pattern use analysi found 16 tabl 4 describ symbol use section 41 assumpt ffl processor connect hypercub topolog complex measur topolog easili deriv use commun complex express topolog given 16 ffl express commun comput written full binari tree 2 l leav depth l express suitabl modifi tree full binari tree without affect scalabl algorithm ffl size classif tree asymptot independ n particular data set assum tree repres knowledg extract particular train data set increas train set size beyond point lead larger decis tree 42 comput commun cost leaf level class histogram tabl need com munic size tabl product number class mean number attribut valu thu size class histogram tabl processor leaf class histogram size number leav level l 2 l thu total size tabl combin class histogram tabl processor c 2 l level l local comput cost involv io scan train set initi updat class histogram tabl attribut local comput cost n c unit comput cost end local comput processor synchron involv global reduct class histogram valu commun cost 1 per level commun cost 2 processor partit split two leaf assign one partit way number train data item two partit approxim order two partit work independ train set move around train case leaf assign processor partit load balanc system processor partit must n train data item movement done two step first processor first partit send relev train data item correspond processor second partit refer move phase processor send receiv maximum n data correspond processor partit cost move phase 2 intern load balanc phase insid partit take place everi processor equal number train data item move phase load balanc phase start processor train data item count vari 0 2lambdan processor send receiv maximum n train data item assum congest interconnect network cost load balanc cost load balanc phase 2 detail deriv equat 4 given 23 also cost load balanc assum network congest reason assumpt network bandwidthrich case commerci system without assum anyth network congest load balanc phase done use transport primit 22 time 2 n split done accumul cost commun becom equal cost move record around split phase 14 split done commun cost move cost balanc criterion split ensur commun cost scheme within twice commun cost optim scheme 14 split recurs appli mani time requir split done comput appli partit partit processor start idl send request busi partit idl state request sent partit processor roughli size idl partit next round split idl partit includ part busi partit comput proce describ 43 scalabl analysi isoeffici metric found use metric scalabl larg number problem larg class commerci parallel comput 16 defin follow let p number processor w problem size total time taken best sequenti algorithm w need grow maintain effici e fe p defin isoeffici function effici e plot fe p respect p defin isoeffici curv effici e assum data classifi tree depth l 1 depth remain constant irrespect size data sinc data fit particular classif tree total cost creat new processor subpartit product total number partit split cost partit split n use equat 3 4 number partit split processor particip less equal l 1 depth tree cost creat new processor partit l 1 commun cost level given equat 2 log p combin commun cost product number level commun cost level combin commun cost process attribut l 1 log p total commun cost sum cost creat new processor partit commun cost process class histogram tabl sum equat 5 6 total commun cost comput cost given equat 1 total comput total parallel run time sum equat 7 8 commun time comput time parallel run serial case whole dataset scan level serial time get isoeffici function equat p time total parallel run time use equat 9 serial comput time therefor isoeffici function isoeffici p log p assum network congest load balanc phase transport primit use load balanc isoeffici op 3 5 experiment result implement three parallel formul use mpi program librari use binari split decis tree node grow tree breadth first manner gener larg dataset use wide use synthet dataset propos sliq paper 18 experi ten classif function also propos 18 dataset use function 2 dataset algorithm dataset two class label record consist 9 attribut 3 categor 6 continu attribut dataset also use sprint algorithm 21 evalu perform experi done ibm sp2 result compar speedup three parallel formul report parallel run 1 2 4 8 16 processor experi hybrid approach report 128 processor processor clock speed 667 mhz 256 mb real memori oper system aix version 4 processor commun high perform switch hp implement keep attribut list disk use memori store program specif data structur class histogram cluster structur first present result scheme context discret attribut compar perform three parallel formul 16 processor ibm sp2 result discret 6 continu attribut uniformli specif discret continu attribut salari 13 commiss 14 age 6 hvalu 11 hyear 10 loan equal interv measur speedup work differ size dataset 08 million train case 16 million train case increas processor 1 16 result figur 6 show speedup comparison three parallel algorithm propos paper graph left show speedup 08 million exampl train set graph show speedup 16 million exampl result show synchron tree construct approach good speedup 2 processor poor speedup 4 processor two reason first synchron tree construct approach incur high commun cost process lower level tree second synchron done among differ processor soon commun buffer fill commun buffer histogram discret variabl node thu contribut node independ tupl count tupl count node proport comput process node process lower level tree synchron done mani time level everi 100 node experi distribut tupl decis tree node becom quit differ lower tree therefor processor wait synchron thu contribut poor speedup partit tree construct approach better speedup synchron tree construct approach howev effici decreas number processor increas 8 16 partit tree construct approach processor speedup 08 million exampl partit hybrid synchron x processor speedup 16 million exampl partit hybrid synchron x figur 6 speedup comparison three parallel algorithm suffer load imbal even though node partit processor get equal number tupl simpl way predict size subtre particular node load imbal lead runtim determin heavili load processor partit tree construct approach also suffer high data movement partit phase partit phase take place higher level tree processor involv take longer reach point processor work local data observ experi load imbal higher commun order major caus poor perform partit tree construct approach number processor increas hybrid approach superior speedup compar partit tree approach speedup keep increas increas number processor discuss section 33 analyz section 4 hybrid control commun cost data movement cost adopt advantag two basic parallel formul hybrid strategi also wait long enough split larg number decis tree node split among processor due alloc decis tree node processor random larg extent good load balanc possibl result confirm propos hybrid approach base two basic parallel formul effect also perform experi verifi split criterion hybrid algorithm correct figur 7 show runtim hybrid algorithm differ ratio commun cost sum move cost load balanc cost ie commun cost move cost log2split criteria ratio x0 ratio1 runtim runtim split differ valu ratio 8 processor 08 million exampl 10100300500log2split criteria ratio x0 ratio1 runtim runtim split differ valu ratio 16 processor 16 million exampl figur 7 split criterion verif hybrid algorithm graph left show result 08 million exampl 8 processor graph show result 16 million exampl processor propos split ratio 10 would optim time result verifi hypothesi runtim lowest ratio around 10 graph right 16 million exampl show clearli split choic critic obtain good perform split decis made farther away optim point propos runtim increas significantli experi 16 processor clearli demonstr hybrid approach give much better perform split criterion use hybrid approach close optim perform experi run hybrid approach number processor differ size dataset studi speedup scalabl experi use origin data set continu attribut use cluster techniqu discret continu attribut decis tree node 23 note parallel formul give almost ident perform serial algorithm term accuraci classif tree size 23 result figur 8 show speedup hybrid approach result confirm hybrid approach inde effect studi scaleup behavior kept dataset size processor constant 50000 exampl increas number processor figur 9 show runtim increas number processor curv close ideal case horizont line deviat ideal case due fact isoeffici function op log p op current experiment data consist deriv isoeffici function intend conduct addit valid experi number processor speedup curv differ size dataset million exampl 16 million exampl 32 million exampl 64 million exampl 128 million exampl 256 million exampl figur 8 speedup hybrid approach differ size dataset number processor total run time runtim algorithm 50k exampl processor figur 9 scaleup algorithm 6 conclud remark paper propos three parallel formul inductiveclassif learn algorithm synchron tree construct approach perform well classif tree remain skinni node level throughout tree rel larg number train case node level thu commun overhead rel small load imbal avoid process node level synchron among processor howev tree becom bushi larg number node level number train data item node decreas frequent synchron done due limit commun buffer size forc commun process fix number node node lower depth tree tupl assign may highli variabl distribut tupl processor lead load imbal henc approach suffer high commun overhead load imbal bushi tree partit tree construct approach work better synchron tree construct approach tree bushi approach pay big commun overhead higher level tree shuffl lot train data item differ processor everi node sole assign singl processor processor construct partial classif tree independ without commun processor howev load imbal problem still present shuffl train data item sinc partit data done static hybrid approach combin good featur two approach reduc commun overhead load imbal approach use synchron tree construct approach upper part classif tree sinc node rel larg number train case associ node upper part tree commun overhead small soon accumul commun overhead greater cost partit data load balanc approach shift partit tree construct approach increment partit take place reason number node present level partit gradual perform random alloc classif tree node result better load balanc load imbal lower level tree processor group finish process assign subtre handl allow idl processor group join busi processor group size shape classif tree vari lot depend applic domain train data set classif tree might shallow other might deep classif tree could skinni other could bushi classif tree might uniform depth tree might skew one part tree hybrid approach adapt well type classif tree decis tree skinni hybrid approach stay synchron tree construct approach hand shift partit tree construct approach soon tree becom bushi tree big varianc depth hybrid approach perform dynam load balanc processor group reduc processor idl acknowledg signific part work done anurag srivastava vineet singh ibm tj watson research center work support nsf grant asc9634719 armi research offic contract dadaah049510538 cray research inc fellowship ibm partnership award content necessarili reflect polici govern offici endors infer access comput facil provid ahpcrc minnesota supercomput institut cray research inc nsf grant cda9414015 note 1 messag size larg rout messag part commun step done constant k0 refer 16 section 37 detail r databas mine perform perspect cloud classif larg outofcor dataset megainduct machin learn larg databas experi multistrategi learn met alearn metalearn multistrategi learn parallel learn concaten parallel techniqu effici parallel divid conquer genet algorithm search use contextu inform featur rank discret new scalabl effici parallel classif algorithm mine larg dataset unstructur tree search simd parallel comput decis tree parallel processor introduct parallel comput algorithm design analysi introduct comput neural net sliq fast scalabl classifi data mine coars grain parallel induct heurist sprint scalabl parallel classifi data mine experi cost benefit window id3 tr ctr amir baror daniel keren assaf schuster ran wolff hierarch decis tree induct distribut genom databas ieee transact knowledg data engin v17 n8 p11381151 august 2005 robert grossman yike guo data mine task method parallel method scale data mine algorithm larg data set handbook data mine knowledg discoveri oxford univers press inc new york ny 2002 doina caragea adrian silvescu vasant g honavar analysi synthesi agent learn distribut dynam data sourc emerg neural comput architectur base neurosci toward neuroscienceinspir comput springerverlag new york inc new york ny 2001 olcay taner yldz onur dikmen parallel univari decis tree pattern recognit letter v28 n7 p825832 may 2007 vipin kumar moham zaki high perform data mine tutori pm3 tutori note sixth acm sigkdd intern confer knowledg discoveri data mine p309425 august 2023 2000 boston massachusett unit state raymond ng alan wagner yu yin icebergcub comput pc cluster acm sigmod record v30 n2 p2536 june 2001 ruggieri effici c45 ieee transact knowledg data engin v14 n2 p438444 march 2002 massimo coppola marco vanneschi parallel distribut data mine parallel skeleton distribut object data mine opportun challeng idea group publish hershey pa aleksandar lazarev zoran obradov boost algorithm parallel distribut learn distribut parallel databas v11 n2 p203229 march 2002 vipin kumar moham zaki high perform data mine tutori pm3 tutori note sixth acm sigkdd intern confer knowledg discoveri data mine p309425 august 2023 2000 boston massachusett unit state massimo coppola marco vanneschi highperform data mine skeletonbas structur parallel program parallel comput v28 n5 p793813 may 2002 jack dongarra ian foster geoffrey fox william gropp ken kennedi linda torczon andi white refer sourcebook parallel comput morgan kaufmann publish inc san francisco ca