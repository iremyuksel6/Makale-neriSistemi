experiment comparison nearestneighbor nearesthyperrectangl algorithm algorithm base nest gener exemplar nge theori salzberg 1991 classifi new data point comput distanc nearest gener exemplar ie either point axisparallel rectangl combin distancebas charact nearest neighbor nn classifi axisparallel rectangl represent employ mani rulelearn system implement nge compar knearest neighbor knn algorithm 11 domain found significantli inferior knn 9 sever modif nge studi understand caus poor perform show perform substanti improv prevent nge creat overlap rectangl still allow complet nest rectangl perform improv modifi distanc metric allow weight featur salzberg 1991 best result obtain studi weight comput use mutual inform featur output class best version nge develop batch algorithm bnge fwmi usertun paramet bnge fwmi perform compar firstnearest neighbor algorithm also incorpor featur weight howev knearest neighbor algorithm still significantli superior bnge fwmi 7 11 domain inferior 2 conclud even improv nge approach sensit shape decis boundari classif problem domain decis boundari axisparallel nge approach produc excel gener interpret hypothes domain test nge algorithm requir much less memori store gener exemplar requir nn algorithm b introduct salzberg 1991 describ famili learn algorithm base nest gener exemplar nge nge exemplar singl train exampl gener exemplar axisparallel hyperrectangl may cover sever train exampl hyperrectangl may overlap nest nge algorithm grow hyperrectangl increment train exampl process gener exemplar learn test exampl classifi comput euclidean distanc exampl gener exemplar exampl contain insid gener exemplar distanc wettschereck tg dietterich gener exemplar zero class nearest gener exemplar output predict class test exampl nge approach view hybrid nearest neighbor method proposit horn claus rule like nearest neighbor method euclidean distanc appli match test exampl train exampl like horn claus rule train exampl gener axisparallel hyperrectangl salzberg report promis classif result three domain howev report nge test 11 addit domain give less accur predict mani domain compar knearest neighbor knn algorithm goal paper demonstr perform understand caus test algorithm modif might improv nge perform first part paper devot studi compar nge knn 1 compar algorithm fairli necessari find optim set variou paramet option nge knn henc first describ seri experi studi perform nge lesser extent knn determin sever key paramet option includ number start seed treatment ungener exemplar treatment nomin featur valu present result show nge best paramet set substanti inferior knn 9 11 domain test superior knn 2 domain second part paper attempt diagnos repair caus perform deficit present sever hypothes includ inappropri nest hyperrectangl bia b inappropri overlap hyperrectangl bia c poor perform search algorithm heurist construct hyperrectangl experi present test hypothes version nge call nong disallow overlap rectangl retain nest rectangl search procedur uniformli superior nge 11 domain significantli better 6 batch algorithm obng incorpor improv search algorithm disallow nest rectangl still permit overlap rectangl superior nge one domain wors two experi lead us conclud major sourc problem nge creation overlap rectangl also present batch version nong call bnge effici requir user tune paramet recommend bnge employ domain batch learn appropri third part paper take issu learn featur weight weight euclidean distanc salzberg 1991 propos onlin weight adjust algorithm data present show algorithm often perform poorli errat altern featur weight algorithm base mutual inform shown work well nn nge bnge final part paper compar best version nge bnge fwmi best version knn knn cv fwmi comparison show despit improv nge still significantli inferior knn 7 domain significantli superior 2 domain compar singl nearest neighbor nn best version nge fare better significantli superior 3 domain significantli inferior 4 ideal behavior hybrid algorithm like nge domain axisparallel rectangl appropri nge take advantag find concis interpret represent learn knowledg howev domain axisparallel rectangl appropri nge behav like nearest neighbor algorithm version nge develop take advantag hyperrectangl perform poorli domain hyperrectangl inappropri research need develop ngelik algorithm robust situat axisparallel hyperrectangl inappropri 2 algorithm experiment method 21 nge algorithm figur 1 summar nge algorithm follow close salzberg definit nge nge construct hyperrectangl process train exampl one time initi randomli select userdefin number seed train exampl construct trivial point hyperrectangl seed new train exampl first classifi accord exist set hyperrectangl comput distanc exampl hyperrectangl class nearest hyperrectangl train exampl coincid nearest hyperrectangl extend includ train exampl otherwis second nearest hyperrectangl tri call second match heurist first second nearest hyperrectangl differ class train exampl train exampl store new trivial hyperrectangl queri classifi accord class nearest hyperrectangl distanc comput follow exampl lie outsid exist hyperrectangl weight euclidean distanc comput exampl fall insid hyperrect angl distanc hyperrectangl zero exampl equidist sever hyperrectangl smallest chosen implement nge first make pass train exampl normal valu featur interv 01 linear normal aha 1990 featur valu test set normal scale factor note may fall outsid 01 rang asid scale pass basic algorithm entir increment hyperrectangl h j label output class hyperrectangl repres lower left corner h j lower upper right corner h j upper distanc h j exampl e featur f 1 f nfeatur 4 wettschereck tg dietterich 1 build nge classifi input number seed 2 initi assum train exampl given random order 3 first train exampl e call createhyperrectangle 4 train 5 remain train exampl e 6 find two h j deh j minim 7 case tie choos two h j minim area 8 call hyperrectangl h closest h second closest 9 compareh closest e generalizeh closest e 10 els compareh second closest e generalizeh second closest e 11 els createhyperrectangle 12 compar class hyperrectangl exampl 13 compareh 14 class classh return true els return fals 15 gener hyperrectangl 17 featur e 19 h lowerf 20 replmissfeaturesh e 21 creat hyperrectangl 22 createhyperrectangle 23 24 h lower 26 replmissfeaturesh e 27 replac miss featur hyperrectangl 28 replmissfeaturesh 29 featur e 30 featur e miss 33 classif test exampl 34 classify 35 output classh j 36 case tie choos h j tie minim area figur 1 pseudocod describ construct nge classifi classif test exampl h gener denot hyperrectangl e exampl defin follow w lowerf lowerf weight featur see section weight hyperrectangl j comput number time compareh j call number time compareh j return true origin nge algorithm design continu featur discret symbol featur requir modif distanc area comput nge adopt nge polici symbol discret featur set cover featur valu store hyperrectangl analog store rang featur valu continu featur hyperrectangl cover certain featur valu valu member cover set hyperrectangl gener includ miss discret symbol featur flag set correspond featur hyperrectangl cover featur valu futur area nontrivi hyperrectangl comput follow 2 nfeatur comput follow 37 h f gener includ miss featur 38 els f continu 39 h upperf h lowerf 40 els 41 els f discret symbol featur 42 number valu f cover h number possibl valu f note maximum possibl size hyperrectangl therefor 1 fur thermor probabl line 39 execut low sinc unlik two continu featur valu match exactli therefor deem unnecessari adjust area hyperrectangl case origin nge paper also specifi polici handl exampl contain miss featur context nearest neighbor algorithm aha 1990 section 521 evalu three method distanc comput miss fea ture adopt ignor method one simplest method deal miss featur featur exampl miss distanc featur 0 furthermor total distanc featur divid number known featur distinguish perfect match miss featur distanc 0 incorpor methodolog gener procedur nge follow whenev hyperrectangl nge extend includ exampl miss featur rang hyperrectangl extend miss featur cover entir input space featur see line 20 26 2732 figur 1 6 wettschereck tg dietterich 22 nearest neighbor algorithm one vener algorithm machin learn nearest neighbor algorithm nn see dasarathi 1991 survey literatur entir train set store memori classifi new exampl euclidean distanc possibl weight comput exampl store train exampl new exampl assign class nearest neighbor exampl gener k nearest neighbor comput new exampl assign class frequent among k neighbor denot knn aha 1990 describ sever spaceeffici variat nearestneighbor algorithm nge adopt aha ignor method handl train exampl miss featur reader note perform nge nn may chang substanti differ missingvalu polici use 23 data set studi employ eleven data set three synthet remain eight drawn ucirvin repositori murphi aha 1994 aha 1990 machin learn databas synthet data set construct test sensit nge shape decis boundari number class figur 2 task c axisparallel decis boundari task b diagon decis boundari task b 2class problem task c 10 class figur 2 artifici data set b gamma indic locat posit neg exampl c digit indic locat exampl class number exampl decis region shown lower left corner region eight irvin data set summar tabl 1 import point note waveform40 domain ident waveform21 domain addit 19 irrelev featur random valu b cleveland databas detrano et al 1989 contain miss featur c mani input featur hungarian databas detrano et al 1989 vote record databas miss 24 experiment method measur perform nge nearest neighbor algorithm employ train settest set methodolog data set randomli partit train set contain approxim 70 pattern test set contain remain pattern see also tabl 1 train train set percentag correct classif test set measur procedur repeat total 25 time reduc statist variat experi algorithm compar train test ident data set ensur differ perform due entir algo rithm gener learn curv follow procedur except subset train set use test set along learn curv constant larger train set contain smaller one report averag percentag correct classif standard error twotail pair ttest conduct determin level signific one algorithm outperform conclud one algorithm significantli outperform anoth algorithm pvalu obtain ttest smaller 005 tabl 1 domain characterist modifi aha 1990 domain train test number kind number set size set size featur class iri 105 display 200 500 hungarian 206 vote 305 letter recognit 16000 4000 3 experi paramet sensit explor sensit nge knn userspecifi paramet nge paramet interest number start seed b treatment ungener exemplar c order present exampl knn paramet interest number nearest neighbor k 31 number start seed figur 3 show perform nge task b c sever differ number start seed perform shown rel perform simpl nearest neighbor task b number class small nge perform particularli poor small number seed 8 wettschereck tg dietterich contradict salzberg find 1991 page 257 first paragraph state perform nge found sensit size seed set number seed ngegammann task c ngegammann task ngegammann task btheta perform rel nn figur 3 perform nge rel nn nge initi vari number seed cv leaveoneout crossvalid base perform nn 976 correct task 970 task b 824 task c datapoint repres mean 25 replic 350 train exampl 150 test exampl see tabl a1 appendix detail number figur 3 also show surprisingli nge perform better task c decisionboundari axisparallel task b boundari diagon task b simpl nn outperform nge right end figur label cv show perform obtain leaveoneout crossvalid weiss kulikowski 1991 employ determin optim number seed strategi work well adopt subsequ experi unless otherwis note 3 follow number seed test leaveoneout crossvalid run 3 5 7 10 15 20 25 crossvalid inher nonincrement cost use crossvalid destroy increment natur nge note nge given suffici larg number seed algorithm becom simpl nearestneighbor algorithm limit one seed everi data point limit reach three task howev nge need approxim 6 task 13 task b 28 task c storag requir nn store entir train set detail number provid tabl a1 appendix 32 treatment ungener exemplar nge hyperrectangl initi point input space therefor size 0 gener nontrivi hyperrectangl see pseudocod figur 1 line 7 25 found led7 domain howev initi size hyperrectangl 1 led signific perform improv 430sigma14 correct 598sigma10 artifact led7 domain specif result fact led7 larg number train exampl ident featur vector belong differ class initi size hyperrectangl effect nge perform domain experi report remaind paper chose initi size hyperrectangl 0 except led7 domain initi size 1 tabl 2 perform nge one specif trainingtest set partit number shown indic perform nge run 25 random permut train set domain mean median min max iri 918sigma08 933 844 978 hungarian 780sigma05 773 716 830 vote 933sigma04 931 892 962 33 order present train data nge sensit order train exampl present tabl 2 show result experi train settest set partit fix order present train set randomli vari see perform vari wide across domain seriou drawback nge algorithm 1 unfortun difficult choos good order train set could find effect way appli crossvalid method exampl select good order result report random order select run nge algorithm mean 25 run report 34 valu k knearest neighbor algorithm wellestablish noisi domain knearest neighbor algorithm perform better simpl nearest neighbor henc chose k optim leaveoneout crossvalid perform algorithm train set tri possibl valu k done rel effici tie broken favor smaller valu k 4 comparison nge knn figur 4 compar perform knearest neighbor algorithm knn nge cv number seed chosen via leaveoneout crossvalid nge 3 seed nge 3 seed 4 nge number seed increas wettschereck tg dietterich 50 train data nge limit rational behind nge limit amount storag requir hyperrectangl twice amount storag requir store singl data point henc number seed equal 50 train data total space requir nge equal space requir knn assum similar method deal tie miss featur use beyond point nge data compress advantag knn 5 5 vote hungarian letter iri task c task recognit perform rel figur 4 perform ngecv nge 3seed nge limit rel knn shown percentag point differ ngecv knn nge 3seed knn nge limit knn signific differ knn differ nge version indic see tabl a2 appendix detail number knearest neighbor outperform nge cv statist signific amount eight nonconstruct domain display figur 4 domain nge cv achiev signific ie 60 85 compress data significantli increas number seed nge limit figur 4 possibl significantli improv perform nge cv task b led7 cleveland hungarian letter recognit domain howev nge limit still significantli inferior knn perform one nonconstruct domain drop perform vote domain task due fact domain leaveoneout crossvalid small number differ seed set size benefici increas size seed set 6 howev improv perform nge limit come high cost case nge perform improv also use memori knn figur 5 show learn curv domain gener curv shape expect induct learn algorithm perform increas number train exampl increas level nearesthyperrectangl comparison 1180100 task theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta c c c c theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta c c c task c theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta c c c c iri c c c theta theta theta theta theta theta theta theta theta500 50 100 150 200 c c c theta theta theta theta theta theta theta theta theta theta theta6080 c c c c c theta theta theta theta theta theta theta theta theta theta theta theta theta6080 c c c c theta theta theta theta theta theta theta theta theta theta theta theta700 50 100 150 200 c c c c c theta theta theta theta theta theta theta theta theta theta theta theta700 50 100 150 200 hungarian c c c c c c theta theta theta theta theta theta theta theta theta theta theta theta800 50 100 150 200 250 300 vote c c c theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta50100 letter recognit c c c c c c theta theta theta theta theta theta theta theta theta theta theta theta theta theta number train exampl number train exampl perform perform perform figur 5 perform nge knn differ number train exampl data point denot mean 25 experi note differ scale axe graph train set reach certain size waveform led7 letter recognit domain perform nge cv level much earlier knn furthermor graph cleveland hungarian vote domain show errat behavior nge cv hungarian vote domain nge cv 12 wettschereck tg dietterich reach near peak perform 25 train exampl seen 25 train exampl perform nge cv vari within two standard error domain cleveland domain perform nge cv peak also 25 exampl 726sigma19 correct drop 669sigma18 inspect number size hyperrectangl construct nge cv domain abl determin caus unusu behavior number hyperrectangl store nge cv grow linearli number train exampl although desir properti machin learn algorithm may caus problem nge cv sinc exist hyperrectangl may gener extend often mean everi time hyperrectangl enlarg may actual becom less relev conclud behavior constitut seriou defici nge search gener procedur 5 possibl explan inferior perform nge given close relationship nge knn surpris nge perform much wors knn learn algorithm two fundament sourc problem first bia algorithm may inappropri applic domain second implement bia may poor eg poor search algorithm employ salzberg never formal defin bia nge let us defin find minimum number axisparallel hyperrectangl possibl nest overlap correctli classifi train data evid bia inappropri know task nonaxisparallel decis boundari axisparallel bia inappropri see figur 3 artificiallyconstruct domain howev aha 1990 report perform c45 quinlan 1992 six domain also use paper c45 also rectangular bia perform similar condit significantli better nge six domain aha 1990 section 433 7 suggest axisparallel bia caus nge poor perform examin learn hyperrectangl sever domain suggest permit rectangl nest overlap problem common form nest larg gener hyperrectangl creat mani singlepoint rectangl nest insid except seen figur 6 plot number hyperrectangl creat number actual gener nonpoint rectangl see overwhelm major hyperrectangl never gener singlepoint hyperrectangl virtual never use classifi new test exampl test exampl fall insid larg hyperrectangl distanc hyperrectangl zero singlepoint hyperrectangl use unless nearesthyperrectangl comparison 1310003500 letter recognit theta theta theta theta theta theta theta theta theta theta theta theta c c cccc c c c c c c c number train exampl number exemplar figur 6 number exemplar store nge train 25 seed differ size train set letter recognit task shown total number hyperrectangl store train theta number hyperrectangl gener least ffi data point denot mean 25 experi either test exampl exactli coincid singlepoint rectangl b singlepoint rectangl nest insid anoth rectangl nge also permit gener rectangl overlap even dont nest may problem well one situat overlap rectangl creat distribut exampl two class b overlap optim decis rule uniform loss function cf duda hart 1973 place decis boundari point probabl densiti exampl class equal probabl densiti exampl class b howev nge instead arbitrarili assign exampl overlap region one classesth one smaller rectangl addit hypothes bia nge consider evid bia implement well nge increment heurist procedur sensit experi know nge sensit order train exampl present order well task c determin optim set hyperrectangl inspect 4 10 respect nge find optim solut instead construct averag 108sigma11 496sigma12 task b hand optim solut involv larg number rather small overlap rectangl one everi train exampl lie near decis boundari howev nge find solut either construct rectangl larg nest smaller one figur 7 display rectangl construct nge cv repres experi task b c summari three hypothes explain nge perform poorli rel knn h1 nest rectangl h2 overlap rectangl h3 poor search algorithm test hypothes conduct seri experi modifi nge elimin one suspect problem measur result chang perform 14 wettschereck tg dietterich figur 7 rectanglesconstructedbi ngecv task b c one repres experi b dash solid line indic locat rectangl repres posit neg exampl c digit indic class rectangl repres trivial point rectangl display note task singl rectangl class 0 cover entir input space first experi test h1 modifi nge produc rel nest rectangl still permit overlap rectangl otherwis chang search procedur second experi test h2 modifi nge produc overlap rectangl differ class except rectangl entir nest insid one anoth otherwis chang search procedur third experi test h3 make simpl modif increment nge improv upon secondmatch heurist goal find fewer hyperrectangl final fourth experi test hypothes simultan implement entir differ search procedur complet elimin nest rectangl overlap rectangl also reduc total number rectangl construct describ experi result 51 greedi nge avoid nest test h1 want construct variant nge avoid nest rectangl major caus nest rectangl second match heurist line 9 figur 1 nearest rectangl wrong class second nearest rectangl right class secondnearest rectangl expand cover new exampl mani case also cover nearest rectangl could singl point thu creat nest salzberg 1991 section 35 introduc test version nge call greedi nge second match heurist greedi version store exampl new hyperrectangl whenev closest previous store hyperrectangl differ class exampl accord salzberg second match heurist nge necessari construct nest overlap hyperrectangl true nge may still con nearesthyperrectangl comparison 15 struct overlap nest hyperrectangl even second match heurist disabl grow hyperrectangl overlap cover anoth hyperrectangl fact greedi nge construct overlap hyperrectangl quit frequent nest hyperrectangl case experi conduct figur 8 show predict accuraci greedi nge significantli better nge three domain cleveland hungarian vote significantli wors 4 other task task c waveform21 waveform40 result task c waveform40 particularli poor base much evid nest rectangl major problem nge vote letter hungarian iri task c task b520 5 task recognit greedi perform rel figur 8 perform greedi nge nge addit match heurist f2noc first two match nearest exemplar exampl class consid nong rel nge indic perform differ nge modif statist signific p 005 see tabl a2 appendix detail number 52 nge without overlap hyperrectangl nong test h2 want construct variant nge avoid overlap rectan gle accomplish follow let us defin p potenti new hyperrectangl construct call gener line 9 10 figur 1 rectangl p rectangl form extend either first match second match rectangl cover train exampl wettschereck tg dietterich nooverlap nge nong construct p check whether would intersect hyperrectangl class p would intersect anoth rectangl reject p creat new singlepoint rectangl instead howev p would complet contain within anoth hyperrectangl accept p way nest rectangl permit overlap nonnest rectangl forbidden figur 8 see nong significantli better nge 6 11 domain never significantli wors nge strongli support hypothesi h2that overlap rectangl caus problem nge 53 better merg heurist nge nge store train exampl new hyperrectangl whenev two nearest hyperrectangl differ output class exampl case howev creat unnecessari new rectangl consid figur 9 rectangl c away point p either rectangl rectangl b howev rectangl c class point p could extend cover point p without overlap either rectangl b extend rectangl c way avoid creat new gener exemplar point p develop modifi version nge call f2noc detect situ ation first two match nearest secondnearest hyperrectangl fail f2noc find nearest hyperrectangl class ex ampl extend nearest hyperrectangl includ new exampl expand hyperrectangl would cover hyperrectangl class otherwis store exampl new hyperrectangl give nge anoth chanc gener gener reduc amount memori requir nge class3 c class2 class1 class3 figur 9 exampl show rectangl c extend cover point p f2noc consid weak test hypothesi h3 search algorithm nge need improv tabl a2 indic addit match heurist inde achiev reduct storag domain henc better implement nge bia howev shown figur 8 f2noc perform significantli better nge task c reduct storag directli relat loss predict accuraci five domain henc improv nge search algorithm explain poor perform nge rel knn nearesthyperrectangl comparison 17 vote letter hungarian iri task c 5 recognit perform rel figur 10 perform obng bnge rel nge shown percentag point differ obng nge bnge nge indic perform differ nge modif statist signific p 005 tabl a2 appendix detail number 54 batch nge obtain better test h3 construct two batch algorithm obng bnge nge bia algorithm begin train exampl memori point hyperrectangl progress merg form gener hyperrectangl step two hyperrectangl nearest one anoth merg subject one follow constraint obng merg merg would caus misclassif train exampl algorithm requir test entir train set potenti merg permit overlap nest rectangl call obng overlap batch nge bnge merg new hyperrectangl cover overlap hyperrectangl class algorithm requir intersect potenti merg hyperrectangl class permit overlap nest call bnge batch nge merg process algorithm repeat merg found note algorithm somewhat depend order potenti merg consid greedi merg accept soon mention condit satisfi wettschereck tg dietterich algorithm conserv gener beyond train data origin nge algorithm sinc gener hyperrectangl part input space clearli belong certain class furthermor due fact bnge obng repeatedli pass train data may also significantli reduc number hyperrectangl remain end bnge also faster easier use nge sinc crossvalid free paramet requir obng howev feasibl larg train set number display figur 10 tabl a2 show bnge significantli outperform nge 7 11 domain test case perform bnge better nge hand obng significantli better nge task c significantli wors nge three domain task task b hungarian provid addit strong evid overlap rectangl inappropri bia domain h2 test h3 examin first whether bnge implement better search algo rithm task c bnge attain optim solut 4 hyperrectangl task c furthermor bnge also use one hyperrectangl cover iri setosa class iri domain good evid qualiti bnge search procedur increment version nge similar bnge nong nge without overlap rectangl compar figur 8 10 tabl a2 seen bnge outperform nong four domain nong outperform bnge two domain give weak evid improv search algorithm bnge respons improv perform note bnge also train increment cost store train exampl increment bnge would split rebuild hyperrectangl whenev cover new exampl differ class 55 discuss experi see weak support h3 strong support h2 explan poor perform nge rel nearest neighbor algorithm support h1 version nge permit overlap rectangl perform consist better nge domain test batch algorithm bnge permit nest overlap rectangl differ class perform quit well avoid need choos number seed nge crossvalid 6 featur weight experi conduct thu far treat featur equal import comput euclidean distanc nearest hyperrectangl nearest neighbor howev mani 11 domain involv noisi nearesthyperrectangl comparison 19 tabl 3 percentag nonse exampl cover least one hyperrectangl nge initi 3 25 seed domain train test 3 seed 25 seed 3 seed 25 seed iri 43 38 72 68 hungarian vote 97 93 100 100 letter recognit 79 79 95 94 complet random featur way improv perform nge knn introduc mechan learn featur import ignor unimport noisi featur distanc comput salzberg 1991 section 33 last paragraph describ method onlin learn featur weight nge assum new exampl e misclassifi exemplar h input featur f weight f w f increas multipli 1 match h f weight w f decreas multipli global featureadjust rate usual set 02 e classifi correctli h featur weight adjust opposit direct two problem heurist first consid task one class much frequent anoth task new exampl tend classifi correctli chanc featur weight chang exponenti featur alway match weight zero featur random receiv infinit weight salzberg person commun 1991 pseudo suggest adjust featur weight match ie nearest secondnearest hyperrectangl fail found empir polici featur weight adjust quit infrequ exampl iri task featur weight adjust 1 train exampl waveform40 featur weight adjust 7 train exampl second seriou problem use featur weight nge high percentag test case fall insid least one hyperrectangl mean distanc nearest hyperrectangl zero featur weight effect distanc calcul tabl 3 show percentag test train case occur suggest limit perform improv obtain use featur weight nest hyperrectangl experi salzberg method comput featur weight found perform almost alway decreas see therefor consid anoth procedur comput featur weight given promis result exemplarbas learn method bakiri 1991 wettschereck tg dietterich 61 determin weight mutual inform purpos featur weight mechan give low weight featur provid inform classif eg noisi irrelev featur give high weight featur provid reliabl inform henc natur quantiti consid mutual inform valu featur class exampl featur provid inform class mutual inform 0 featur complet determin class mutual inform proport log number class let c probabl class train exampl equal c probabl valu featur j exampl fall interv ninterv joint probabl two event mutual inform featur f j classif c log discret featur ninterv equal number possibl distinct put continu featur ninterv chosen 5 probabl estim train data miss valu ignor mutual inform measur also known machin learn literatur inform gain use split criterion id3 c45 quinlan 1992 62 experi featur weight figur 11 tabl a2 show effect includ featur weight compar two differ procedur comput weight salzberg method give statist signific increas perform hungarian domain statist signific decreas task c signific effect domain mutual inform featur weight gener give slight though statist insignific improv domain without irrelev featur improv substanti domain irrelev featur give statist signific improv cleveland hungarian vote domain well task c small p 005 decreas perform observ mutual inform featur weight letter recognit domain mutual inform featur weight similar posit effect perform simpl nearest neighbor lesser extent knn see tabl a2 mutual inform weight small irrelev input domain furthermor featur weight differ substanti one random partit data set anoth contrast weight comput nearesthyperrectangl comparison 2155 recognit letter hungarian vote iri task c task perform rel figur 11 perform nge fwmi nge fw salzberg rel nge without featur weight shown percentag point differ nge fwmi nge nge fw salzberg nge indic signific differ nge modi ficat see tabl a2 appendix detail number salzberg method differ substanti one partit anoth vari much factor 1000 within given train settest set partit featur less equal weight experi section 6 conclud salzberg weight procedur signific impact nge behavior domain mutual inform weight procedur perform well domain larg number irrelev featur furthermor sinc mutual inform weight procedur independ algorithm use procedur could use effect mani induct learn algorithm filter irrelev featur 7 comparison best variant nge knn develop sever modif nge uniformli improv perform algorithm best combin batch nge mutual inform featur weight bnge fwmi best correspond version nearest neighbor algorithm k nearest neighbor crossvalid determin mutual inform featur weight knn fwmi section compar two algorithm determin whether modif nge make competit knn figur 12 show result comparison main conclus draw bnge fwmi significantli inferior knn fwmi 7 domain significantli superior 2 two domain domain know 22 wettschereck tg dietterich hungarian vote 5 letter iri task c task recognit knn fwmi perform rel fwmi figur 12 perform nge fwmi bnge fwmi rel knn fwmi shown percentag point differ nge fwmi bnge fwmi knn fwmi differ statist signific see tabl a2 appendix detail number axisparallel rectangl bia appropri show hyperrectangl appropri bnge fwmi abl exploit howev domain rectangl evid appropri bnge fwmi perform suffer knn fwmi robust situat show research still need develop nge algorithm robust situat 8 relat work simpson simpson 1992 introduc increment algorithm extrem similar nge call fuzzi minmax neural network main differ nge fuzzi minmax classifi hyperrectangl fmmc bound size b fmmc alway extend nearest hyperrectangl class given exampl includ exampl long size new hyperrectangl larger userdefin valu c ffmc shrink hyperrectangl elimin overlap hyperrectangl differ class carpent et al 1992 introduc neural network architectur base fuzzi logic adapt reson theori art neural network categori box use fuzzi artmap complement code compar hyperrectan gle hyperrectangl fuzzi artmap complement code grow monoton nearesthyperrectangl comparison 23 ical learn maximum size bound vigil paramet see carpent et al 1992 short comparison nge ffmc fuzzi artmap neither fmmc fuzzi artmap use featur weight sens discuss paper 9 summari discuss extens studi nge algorithm conduct basic algorithm number modif evalu eleven domain nge found quit sensit number start seed order present exampl perform nge compar perform knearest neighbor algorithm found substanti wors sever domain even crossvalid appli optim number start seed nge three hypothes introduc explain differ perform nest rectangl provid poor bia b overlap rectangl provid poor bia c increment search algorithm nge need improv experiment modif nge made order test hypothes two version nge avoid nest rectangl permit overlap rectan gle perform substanti better nge howev algorithm call nong permit nest rectangl avoid overlap rectangl perform uniformli better nge eleven domain improv statist signific 6 domain batch algorithm bnge implement better search algorithm allow nest overlap rectangl also perform uniformli better nge perform better nong 4 domain wors 2 experi conclud overlap rectangl primari sourc difficulti nge bnge best variant nge studi experi report wettschereck 1994 show bnge commit error outsid hyperrectangl use knn classifi test exampl fall outsid hyperrectangl hybrid method bnge knn attain classif accuraci compar knn alon larg improv classif speed version nge effect compress data compar knn also studi whether nge algorithm could improv incorpor featur weight distanc metric comput algorithm featur weight mechan introduc salzberg 1991 shown never provid signific improv perform nge without featur weight deed significantli wors simpl nge three domain hand featur weight mechan base comput mutual inform featur output class shown significantli better nge five domain significantli wors one mechan wettschereck tg dietterich independ nge therefor use preprocess step induct learn algorithm 10 conclus data present strongli support conclus nge algorithm describ salzberg 1991 modifi number way first construct overlap hyperrectangl avoid second entir train set avail store memori classifi train batch mode elimin comput expens crossvalid number initi seed third mutual inform use comput featur weight prior run nge modif nge give superior perform domain axisparallel hyperrectangl bia appropri howev domain nge perform well knn henc gener perform robust critic knn algorithm choic hand understand memori compress import nge modifi recommend fast easytous induct learn algorithm 8 acknowledg thank steven salzberg provid assist implement nge thank one anonym review point heurist comput size symbol featur us also thank steven salzberg anonym review bill langford help comment earlier draft note research support part nsf grant iri8657316 nasa ame grant nag 2630 gift sun microsystem hewlettpackard r studi instancebas algorithm supervis learn task convert english text speech machin learn approach fuzzi artmap neural network architectur increment supervis learn analog multidimension map nearest neighbornn norm nn pattern classif techniqu pattern classif scene analysi simpl classif rule perform well commonli use dataset nearest hyperrectangl learn method fuzzi minmax neural network 1 comput system learn hybrid nearestneighbor nearesthyperrectangl algorithm tr ctr j mitran bouillant e bourennan svm approxim realtim imag segment use improv hyperrectanglesbas method realtim imag v9 n3 p179188 june igor jurisica janic glasgow john mylopoulo increment iter retriev browsingfor effici convers cbr system appli intellig v12 n3 p251268 mayjun 2000 jurisica p roger j glasgow fortier j r luft j r wolfley bianca r week g detitta intellig decis support protein crystal growth ibm system journal v40 n2 p394409 februari 2001 steven l salzberg compar classifi pitfal toavoid recommend approach data mine knowledg discoveri v1 n3 p317328 1997 j mitran j mata e bourennan paindavoin j duboi automat hardwar implement tool discret adaboostbas decis algorithm eurasip journal appli signal process v2005 n1 p10351046 1 januari 2005 charl x ling hangdong wang comput optim attribut weight set nearest neighboralgorithm artifici intellig review v11 n15 p255272 feb 1997 tam horvth stefan wrobel uta bohnebeck relat instancebas learn list term machin learn v43 n12 p5380 aprilmay 2001 niloofar arshadi igor jurisica data mine casebas reason highdimension biolog domain ieee transact knowledg data engin v17 n8 p11271137 august 2005 melodi kiang compar assess classif method decis support system v35 n4 p441454 juli jo ranilla oscar luac antonio bahamond heurist learn decis tree prune classif rule ai commun v16 n2 p7187 katharina morik peter brockhausen multistrategi approach relat knowledg discoveri indatabas machin learn v27 n3 p287312 june 1997 jo ranilla oscar luac antonio bahamond heurist learn decis tree prune classif rule ai commun v16 n2 p7187 april jinyan li guozhu dong kotagiri ramamohanarao limsoon wong deep new instancebas lazi discoveri classif system machin learn v54 n2 p99124 februari 2004 randal wilson toni r martinez reduct techniqu instancebasedlearn algorithm machin learn v38 n3 p257286 march 2000 francisco azuaj werner dubitzki norman black kenni adamson retriev strategi casebas reason categoris bibliographi knowledg engin review v15 n4 p371379 decemb 2000 foster provost venkateswarlu kolluri data mine task method scalabl handbook data mine knowledg discoveri oxford univers press inc new york ny 2002 dietrich wettschereck david w aha takao mohri review empir evalu featur weight method aclass lazi learn algorithm artifici intellig review v11 n15 p273314 feb 1997 vassili g kaburlaso ioanni n athanasiadi pericl mitka fuzzi lattic reason flr classifi applic ambient ozon estim intern journal approxim reason v45 n1 p152188 may 2007 foster provost venkateswarlu kolluri survey method scale induct algorithm data mine knowledg discoveri v3 n2 p131169 june 1999