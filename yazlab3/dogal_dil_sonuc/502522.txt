data mine criteria treebas regress classif paper concern construct regress classif tree adapt data mine applic convent tree end propos new split criteria grow tree convent split criteria attempt perform well side split attempt compromis qualiti fit left right side contrast adopt data mine point view propos criteria search interest subset data oppos model data equal well new criteria split base compromis left right bucket effect pick interest bucket ignor othera expect result often simpler character interest subset data less expect new criteria often yield whole tree provid interpret data descript surprisingli flaw work advantag new criteria increas tendenc accept split near boundari predictor rang socal endcut problem lead repeat peel small layer data result unbalanc highli express interpret tree b introduct tree method appli two kind predict problem regress tree use predict continu respons classif tree use predict class label goal tree method partit data small bucket respons valu regress tree class label classif tree well predict subset figur 1 show partit regress tree left panel classif tree right panel left panel data partit two subset order explain respons vertic axi best possibl mean subset right panel data partit two subset order explain class label 123 best possibl andrea buja technolog consult att lab research 180 park ave po box 971 florham park nj 079320971 andreasresearchattcom httpwwwresearchattcomandrea yungseop lee graduat student depart statist rutger univers hill center mathemat scienc busch campu piscataway nj 08855 regress tree x classif tree x class figur 1 partit regress classif tree 11 structur tree data repeatedli partit even smaller subset mean binari split thu tree describ diagram figur 2 node repres subset data pair daughter node repres binari split subset correspond parent node2 b figur 2 two predictor exampl standard tree partit data binari split along predictor variabl two daughter subset parent subset obtain split fix valu fix threshold exampl x goe left daughter x 1 1 goe right daughter figur 2 illustr tree repeat split x 1 respect 1 x 2 respect 2 x 1 respect 3 geometri result partit illustr figur 2 b 12 tree construct greedi optim split one repeatedli search best possibl split subset search possibl threshold valu variabl optim accord impur measur discuss detail section 3 4 regress tree impur measur variant rss classif tree impur measur exampl misclassif rate entropi gini index one stop split subset signific gain impur obtain subset form termin node leaf tree sinc cart breiman et al 1984 size tree somewhat complex one tend grow first overli larg tree prune back second stage reason greedi tree construct look ahead one step may henc miss success split line overgrow prune tree may therefor find optim tree grow alon 13 split criteria data mine tree grow strategi specifi defin measur impur split done defin measur impur left right bucket split combin two measur overal impur measur split convent split criteria left right combin weight sum two side effect one compromis left right bucket take size account new data mine criteria howev interest model data equal well rather content long find subset data interest therefor propos combin impur left right bucket split way split occur one bucket alon low impur regardless bucket low impur one bucket alon caus low valu impur measur split data mine criteria split need develop regress classif tree separ section 3 deal regress section 4 classif 2 data tree 21 grow tree recent tree method appli mani area data mine sometim even data suitabl tree method gener grow tree use depend predictor heterogen complex interact present depend heterogen complex multipl local structur handl tree method model handl singl promin structur strength tree detect interact effect advert name first tree method interact detect morgan sonquist 1963 chisquarebas aid hartigan 1975 predict accuraci tree suffer follow situat ffl regress tree may fail dose respons present term dose spons borrow biostatist refer gradual monoton depend opposit depend threshold effect ffl classif tree may fail optim decis boundari align way variabl axe henc split variabl abl make full use inform contain predictor interpret tree hand may suffer presenc highli correl predictor correl predictor substitut appear less random altern fact one predictor would suffic effect ad complex interpret data analyst even wors possibl mislead conclus separ distinct effect attribut predictor even though share effect due correl 22 exampl grow tree waveform data breiman et al 1984 p 49 134 exampl unsuit data tree grow data gener artifici 21dimension predictor three class whose distribut predictor space analyt describ follow number u ffl independ distribut accord uniform distribut 0 1 gaussian zero mean unit varianc respec tive three 21dimension vector h irrelev except fact form obliqu place triangl side length roughli 115 115 165 shape result pointcloud three sausag end link togeth reflect project onto first two princip compon shown figur 3 reason tree method success data optim classif boundari align coordin axe author mention p 55 geometri data immedi linear discrimin analysi outperform tree thu appli tree method blindli one perform preliminari exploratori analysi determin type classif procedur make best use avail inform data figur 3 distribut class waveform data 23 use tree two principl must balanc use tree grow algorithm accuraci predict 2 interpret predict problem one want grow tree produc accur classifi base train sampl gener well test sampl often one also want grow interpret tree tree whose node repres potenti use meaning subset interpret top tree usual valuabl part top node describ use condit gener step tree add new inequ descript node except see also help although essenti interpret top node tree tend statist less variabl lower level node 24 simplic interpret tree present work concern construct method favor interpret tree attempt find method search meaning node close top tree possibl emphas interpret node near top deemphas precis calibr tree depth predict stop criteria grow prune tree low prioriti purpos interpret data analyst alway ignor lower node tree grown deepli harmless long analyst interpret statist fluke lower node deemphas lower part tree may sacrific global accuraci predict remark simplic interpret tree order although literatur bia favor balanc tree balanc interpret differ concept exist type extrem unbalanc tree highli interpret name use variabl repeatedli cascad split see figur 4 exampl simplic tree stem fact node describ one two condit regardless tree depth tree fragment similar exampl appear often tree fit data exhibit dose respons exampl figur 4 appar mean valu node respons show monoton increas depend predictor x kind tree structur found data analyst may want consid linear addit model describ monoton depend direct way hand dose respons may present local case tree may still success descript data linear addit model illustr boston hous data new data mine criteria uncov local dose respons new criteria split sometim gener tree less balanc yet interpret convent balanc tree contradict preced consider show x 7x 4 figur 4 artifici exampl simpl interpret yet unbalanc tree 3 regress tree 31 convent criteria regress tree mention section 11 tree grown recurs split data base minim split criterion convent split criteria compromis impur left right bucket impur measur choic bucket simpli varianc compromis split criterion weight averag varianc function thereof left right bucket need notat mean varianc left right bucket denot r nr r nr compromis split deriv maximum likelihood estim combin gaussian model two bucket iid nl oe 2 l left bucket iid nr oe 2 r right bucket cart equal varianc assum necess assumpt give criteria equal nonequ varianc minim neg log likelihood model follow split criteria result equal varianc model cart crit lr nl nr n l oe 2 n l log l n r log oe 2 make precis sens convent criteria compromis left right bucket minim neg log likelihood straightforward anyway equal varianc case min l r oe gammalog likelihoodl oe l 2 pool varianc estim thu minim yield split minim neg log likelihood nonequ varianc case get min l oe l r oe r gammalog likelihoodl r 1log constant drop affect minim split 32 data mine criteria regress tree circumst convent criteria tree grow unabl immedi identifi singl interest bucket interest could mean bucket high mean valu respons high puriti term small varianc respons kind situat mind depict figur 5 left hand plot show respons subset small varianc right right hand plot subset extrem mean right plain cart criterion deal properli left hand situat assum equal varianc right hand situat cart find split middl around x 300 wherea may interest find small bucket extrem high mean right approach identifi pure bucket oe 2 small extrem bucket ex treme quickli possibl exampl ignor left bucket right side interest r small r high low thu compromis anymor left right bucket order gener type tree use two new criteria split x 55x 226 figur 5 exampl pure extrem bucket left around x200 find pure bucket small oe 2 right around x600 find extrem bucket larg mean criterion search one pure bucket earli possibl end rather use weight averag two varianc criterion crit minim criterion possibl split find split whose left right side singl bucket smallest varianc puriti note subsequ split highpur bucket ignor bucket candid split thu ignor bucket get chanc highpur bucket split later typic highpur bucket unlik split result tree grown criterion tend purpos unbalanc ffl new criterion 2 onesid extrem high low valu respons criterion search high mean respons variabl earli possibl dual criterion would search low mean criterion radic departur convent approach notion puriti never question far mean never thought split criteria although often greater interest varianc point view minim variancebas criterion circuit rout search interest mean mean criterion propos maxim larger mean left right bucket crit implicitli bucket smaller mean ignor maxim criterion possibl split find split whose left right side singl bucket highest mean point natur critic criteria may aris potenti excess greedi tree built criteria may miss import split variabl may instead captur spuriou group peripheri variabl rang thu exacerb socal end cut problem critic grain truth paint situat bleaker true import split variabl gener miss depend data hand whether convent newli propos criteria success criterion search onesid extrem exampl success extrem respons valu often found peripheri variabl rang reason monoton mani respons surfac end cut problem prefer cut near extrem variabl rang share treebuild strategi see breiman et al 1984 p313 noth peculiar new criteria second critic lack balanc tree construct criteria superfici one might expect balanc tree interpret unbalanc one defeat rational criteria concern unfound though show real data exampl case criteria succeed produc interpret tree due simpl rational underli final recal present goal devis method produc superior fit method enhanc interpret therefor concern usual problem tune treedepth fit stop prune strategi cours interpret tree user simpli ignor lower level node longer interpret 4 classif tree 41 convent criteria classif tree consid twoclass situat class label denot 0 1 given split left right bucket let p 0 probabl 0 1 left right respect convent loss impur notion bucket ffl misclassif rate left bucket minp 0 breiman et al 1984 p98 implicitli one assign class bucket major vote estim misclassif rate proport class ffl entropi inform gammap 0 l probabl estim rel frequenc denot abus notat entropi also interpret mingammalog likelihoodn l multinomi model left bucket nl size left bucket breiman et al 1984 p103 ffl gini index p 0 l term estim essenti mean squar fit mean n 2 f0 1g n 2 l short calcul show l number 0s n 1 l number 1s left bucket020600 05 10 misclassif gini index figur impur function bucket left right misclassif rate entropi gini index function p 0 l exampl impur criteria bucket convent blend impur criteria split form weight sum left right bucket thu compromis left right denot pl margin probabl left right bucket compromis take follow form misclassif rate entropi r log r log gini index impur function bucket depict figur 6 sever desir properti given node take maximum valu class equal proport minimum valu bucket member class also function symmetr henc two class treat equal assum equal prior among three impur function misclassif rate problemat may lead mani indistinguish split may intuit prefer other problem illustr exampl breiman et al 1984 p96 gener reason linear misclassif rate either half unit intervalse left plot figur 6 linear impli data shift within limit left right bucket without chang combin misclassif rate split follow consider give idea larg number potenti split equival misclassif rate consid misclassif count nlminp 0 rate train data estim probabl rel frequenc denot n l l n l r count minor class loser left right correspondingli n w l n w r count major class winner left right l r n w r 1 l 6 w 2 f0 1g note r 2 misclassif count l r n w r count left right bucket respect r n w r 3 count parent bucket fix valu misclassif count exist mani combin n l r satisfi condit 1 2 3 exampl fix exist larg number combin gener exist combin fix n amount 1281 possibl fix n maximum number combin n attain misclassif count figur 7 show number combin function missclassif count number combin parent bucket size 100 figur 7 number combin misclassif count fix n100 consider suggest misclassif rate use split criterion suffer consider nonuniqu minim split consid two exampl equival split howev one observ quickli one two split usual prefer reason misclassif rate exampl among two equival split result combin n l respect latter clearli prefer provid one larg bucket r complet pure root problem piecewis linear misclassif rate minp 0 r right bucket therefor need impur function acceler toward zero decreas faster linearli proport domin class bucket move closer 1 rational use concav impur function entropi gini index cart breiman et al 1984 salford system 1995 use gini index c45 quinlan 1993 splu venabl ripley 1994 use entropi twoclass case seem exist clear differ perform entropi gini index multiclass case howev recent work breiman 1996 brought light differ gini entropi criterion gini index tend assign major class one pure bucket exist rest class bucket tend form unbalanc well distinguish bucket entropi hand tri balanc size two bucket accord breiman result defici entropi share gini index 42 data mine criteria classif tree mention section 32 approach tri identifi pure extrem bucket quickli possibl criteria regress tree base varianc mean one classif tree base probabl class 0 1 goal therefor restat search bucket one class probabl p 0 either left right bucket necessarili anoth approach select one two class 1 say look bucket pure class 1 exampl medic context one might want quickli find bucket show high rate mortal high rate treatment effect section 32 use two criteria split correspond two approach describ criterion search pure bucket regardless class earli possibl crit equival crit minp 0 exampl monoton transform criteria also equival crit b one p 0 l maximum minimum latter criterion express idea pure bucket directli ffl new criterion 2 onesid extrem chosen class 1 class interest criterion search pure class 1 bucket among l r crit ident crit p 0 l exampl note criteria direct analog new data mine criteria gression shown follow tabl regress tree classif tree onesid puriti mino 2 onesid extrem max 5 endcut problem high variabl small bucket lead chanc capit breiman et al p313 ff optim split take advantag randomli occur puriti small bucket implic split method lead extrem unbalanc split problem even greater data mine criteria look bucket individu without combin sizeweight averag cart usual cart criterion small bucket higher variabl downweight accord size illustr endcut problem simul simpl case unstructur regress data case theoret examin breiman et al 1984 theoret cut equal merit empir endcut prefer finit sampl emerg known figur merit simul necessari theoret consider cart criterion carri new data mine criteria thu gener set 200 observ gaussian distribut zero mean unit varianc comput split bucket size 5 cart criterion rssl r new onesid puriti criterion mino l oe r comput optim split locat criteria scheme repeat 10000 time optim split locat talli histogram first histogram figur 8 show frequenc split locat minimum cart criterion second histogram show onesid puriti criterion two figur show extent criteria prefer cut locat closer either extrem clearli effect pronounc onesid puriti criterion criteria requir measur counteract effect onesid puriti criterion split locat minimum total rss data mine criterion 1 split locat minimum puriti criterion figur 8 illustr endcut problem approach solv endcut problem penal bucket small size criterion penalti term make small bucket less viabl penal best understood criterion interpret neg log likelihood suitabl model case literatur offer larg number addit penalti term c p mallow c p statist aic akaik inform criterion bic schwarz bayesian inform criterion mdl minimum descript length criterion among other present paper work aic bic criteria reason popular aic penalti add effect number estim paramet neg log likelihood wherea bic add number estim paramet multipli logn2 appli penalti individu bucket obtain constant gaussian multinomi model underli regress classif tree model log likelihood aic bic regress gaussian nlog classif multinomi n entropi stage rais import point intend use aic bic penalti convent penalti use model select context one appli multipl model fix dataset unconvent situat howev appli one fix model multipl dataset name variables nr nl bucket data part larger dataset ensu problem log likelihood compar across differ bucket size log likelihood unbias estim bucket size time diverg model respect actual distribut therefor compar across bucket size gain one use averag log likelihood unbias estim diverg across bucket size log p z log p xdqx rest section n denot gener sampl size bucket size order avoid subscript nl nr consequ penal averag log likelihood penalti term also divid bucket size model ave log likelihood 1 regress gaussian 1log classif multinomi entropi penalti term 2 n log n n 1log n n monoton decreas n 3 converg zero n 1 behavior obviou requir addit penalti penal valu associ bic bigger associ aic except small bucket illustr figur 9 unfortun even though approach produc intuit pleas penalti perform experi somewhat disappoint expect howev approach perform better recent result jianm ye 1998 taken account light ye insight plausibl penalti number paramet model replac ye gener degre freedom gdf take consider fact extens search implicitli consum degre freedom gdf tend consider higher convent df exampl follow section counteract endcut problem impos minimum bucket size roughli 5 overal sampl size 6 exampl regress tree boston hous data follow breiman et al 1984 demonstr applic new data mine criteria boston hous data wellknown data origin bucket size penal valu aic penalti bic penalti figur 9 plot 1 1log n except small size n creat harrison rubinfeld 1978 also exploit belsley kuh welsch 1980 quinlan 1993 harrison rubinfeld main interest data investig air pollut concentr nox affect valu singl famili home suburb boston although nox turn minor factor data frequent use demonstr new regress method boston hous data avail uc irvin machin learn repositori httpwwwicsuciedumlearnmlrepositoryhtml data contain median hous valu respons 13 predictor variabl 506 censu tract boston area predictor display tabl 1 61 comparison criteria regress tree construct sever tree base cart new data mine cri teria facilit comparison tree gener equal size name termin node minimum bucket size 23 chosen 5 overal sampl size 506 prune appli interest interpret oppos predict result display figur 10 variabl descript crim crime rate zn proport residenti land zone lot 25000 sq ft indu proport nonretail busi acr cha charl river dummi variabl 1 tract bound river 0 otherwis nox nitric oxid concentr pphm rm averag number room per dwell age proport owneroccupi unit built prior 1940 di weight distanc five boston employ center rad index access radial highway tax fullvalu properti tax rate per 10000 ptratio pupil teacher ratio proport black lstat percent lower statu popul respons median valu owner occupi home 1000 tabl 1 predictor variabl boston hous data 15 summar tabl 2 figur mean respons size sz given node perus six tree summari sequenc worthwhil return cart tree figur 10 begin appli lesson extrem mean tree last two figur 14 15 recogn cart tree rm domin variabl particular rm 7 indic monoton depend rm larg valu rm rm 7 lstat take learnt high mean tree rm 7 exist monoton decreas depend lstat cart tree tri tell stori prejudic favor balanc split incap success layer data accord ascend valu lstat split lstat second level divid bucket size 51 34 left bucket divid lstat comparison high mean criterion creat level 3 split lstat bucket size 9 77 clearli indic left bucket first half dozen tree ring ascend order lstat descend order hous price summari appear us least interpret tree first two correspond cart criterion separatevari criterion although 08 highest among six tree greater interpret gain onesid puriti criterion partli due fact success peel mani small bucket result less balanc yet tell tree greatest lstat536 b3804 crim748 57 89 m21 47 m24 87 67 49 65 m21 47 45 m17 87 m15 71 55 81 m35 45 45 m45 59 m23 sz1000 850 m23 510 m25 281 m24 134 m21 m15 340 m17 204 m16 158 136 m37 150 91 boston hous pool varianc model cart figur 10 boston hous data tree 1 cart criterion dis336 rm706 age932 47 m220 105 m260 85 57 m340 45 61 m230 81 m200 57 m210 71 59 m200 55 m170 45 81 m140 51 m120 49 99 47 sz1000 401 340 190 103 599 269 m200 130 330 101 148 m110 97 boston hous separ varianc model figur 11 boston hous data tree 2 separ varianc criterion age221 51 m27 146 53 m34 45 m46 53 61 51 61 55 m11 53 47 67 47 71 45 m17 89 m23 sz1000 m23 911 m24 866 m25 747 411 m31 m28 296 m27 200 285 m18 m17 156 m15 109 m16 boston hous raw onesid puriti figur 12 boston hous data tree 3 onesid puriti criterion m24 65 79 m23 61 55 m35 49 m28 49 m46 51 m21 67 89 49 85 m11 45 47 71 45 m17 89 m23 sz1000 m23 911 m24 866 m25 747 411 m24 206 m25 144 m35 206 154 m32 99 m18 269 138 m16 130 m16 boston hous data penal onesid puriti figur 13 boston hous data tree 4 penal onesid puriti criterion lstat622 m36 47 m27 87 m25 79 47 m21 57 59 m21 53 m21 55 85 m18 51 m18 57 m15 47 m16 45 m11 130 m33 45 m45 51 m23 sz1000 m21 949 m21 901 856 769 m18 690 m24 105 m17 585 m17 526 m16 m16 417 m15 281 m13 boston hous onesid extrem high figur 14 boston hous data tree 5 high mean criterion lstat141 ptratio202 m13 47 m23 63 m25 57 m24 47 49 59 m34 47 m41 89 73 m21 87 53 67 m17 77 m15 85 45 51 m23 sz1000 m23 949 m24 901 m24 856 m25 771 694 m27 626 m27 573 486 413 m31 m24 105 m34 196 m39 136 boston hous onesid extrem low figur 15 boston hous data tree 6 low mean criterion r cart pool varianc model somewhat balanc tree depth 6 major variabl rm 3x lstat 6x minor variabl appear nox crim b ptratio di indu split mostli expect direct mean termin node vari 4510 1020 tree 2 nl log r separ varianc model balanc tree cart tree depth 5 major variabl rm 4x lstat 3x minor variabl doesnt appear split expect direct mean termin node vari 4510 994 tree 3 mino 2 r data mine criterion 1 raw onesid puriti unbalanc tree depth 9 ptratio 1x appear top judg top import split small bucket size 9 appar cluster school district significantli wors pupiltoteach ratio joriti crimeinfest neighborhood peel next small bucket size 5 crim 1x nox make surprisingli 3 appear anc would made harrison rubinfeld happi third split top nox break 12 highli pollut area low bucket mean 16 compar 25 rest power variabl lstat 3x creat next power split bucket size 41 34 mean 19 respect notic ambigu role di 3x correl neg hous valu low valu lstat 1015 highstatu posit high valu lstat lowstatu high valu nox 052 pollut rm 2x play role highstatu neighborhood crime neighborhood peel earli singular area extrem low hous valu crim 1x split age 1x zn 1x irrelev due low meandiffer log oe 2 data mine criterion 2 penal onesid puriti aic qualit tree surprisingli similar previou one differ lower level tree penal seem affect split till tree mine criterion 3 onesid ex treme high mean search high respons valu creat unbalanc tree singl power split peel split small bucket one side repeat appear two variabl rm 2x level 1 3 lstat 8x howev tell power stori highest hous price bucket mean 45 averag size home measur rm 759 variabl mat ter rm 708 persist monoton decreas depend lstat take median hous valu 17 simpl interplay rm lstat lend strike interpret tree tell simpl convinc stori bottom crime crim 2x pollut nox 1x show remain smaller effect expect direct smaller effect di tax also seen halfway tree r data mine criterion 4 onesid ex treme low mean tree tell similar stori previou one greater precis achiev low hous valu criterion look first tree unbalanc first peel split crim 1x set asid 5 bucket crime infest neighborhood lowest hous valu around 10 second lowest mean bucket consist 5 censu tract low b 100 correspond 63sigma32 africanamerican popula tion due quadrat transform thereaft monoton decreas depend lstat take form six peel split follow monoton increas depend rm form five peel split two success dose respons effect essenti previou tree found revers order due peel high low hous valu tabl 2 result regress tree boston hous data interpret achiev onesid extrem mean criteria partli due extrem imbal interpret found exampl two side ffl bucket extrem high low mean near top tree bucket desir interpret describ extrem respons behavior term simpl claus find bucket exactli purpos extrem mean criteria boston hous data highmean criterion exampl immedi find bucket welloff area larg home rm 759 lowmean criterion comparison immedi find highcrim bucket crim 1579 cart also find area larg home second level find high crime bucket ffl dose respons effect monoton depend iter peel behavior data mine criteria allow detect gradual increas decreas respons function individu predictor iter peel predictor becom appar essenti peel layer form seri small dangl termin bucket henc form highli unbalanc tree cart comparison handicap regard favor balanc split data mine criteria last point iron impli greater endcut problem data mine criteria compar cart work favor convers cart endcut problem suffici strong allow clearli detect monoton depend highli unbalanc tree monoton depend detect plausibl switch tree model addit even linear model includ suitabl interact term interact term may necessari local monoton depend exampl tree gener low mean criterion might suggest linear model follow form 62 graphic diagnost regress tree although treebas method sens flexibl mani convent parametr method still necessari guard artifact best techniqu diagnos artifact missfit graphic contrast linear regress basic diagnost regress tree straightforward requir addit comput first cut may suffici graphic render effect split turn may achiev plot respons variabl predictor split point parent bucket one graphic differenti point two child bucket plot differ glyph color creat seri diagnost plot tree gener low mean criterion figur 16 show bucket ascend hous valu split ffl high crime area strongli africanamerican neighborhood ffl segment decreas fraction lower statu peopl ffl commun unfavor pupilteach ratio school ffl anoth segment decreas fraction lower statu peopl final ffl segment increas size home matter plot confirm split plausibl high crime factor depress hous valu exist cluster neighborhood whose pupilteach ratio clearli wors well separ major final monoton depend clearli visibl decreas percentag lower statu peopl increas number room also visibl outlier name desir area beacon hill back bay near boston downtown top hous valu yet limit size home 14 figur graphic view major split appli boston hous data use low mean criterion 7 exampl classif tree pima indian diabet demonstr applic new data mine criteria classif tree pima indian diabet data pima data short data origin own nation institut diabet digest kidney diseas avail uc irvin machin learn repositori httpwwwicsuciedumlearnmlrepositoryhtml class label pima data 1 diabet 0 otherwis 8 predictor variabl 768 patient femal least 21 year age pima indian heritag near phoenix az among 768 patient 268 test posit diabet class 1 detail data see document uc irvin repositori predictor variabl definit shown tabl 3 variabl descript prgn number time pregnant plasma plasma glucos concentr two hour oral glucos toler test bp diastol blood pressur mm hg thick tricep skin fold thick mm insulin two hour serum insulin uml bodi bodi mass index weight kgheight 2 diabet pedigre function age age year respons class variabl 1 diabet 0 otherwis tabl 3 predictor variabl pima indian diabet data use pima data construct four tree base cart new data mine criteria minimum bucket size 35 impos 5 overal sampl size 768 regress tree boston hous data sinc concern interpret use prune result tree shown figur 20 23 node proport p class size sz given tabl 4 5 summar tree tree summari becom clear plasma power predictor follow bodi particular third tree almost complet domin two variabl interleav appear tree suggest combin monoton depend studi care 0 diabet 50 100 150 200305070 plasma class 1 diabet figur 17 distribut two class pima diabet data bodi plasma fulli figur 17 show distribut two class plasmabodi plane switch anoth fit method natur describ monoton depend name nearestneighbor fit everi point estim condit class 1 probabl p 1 plasma bodi fraction class 1 sampl among 20 nearest neighbor term euclidean distanc plasmabodi coordin standard variabl unit varianc figur show sequenc plot data plasma bodi plane rendit p 1 plasma bodi term highlight slice increas sequenc six valu c plot make clear respons behavior quit complex first plot show slice best describ cut low valu bodi follow four slice veer 90 clockwis last slice best describ cut high valu plasma one featur worth note though third plot notic hole center highlight slice hole fill blob data fourth plot featur infer exist mild hump p 1 surfac center data summari function p 1 plasma bodi shape clockwis ascend spiral rule surfac hump middl obvious tree quit suboptim fit respons charac terist figur 19 show third tree figur 22 tri approxim surfac step function axesalign rectangular tile plasma plasma figur 18 pima indian diabet data bodi plasma highlight repres slice nearconst p 1 ffl valu p 1 slice increas left right top bottom open squar diabet class 0 figur 19 pima diabet data bodi plasma plain tile accord bucket tree figur 22 open squar diabet class 0 age28 plasma1051 pedigree026 insulin00000101p100000 132 p093007 70 p082018 49 p092008 49 p073027 66 p093007 60 p087013 51 p070030 48 p053047 66 p036064 72 p067033 86 p053047 59 p028072 79 p008092 48 p016084 64 p065035 sz1000 p079021 367 p097003 202 165 p087013 99 p066034 297 p059041 p069031 165 p079021 99 p037063 p027073 p039061 138 p013087 pima misclass error figur 20 pima indian diabet data tree 1 cart criterion plasma993 body252 plasma1662 pedigree02 age28 p095005 56 p100000 49 p084016 49 p091009 46 p089011 81 p086014 77 p092008 51 p072028 74 p071029 64 p071029 49 p046054 146 p076024 48 p028072 61 p025075 52 p019081 48 p008092 48 p065035 sz1000 p063037 944 p092008 99 845 p058042 799 p055045 719 642 p058042 546 p080020 125 421 p047053 305 p057043 p052048 195 p014086 96 pima onesid puriti misclass error figur 21 pima indian diabet data tree 2 onesid puriti plasma993 body252 thick28 plasma122 thick341 thick28 typic balanc tree depth 6 strongest variabl plasma 5x creat success split top bodi 3x next import variabl much less follow pedigre 3x age 2x class ratio termin bucket rang 100000 left 016084 right split right direct overal tree plausibl simpl interpret r data mine criterion 1 onesid pu riti extrem unbalanc tree depth 12 spite depth tree overal structur simpl tree move right layer high class 0 diabet shave con vers tree step left layer high class 1 diabet shave top tree domin bodi age pedigre play role lower part tree larg rest bucket get harder harder classifi tree 3 maxp 0 r data mine criterion 2 onesid ex treme high class 0 extrem unbalanc tree simpl structur criterion search layer high class 0 diabet tree keep step right order describ condit class 0 preval appear bodi plasma mat ter tree show sequenc interleav split two variabl indic combin monoton depend see investig behavior interpret tree success one tabl 4 result classif tree pima indian diabet data tree 4 maxp 1 r data mine criterion 2 onesid ex treme high class 1 anoth extrem unbalanc tree simpl structur criterion search layer high class 1 diabet caus tree step left order describ condit class 1 preval plasma 6x matter far follow prgn 2x tabl 5 result classif tree pima indian diabet data summari follow messag investig experi ffl tree grown interpret global measur good fit alway desir ffl hypergreedi data mine criteria give differ insight ffl highli unbalanc tree reveal monoton depend doserespons effect endcut problem turn virtu ffl realli understand data algorithm extens visual necessari follow topic would merit research assess endcut problem hurt help ffl extend new 2class criteria multiclass problem ffl develop sophist rule stop prune ffl increas accuraci limit 2step lookahead procedur new cri teria adopt suggest breiman 1996 r new look statist model regress diagnost technic note properti split criteria classif regress tree treebas model statist perspect knowledg discoveri databas data mine knowledg discoveri overview model select principl minimum descript length hedon price demand clean air cluster algorithm comment c p uci repositori machin learn data base httpwww problem analysi survey data propos estim dimens model cart supplementari modul sy tat xgobi interact data visual x window system modern appli statist splu measur correct effect data mine model select tr c45 program machin learn technic note simpl fast effect rule learner ctr xiaom huo seoung bum kim kwokleung tsui shuchun wang fbp frontierbas treeprun algorithm inform journal comput v18 n4 p494505 januari 2006 soon tee teoh kwanliu paintingclass interact construct visual explor decis tree proceed ninth acm sigkdd intern confer knowledg discoveri data mine august 2427 2003 washington dc owen carmichael martial hebert shapebas recognit wiri object ieee transact pattern analysi machin intellig v26 n12 p15371552 decemb 2004 vasili agg panagioti anagnost ebank predict use data mine method proceed 4th wsea intern confer artifici intellig knowledg engin data base p16 februari 1315 2005 salzburg austria