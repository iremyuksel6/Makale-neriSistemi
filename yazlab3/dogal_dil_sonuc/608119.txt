combin classifi meta decis tree paper introduc meta decis tree mdt novel method combin multipl classifi instead give predict mdt leav specifi classifi use obtain predict present algorithm learn mdt base c45 algorithm learn ordinari decis tree odt extens experiment evalu new algorithm perform twentyon data set combin classifi gener five learn algorithm two algorithm learn decis tree rule learn algorithm nearest neighbor algorithm naiv bay algorithm term perform stack mdt combin classifi better vote stack odt addit mdt much concis odt thu step toward comprehens combin multipl classifi mdt also perform better sever approach stack b introduct task construct ensembl classier 8 broken two subtask rst gener divers set baselevel classier baselevel classier gener issu combin predict aris sever approach gener baselevel classier possibl one approach gener classier appli dierent learn algorithm heterogen model represent singl data set see eg merz 14 anoth possibl appli singl learn algorithm dierent paramet set singl data set final method like bag 5 boost 9 gener multipl classi appli singl learn algorithm dierent version given data set two dierent method manipul data set use random sampl replac also call bootstrap sampl bag reweight misclassi train exampl boost techniqu combin predict obtain multipl baselevel classier cluster three combin framework vote use bag boost ing stack gener stack 22 cascad 10 vote baselevel classier give vote predict predict receiv vote nal predict stack learn algorithm use learn combin predict baselevel classier induc metalevel classier use obtain nal predict predict baselevel classier cascad iter process combin classier iter train data set extend predict obtain previou iter work present focus combin predict baselevel classier induc appli dierent learn algorithm singl data set adopt stack framework learn combin baselevel classier end introduc notion meta decis tree mdt propos algorithm learn evalu mdt comparison method combin classier meta decis tree mdt novel method combin multipl classier dierenc meta ordinari decis tree odt mdt leav specifi baselevel classier use instead predict class valu directli attribut use mdt deriv class probabl distribut predict baselevel classier given exampl develop mlc45 modic c45 17 induc meta decis tree mdt mlc45 describ section 3 perform mdt evalu collect twentyon data set mdt use combin classier gener baselevel learn algorithm two tree learn algorithm c45 17 ltree 11 rulelearn algorithm cn2 7 knearest neighbor knn algorithm 20 modic naiv bay algorithm 12 experi compar perform stack mdt perform stack odt also compar mdt two vote scheme two stack approach final compar mdt boost bag decis tree state art method construct ensembl classier section 4 report experiment methodolog result experiment result analyz discuss section 5 present work put context previou work combin multipl classier section 6 section 7 present conclus base empir evalu along direct work combin multipl classier paper focu combin multipl classier gener use dierent learn algorithm singl data set rst phase depict left hand side figur 1 set n baselevel classier gener appli learn algorithm 1 singl train data set l train set cn x new exampl cn cml figur 1 construct use ensembl classier left hand side gener baselevel classier appli n dierent learn algorithm singl train data set l right hand side classic new exampl x use baselevel classier c combin method cml assum baselevel classier c predict probabl distribut possibl class valu thu predict baselevel classier c appli exampl x probabl distribut vector set possibl class valu p c c jx denot probabl exampl x belong class c estim predict classier c class c j highest class probabl p c c j jx predict classier c classic new exampl x metalevel depict right hand side figur 1 first n predict fp c1 x p c2 baselevel classier c x gener obtain predict combin use combin method cml dierent combin method use dierent combin framework follow subsect combin framework vote stack present 21 vote vote framework combin classier predict baselevel classier combin accord static vote scheme chang train data set l vote scheme remain dierent train set set learn algorithm baselevel classier simplest vote scheme plural vote accord vote scheme baselevel classier cast vote predict exampl classi class collect vote renement plural vote algorithm case class probabl distribut predict baselevel classier 8 let p c x class probabl distribut predict baselevel classier c exampl x probabl distribut vector return baselevel classier sum obtain class probabl distribut metalevel vote classier predict class x class c j highest class probabl p cml 22 stack contrast vote cml static stack induc combin method cml metalevel train set base l addit baselevel classier cml induc use learn algorithm metalevel metalevel exampl construct predict baselevel classier exampl l correct classic latter combin intend combin predict baselevel classier induc entir train set l unseen exampl special care taken construct metalevel data set end crossvalid procedur present tabl 1 appli tabl 1 algorithm build metalevel data set use induc combin cml stack framework function build combinerl fa stratifi partitionl n let c ji classier obtain appli j l n l let cv ji class valu predict c ji exampl l let cd ji class distribut predict c ji exampl l endfor endfor appli aml lml order induc combin cml return cml endfunct first train set l partit disjoint set equal size partit strati sens set l roughli preserv class probabl distribut l order obtain baselevel predict unseen exampl learn algorithm j use train baselevel classier c ji train set l n l train classier c ji use obtain predict exampl l predict baselevel classier includ predict class valu cv ji well class probabl distribut cd ji use calcul metalevel attribut exampl l metalevel attribut calcul n learn algorithm join togeth set metalevel exampl set one part metalevel data set lml repeat procedur time set l obtain whole metalevel data set final learn algorithm aml appli order induc combin cml framework combin multipl classier use paper base combin methodolog describ 6 stack framework 22 two ap proach class valu predict baselevel classier use metalevel attribut therefor meta level attribut procedur use framework trivial return class valu predict baselevel classier approach use class probabl distribut predict baselevel classier addit predict class valu calcul set metalevel attribut metalevel attribut use studi discuss detail section 3 3 meta decis tree section rst introduc meta decis tree mdt discuss possibl set metalevel attribut use induc mdt final present algorithm induc mdt name mlc45 31 meta decis tree structur meta decis tree ident structur ordinari decis tree decis inner node speci test carri singl attribut valu outcom test branch lead appropri subtre leaf node mdt predict classier use classic exampl instead predict class valu exampl directli odt would dierenc ordinari meta decis tree illustr exampl present tabl 2 3 first predict baselevel classier tabl 2a obtain given data set includ predict class probabl distribut well class valu metalevel data set tabl 2b metalevel attribut c 1 c 2 class valu predict two baselevel classier c 1 c 2 given exampl two addit metalevel attribut conf 1 conf 2 measur condenc predict c 1 c 2 given exampl highest class probabl predict baselevel classier use measur predict condenc tabl 2 build metalevel data set predict baselevel classier b metalevel data set predict baselevel classier baselevel attribut x p c1 0jx p c1 1jx pred p c2 0jx p c2 1jx pred 0875 0125 0 0875 0125 0 b metalevel data set meta decis tree induc use metalevel data set given tabl 3a mdt interpret follow condenc conf 1 baselevel classier c 1 high c 1 use classifi exampl otherwis baselevel classier use ordinari decis tree induc use metalevel data set given tabl 3b much less comprehens despit fact ect rule choos among baselevel predict note mdt odt need predict baselevel classier order make predict tabl 3 dierenc ordinari meta decis tree meta decis tree induc metalevel data set mlc45 b odt induc metalevel data set c45 c mdt written logic program mdt induc conf1 0625 c2 conf1 0625 c1 b odt induc conf1 0625 conf1 0625 conf1 0625 1 conf1 0625 c mdt written logic program comprehens mdt tabl 3a entir due extend express mdt leav mdt odt tabl 3a b induc proposit data set odt induc pure proposit mdt rst order logic program equival mdt present tabl 3c predic combineconf 1 c 1 conf 2 c 2 c use combin predict baselevel classier c 1 c 2 class c accord valu attribut variabl conf 1 conf 2 claus program correspond one leaf node mdt includ nonproposit class valu assign rst second claus proposit framework possibl assign one class valu anoth way interpret meta decis tree meta decis tree select appropri classier given exampl domain consid subset exampl fall one leaf mdt identi subset data one baselevel classier perform better other thu mdt identifi subset rel area expertis baselevel classier area expertis baselevel classier rel sens predict perform area better compar perform baselevel classier dierent area expertis individu baselevel classier 15 subset data predict singl baselevel classier correct note process induc meta decis tree two type attribut use ordinari attribut use decis inner node mdt eg attribut conf 1 conf 2 exampl metalevel data set role attribut ident role attribut use induc ordinari decis tree class attribut eg c 1 c 2 hand use leaf node baselevel classier class attribut valu attribut predict baselevel classier thu class attribut assign leaf node mdt decid baselevel classier use predict induc odt combin classier class attribut use way ordinari attribut partit data set rel area expertis base valu ordinari metalevel attribut use induc mdt exist studi area expertis individu classier 15 origin baselevel attribut domain hand use use dierent set ordinari attribut induc mdt properti class probabl distribut predict baselevel classier ect certainti condenc predict howev origin baselevel attribut also use induc mdt detail two set metalevel attribut given follow subsect 32 metalevel attribut metalevel attribut calcul properti class probabl cdp distribut predict baselevel classier ect certainti condenc predict first maxprobx c highest class probabl ie probabl predict class predict baselevel classier c exampl x next entropyx c entropi class probabl distribut predict classier c exampl x final weightx c fraction train exampl use classier c estim class distribut exampl x decis tree weight exampl leaf node use classifi exampl rule weight exampl cover rule use classifi exampl properti use nearest neighbor naiv bay classier appli straightforward fashion entropi maximum probabl probabl distribut ect certainti classier predict class valu probabl distribut return highli spread maximum probabl low entropi high indic classier certain predict class valu hand probabl distribut return highli focus maximum probabl high entropi low thu indic classier certain predict class valu weight quanti reliabl predict class probabl distribut intuit weight correspond number train exampl use estim probabl distribut higher weight reliabl estim exampl mdt induc imag domain uci repositori 3 given tabl 4 leaf denot asterisk speci c45 classier use classifi exampl 1 maximum probabl class probabl distribut predict knn smaller 077 2 fraction exampl leaf tree use predict larger 04 exampl train set 3 entropi class distribut predict c45 less 014 sum knn classier condent predict 1 c45 classier tabl 4 meta decis tree induc imag domain use class distribut properti ordinari attribut knn maxprob 077147 c45 weight 000385 knn c45 weight 000385 c45 entropi 014144 c45 c45 entropi 014144 ltree condent predict 3 2 leaf recommend use c45 predict consist commonsens knowledg domain classier combin anoth set ordinari attribut use induc meta decis tree set origin domain baselevel attribut bla case rel area expertis baselevel classier describ term origin domain attribut exampl mdt tabl 5 tabl 5 meta decis tree induc imag domain use baselevel attribut ordinari attribut shortlinedensity5 0 shortlinedensity2 0 knn shortlinedensity2 0 ltree shortlinedensity5 0 shortlinedensity5 0111111 ltree shortlinedensity5 0111111 c45 leaf denot asterisk tabl 5 speci c45 use classifi exampl shortlinedensity5 valu larger 011 mdt base baselevel ordinari attribut provid new insight applic baselevel classier domain use howev human expert domain use interpret mdt induc use attribut interpret directli point view classier combin note anoth import properti mdt induc use cdp set metalevel attribut domain independ sens languag express meta decis tree use domain x set baselevel classier use mean mdt induc one domain use domain combin set baselevel classier although may perform well part due fact cdp set metalevel attribut domain independ depend set baselevel classier c howev odt built set metalevel attribut still domain depend two reason first use test class valu predict baselevel classier eg test root node odt tabl 3b second odt predict class valu clearli domain depend sum three reason domain independ mdt 1 cdp set metalevel attribut 2 use class attribut decis inner node 3 predict baselevel classier use instead predict class valu 33 mlc45 modic c45 learn mdt subsect present mlc45 1 algorithm learn mdt base quinlan c45 17 system induc odt mlc45 take input metalevel data set gener algorithm tabl 1 note data set consist ordinari class attribut four dierenc mlc45 c45 1 ordinari attribut use intern node 2 assign form class attribut made mlc45 leaf node oppos assign form class valu 3 goodnessofsplit intern node calcul dierent describ 4 mlc45 postprun induc mdt rest mlc45 algorithm ident origin c45 algorithm describ c45 mlc45 measur select attribut intern node patch use transform sourc code c45 mlc45 avail httpaiijssibernardmdt c45 greedi divid conquer algorithm build classic tree 17 step best split accord gain gain ratio criterion chosen set possibl split attribut accord criterion split chosen maxim decreas impur subset obtain split compar impur current subset exampl impur criterion base entropi class probabl distribut exampl current subset train exampl denot rel frequenc exampl belong class c gain criterion select split maxim decrement info measur mlc45 interest accuraci baselevel classier c c exampl ie proport exampl class equal class attribut c newli introduc measur use mlc45 dene accuracyc denot rel frequenc exampl correctli classi baselevel classier c vector accuraci probabl distribut properti element sum 1 entropi calcul reason replac entropi base measur accuraci base one c45 split process stop least one follow two criteria satis 1 accuraci one classier current subset 100 lead info ml 2 user dene minim number exampl achiev current subset case leaf node construct classier maxim accuraci predict leaf node mdt order compar mdt odt principl fashion also develop intermedi version c45 call ac45 induc odt use accuraci base info measur 4 experiment methodolog result main goal experi perform evalu perform meta decis tree especi comparison method combin classier vote stack ordinari decis tree well method construct ensembl classier boost bag also investig use dierent metalevel attribut mdt perform experi collect twentyon data set uci repositori machin learn databas domain theori 3 data set wide use compar studi remaind section rst describ classic error rate estim compar list baselevel metalevel learn algorithm use studi final describ measur divers baselevel classier use compar perform metalevel learn algorithm 41 estim compar classic error rate experi present classic error estim use 10fold strati cross valid cross valid repeat ten time use dierent random reorder exampl data set set reorder use experi pairwis comparison classic algorithm calcul rel improv pair ttest describ order evalu accuraci improv achiev given domain use classier c 1 compar use cla sier c 2 calcul rel improv 1 errorc 1 errorc 2 analysi present section 5 compar perform meta decis tree induc use cdp ordinari metalevel attribut approach c 1 thu refer combin induc mlc45 use cdp averag rel improv across domain calcul use geometr mean error reduct individu domain classic error c 1 c 2 averag ten run 10fold cross valid compar data set errorc 1 errorc 2 refer averag statist signic dierenc perform test use pair ttest exactli fold use c 1 c 2 signic level 95 right gure tabl result mean classier c 1 signicantli betterwors c 2 anoth aspect tree induct perform simplic induc decis tree experi present use size decis tree measur number intern leaf node measur simplic smaller tree simpler 42 baselevel algorithm five learn algorithm use baselevel experi two treelearn algorithm c45 17 ltree 11 rulelearn algorithm cn2 7 knearest neighbor knn algorithm 20 modic naiv bay algorithm 12 algorithm use default paramet set output baselevel classier exampl test set consist least two compon predict class class probabl distribut baselevel algorithm use studi calcul class probabl distribut classi exampl two knn naiv bay calcul weight exampl use classic see section 3 code three c45 cn2 adapt output class probabl distribut well weight exampl use classic classic error baselevel classier twentyon data set present tabl 7 appendix smallest overal classic error achiev use linear discrimin tree induc ltree howev dierent data set dierent baselevel classier achiev smallest classic error 43 metalevel algorithm metalevel evalu perform eleven dierent algorithm construct ensembl classier list nine make use exactli set baselevel classier induc algorithm previou section brief two perform stack odt use algorithm c45 ac45 see previou sec three perform stack mdt use algorithm mlc45 three dierent set metalevel attribut cdp bla cdpbla two vote scheme selectbest choos best baselevel classier scann perform stack nearest neighbor analyz depend among baselevel classier addit boost bag decis tree consid creat larger ensembl 200 tree use ordinari decis tree induc c45 combin baselevel classier use odt induc ac45 combin baselevel classier mdtcdp use meta decis tree induc mlc45 set class distribut properti cdp metalevel attribut mdtbla use mdt induc mlc45 set baselevel attribut bla metalevel attribut mdtcdpbla use mdt induc mlc45 union two altern set metalevel attribut cdp bla pvote simpl plural vote algorithm see section 21 cdvote renement plural vote algorithm case class probabl distribut predict baselevel classier see section 21 selectbest select baselevel classier perform best train set estim 10fold strati crossvalid equival build singl leaf mdt scann 14 perform stack correspod analysi nearest neighbour correspond analysi use deal highli correl predict baselevel classier scann transform origin set potenti highli correl metalevel attribut ie predict baselevel classier new smaller set uncorrel metalevel attribut nearest neighbor classier use classic new set metalevel attribut boost decis tree two hundr iter use boost decis tree induc use j48 2 c45 default paramet set pre post prune weka 21 data mine suit implement adaboost 9 boost method reweight train exampl bag decis tree two hundr iter decis tree use bag use j48 default set detail report perform method found appendix classic error found tabl 9 size ordinari meta decis tree induc dierent metalevel combin algorithm given tabl 8 final comparison classic error method mdtcdp term averag rel accuraci improv number signic win loss given tabl 10 summari detail report given tabl 6 44 divers baselevel classier empir studi perform 1 2 show classic error metalevel learn method well improv accuraci achiev use highli correl degre divers predict baselevel classier measur divers two classier use studi error correl smaller error correl greater divers baselevel classier 2 experi bag boost perform use weka data mine suit includ j48 java reimplement c45 dierenc j48 result c45 result neglig averag 001 maximum rel dierenc 4 correl dene 1 2 probabl classier make error denit error correl normal maximum valu lower two classic error altern denit error correl propos 11 use paper error correl dene condit probabl classier make error given one make error predict classier c c j given exampl x cx true class x error correl set multipl classier c dene averag pairwis error correl rel improv ltree baselevel degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific rel improv knn baselevel degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur 2 rel accuraci improv achiev mdt compar two baselevel classier ltree knn depend error correl among baselevel classier graph figur 2 conrm result meta decis tree rel accuraci improv achiev mdt ltree knn two baselevel classier highest overal accuraci decreas error correl baselevel cla sier increas linear regress line interpol point conrm trend show perform improv achiev mdt correl divers error baselevel classier tabl summari perform metalevel learn algorithm compar mdt induc use class distribut properti mdtcdp metalevel attribut averag rel accuraci improv number signic winsloss averag tree size applic detail tabl 10 8 appendix metalevel algorithm ave rel acc imp mdtbla 1447 80 6694 mdtcdpbla 1391 80 7373 selectbest 781 52 1 scann 1395 96 na boost 936 136 na bag 2226 104 na 5 analysi experiment result result experi summar tabl 6 brief follow main conclus drawn result 1 properti class probabl distribut predict baselevel cla sier cdp better metalevel attribut induc mdt baselevel attribut bla use bla addit cdp worsen perform 2 meta decis tree mdt induc use cdp outperform ordinari decis tree vote combin classier 3 mdt perform slightli better scann selectbest method 4 perform improv achiev mdt correl divers error baselevel classier higher divers better rel perform compar method 5 use mdt combin classier induc dierent learn algorithm outperform ensembl learn method base bag boost decis tree look claim experiment result detail 51 mdt dierent set metalevel attribut analyz depend mdt perform set ordinari metalevel attribut use induc use three set attribut properti class distribut predict baselevel classier cdp origin baselevel domain attribut bla union cdpbla averag rel improv achiev mdt induc use cdp mdt induc use bla cdpbla 14 cdp signicantli better 8 domain see tabl 6 tabl 10 appendix mdt induc use cdp time smaller averag mdt induc use bla cdpbla see tabl 8 result show cdp set metalevel attribut better bla set furthermor use bla addit cdp decreas perform remaind section consid mdt induc use cdp analysi result ordinari decis tree induc use cdp bla cdpbla result cdp actual present paper show claim hold also odt result especi import highlight import use class probabl distribut predict baselevel classier identifi rel area expertis far baselevel attribut origin domain typic use identifi area expertis baselevel classier 52 meta decis tree vs ordinari decis tree compar combin classier mdt odt rst look rel improv use mlc45 cc45 see tabl 6 column cc45 tabl 10 appendix left hand side figur 3 perform signicantli better 15 signicantli wors 2 data set 4 overal decreas accuraci geometr mean entir due result tictacto domain combin method perform well exclud tictacto domain 7 overal rel increas obtain thu say mlc45 perform slightli better term accuraci howev mdt much smaller size reduct factor 16 see tabl 8 despit fact odt induc c45 postprun mdt rel improv tictacto balanc breastw hypothyroid soya heart imag vote hepat glass echocardiogram waveform iri german australian chess diabet car bridgestd wine ionospher avg insignific signific rel improv iri bridgestd imag heart soya waveform vote breastw hepat german balanc diabet echocardiogram glass ionospher australian hypothyroid chess wine car tictacto avg insignific signific figur 3 rel improv accuraci use mdt induc mlc45 compar accuraci odt induc ac45 c45 get clearer pictur perform dierenc due extend express power mdt leav compar odt leav compar mlc45 cac45 see tabl 6 column cac45 tabl 10 right hand side figur 3 mlc45 ac45 use learn algorithm dierenc type tree induc mlc45 induc meta decis tree ac45 induc ordinari one comparison clearli show mdt outperform odt combin classier overal rel accuraci improv 8 mlc45 signicantli better cac45 12 21 data set signicantli wors one ionospher consid also graph right hand side figur 3 mdt perform better odt two domain perform gain much larger loss furthermor mdt averag 34 time smaller odt induc ac45 see tabl 8 reduct tree size improv comprehens meta decis tree exampl abl interpret comment mdt tabl 4 sum meta decis tree perform better ordinari decis tree combin classier mdt accur much concis comparison mlc45 ac45 show perform improv due extend express power mdt leav 53 meta decis tree vs vote combin classier mdt signicantli better plural vote 10 domain signicantli wors 6 howev signic improv much higher signic drop accuraci give overal accuraci improv 22 sinc perform slightli better plural vote smaller overal improv 20 achiev mdt mlc45 signicantli better 10 data set signicantli wors 5 result show mdt outperform vote scheme combin classier see tabl 6 tabl 10 appendix 04 rel improv degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific 04 rel improv degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur 4 rel improv accuraci mdt two vote scheme depend degre error correl baselevel classier explor depend accuraci improv mdt vote divers baselevel classier graph figur 4 show mdt make better use divers error baselevel classier vote scheme name domain low error correl therefor higher divers baselevel classier rel improv mdt vote scheme higher howev slope linear regress line smaller one improv baselevel classier still trend clearli show mdt make better use error divers baselevel predict vote 54 meta decis tree vs selectbest combin classier mdt signicantli better selectbest 5 domain signicantli wors 2 give overal accuraci improv almost 8 see tabl 6 tabl appendix rel improv selectbest degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur 5 rel improv accuraci mdt selectbest method depend degre error correl baselevel classier result depend analysi accuraci improv mdt select best divers baselevel classier given figur 5 mdt make slightli better use divers error baselevel classier selectbest slope linear regress line smaller one improv vote method 55 meta decis tree vs scann combin classier mdt signicantli better scann 9 domain signicantli wors 6 see tabl 6 tabl 10 appendix howev signic improv much higher signic drop accuraci give overal accuraci improv almost 14 result show mdt outperform scann method combin classier 04 rel improv degre error correl baselevel classifi australian balanc breastw bridgestd car chess diabet echocardiogram german glass heart hepat hypothyroid imag ionospher iri soya tictacto vote waveform wine insignific signific figur rel improv accuraci mdt scann method depend degre error correl baselevel classier explor depend accuraci improv mdt scann divers baselevel classier graph figur 6 show mdt make slightli better use divers error baselevel classier scann slope linear regress line smaller one improv vote method 56 meta decis tree vs boost bag final compar perform mdt perform two state art ensembl learn method bag boost decis tree perform signicantli better boost 13 signicantli better bag 10 21 data set mlc45 perform signicantli wors boost 6 domain signicantli wors bag 4 domain overal rel improv perform 9 boost 22 bag see tabl 6 tabl appendix clear mdt outperform bag boost decis tree comparison fair sens mdt use baselevel classier induc decis tree four learn method boost bag use decis tree baselevel learn algorithm howev show approach construct ensembl classier competit exist state art approach 6 relat work overview method construct ensembl classier found 8 sever metalevel learn studi close relat work let us rst mention studi use scann 14 combin baselevel classier mention scann perform stack use correspond analysi classic baselevel classier author show scann outperform plural vote scheme also case baselevel classier highli correl scann use class probabl distribut properti predict baselevel classier although possibl extend method direct mention therefor comparison cd vote scheme includ studi studi show mdt use cdp attribut slightli better scann term perform also concept induc scann metalevel directli interpret use identifi rel area expertis baselevel classier cascad baselevel classier induc use exampl current node decis tree step divid conquer algorithm build decis tree new attribut base class probabl distribut predict baselevel classier gener ad set origin attribut domain baselevel classier use studi naiv bay linear discrimin integr two baselevel classier within decis tree much tighter combiningstack framework similar approach class probabl distribut use version stack gener use class probabl distribut predict baselevel classier implement data mine suit weka 21 howev class probabl distribut use directli properti maxim probabl entropi make domain depend sens discuss section 3 indirect use class probabl distribut properti make mdt domain independ ordinari decis tree alreadi use combin multipl classier 6 howev emphasi studi partit techniqu massiv data set combin multipl classier train dierent subset massiv data set studi focus combin multipl classier gener data set therefor obtain result directli compar combin classier identifi area expertis alreadi explor 15 13 studi descript area expertis form ordinari decis tree call arbit induc individu baselevel classier singl data set mani arbit need baselevel classier combin multipl classier vote scheme use combin decis arbit howev singl mdt identifi rel area expertis baselevel classier much comprehens anoth improv present studi possibl use certainti condenc baselevel predict identifi classier expertis area origin baselevel attribut data set present studi also relat previou work topic metalevel learn 18 introduc induct logic program 16 ilp framework learn relat data set characterist perform dierent base level classier express nonproposit formul use repres metalevel exampl data set characterist eg properti individu attribut induc metalevel concept also nonproposit mdt leav express odt leav languag mdt still much less express languag logic program use ilp 7 conclus work present new techniqu combin classier base meta decis tree mdt mdt make languag decis tree suitabl combin classier select appropri baselevel classier given exampl leaf mdt repres part data set rel area expertis baselevel classier leaf rel area expertis identi basi valu origin baselevel attribut bla data set also basi properti class probabl distribut cdp predict baselevel classier latter ect certainti condenc class valu predict individu baselevel classier extens empir evalu show mdt induc cdp perform much better much concis mdt induc bla due extend express mdt leav also outperform ordinari decis tree odt term accuraci concis mdt usual small easili interpret regard step toward comprehens model combin cla sier explicitli identifi rel area expertis contrast exist work use nonsymbol learn method eg neural network combin classier 14 mdt use divers baselevel classier better vote outperform vote scheme term accuraci especi domain high divers error made baselevel classier mdt also perform slightli better scann method combin classier selectbest method simpli take best singl classier final mdt induc cdp perform better boost bag decis tree thu competit state art method learn ensembl mdt built use cdp domain independ principl transfer across domain x set baselevel learn algorithm sens mdt built one data set use data set sinc use set attribut sever potenti benet domain independ mdt first machin learn expert use mdt domain independ analysi rel area expertis dierent baselevel classier without knowledg particular domain use furthermor mdt induc one data set use combin classier induc set baselevel learn algorithm data set final mdt induc use data set contain exampl origin dierent domain explor option alreadi give us topic work combin data dierent domain learn mdt especi interest avenu work would bring togeth present studi metalevel learn work select appropri classier given domain 4 case attribut describ individu data set properti ad class distribut properti metalevel learn data set preliminari investig along line alreadi made 19 sever obviou direct work ordinari decis tree alreadi known postprun give better result preprun preliminari experi show preprun degrad classic accuraci mdt thu one prioriti work develop postprun method meta decis tree implement mlc45 interest aspect work use classdistribut properti metalevel learn work combin classier use predict class correspond probabl distribut would interest use learn algorithm neural network bayesian classic scann combin classier base probabl distribut return comparison combin cla sier use class predict vs class predict along class probabl distribut would also worthwhil consist meta decis tree common sens classier combin knowledg brie discuss section 3 open anoth question research process induc metalevel classier bias produc metalevel classier consist exist knowledg achiev use strong languag bia within mlc45 probabl easili within framework meta decis rule rule templat could use acknowledg work report support part slovenian ministri educ scienc sport eufund project data mine decis support busi competit european virtual enterpris ist199911495 thank joao gama mani insight inspir discuss combin multipl classier mani thank marko bohanec thoma dietterich nada lavrac three anonym review comment earlier version manuscript r explain degre error reduct due combin multipl decis tree reduct learn multipl descript uci repositori machin learn databas analysi result bag predictor accuraci metalearn scalabl data mine rule induct cn2 recent improv experi new boost algorithm combin classi discrimin tree linearbay classi er integr multipl classi use correspond analysi combin classi exploit multipl exist model learn algorithm learn logic de studi distancebas machin learn algorithm data mine practic machin learn tool techniqu java implement stack gener tr ctr michael gamon sentiment classif custom feedback data noisi data larg featur vector role linguist analysi proceed 20th intern confer comput linguist p841e august 2327 2004 geneva switzerland saso deroski bernard enko combin classifi stack better select best one machin learn v54 n3 p255273 march 2004 efstathio stamatato gerhard widmer automat identif music perform learn ensembl artifici intellig v165 n1 p3756 june 2005 christoph giraudcarri ricardo vilalta pavel brazdil introduct special issu metalearn machin learn v54 n3 p187193 march 2004 joo gama function tree machin learn v55 n3 p219250 june 2004 pavel b brazdil carlo soar joaquim pinto da costa rank learn algorithm use ibl metalearn accuraci time result machin learn v50 n3 p251277 march nicol garcapedraja domingo ortizboy cooper construct method neural network pattern recognit pattern recognit v40 n1 p8098 januari 2007 b kotsianti zaharaki p e pintela machin learn review classif combin techniqu artifici intellig review v26 n3 p159190 novemb 2006