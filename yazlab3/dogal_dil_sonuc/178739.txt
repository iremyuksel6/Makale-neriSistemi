extract refin rule knowledgebas neural network neural network despit empir proven abil littl use refin exist knowledg task requir threestep process first knowledg must insert neural network second network must refin third refin knowledg must extract network previous describ method first step process standard neural learn techniqu accomplish second step articl propos empir evalu method final possibl difficult step method effici extract symbol rule train neural network four major result empir test method extract rule 1 close reproduc accuraci network extractedsemi 2 superior rule produc method directli refin symbol rulessemi superior produc previou techniqu extract rule train neural networkssemi human comprehens thu method demonstr neural network use effect refin symbol knowledg moreov ruleextract techniqu develop herein contribut understand symbol connectionist approach artifici intellig profit integr b introduct artifici neural network ann proven power gener techniqu machin learn fisher mckusick 1989 shavlik et al 1991 howev ann sever wellknown shortcom perhap signific train ann essenti black box determin exactli ann make particular decis daunt task signific shortcom without abil produc understand decis hard confid reliabl network address realworld problem also fruit train neural network difficult transfer neural network pratt et al 1991 amelior problem imposs directli transfer nonneur learn system henc train neural network analog pierr de fermat comment last theorem like fermat network tell discov someth wonder tell discov paper shed light neuralnetwork black box combin symbol rulebas reason neural learn approach form threelink chain illustr figur 1 symbol knowledg revis correct use neural network thu approach present make possibl use neural network empir learn algorithm underli rulerefin system figur approxim first link threelink chain insert knowledg need neither complet correct neural network use kbann towel et al 1990 network creat use kbann refer knowledgebas neural network knn step chang represent rule symbol neurallybas therebi make rule refin standard neural learn method second link chain train knn use set classifi train exampl standard neural learn algorithm backpropag rumelhart et al 1986 method weight optim feedforward neural network rule upon knn base correct consist train exampl final link extract rule train knn extrem difficult task arbitrarilyconfigur network somewhat less daunt knn due properti stem initi comprehens take advantag properti develop method effici extract intellig rule network evalu two realworld test problem term abil correctli classifi exampl seen train method produc set rule close approxim network came moreov extract rule equal superior rule result rulerefin method act directli rule rather rerepresent neural network also show method superior previou algorithm extract rule gener neural network eg saito nakano 1988 fu 1991 next section contain brief overview method insert rule neural network subsequ section describ method best report method extract rule train knn section 4 5 present seri empir test ruleextract method section 4 use two realworld learn problem taken molecular biolog determin strength ruleextract method section 5 use artifici domain character close possibl use realworld domain abil ruleextract method final section paper relat approach other extract rule train neural network discuss futur research plan 2 kbann rulestonetwork translat kbann translat symbol knowledg neural network defin topolog connect weight network creat use knowledg base domainspecif infer rule repres proposit horn claus defin initi known topic detail explan procedur use kbann translat rule knn given towel et al 1990 towel 1991 provid brief summari procedur follow exampl consid sampl knowledg base figur 2a defin membership categori figur 2b repres hierarch structur rule solid dot line repres necessari prohibitori depend respect figur 2c repres knn result translat knowledg base neural network unit 1 x figur 2c introduc knn repres disjunct 1 unit basic process element neural network receiv realnumb signal unit weight connect refer link mathemat transform signal realnumb output sent unit see tabl 1 gener unit divid three categori input receiv signal environ output send signal environ hidden connect environ rule set otherwis unit knn correspond consequ anteced knowledg base thick line figur 2c repres heavilyweight link knn correspond depend knowledg base thin line repres link ad network allow addit refin knowledg base figur approxim exampl illustr use procedur initi knn two princip benefit first algorithm indic input featur believ import exampl classif second specifi import deriv featur eg b c figur 2 therebi guid choic number connect hidden unit knn 3 rule extract section present detail explan approach previous report approach extract rule train knn first algorithm present comparison second algorithm introduc section 34 focu work 31 assumpt rule extract method present make two assumpt train network first assumpt underli method extract rule train neural network unit either maxim activ ie activ near one inact ie activ near zero 2 assumpt particularli restrict commonlyus logist activ function slightli modifi ensur unit approxim step function make assumpt noninput unit train knn interpret step function boolean rule therefor rule extract problem determin situat rule true second assumpt train significantli alter mean unit make assumpt method abl attach label extract 2 except gener includ method propos bochereau bourgin 1990 method extract fuzzi rule eg berenji 1991 w ij 2 activ unit w ij weight link unit j unit bia unit paramet affect slope sigmoid except explicitli state tabl 1 logist activ function use backpropag rule correspond consequ symbol knowledg upon knn base therebi enhanc comprehens rule examin train network indic mean usual quit stabl although sutton 1986 suggest assumpt may gener true 32 common method introduc extract rule neural network well previous describ eg saito nakano 1988 fu 1991 tri find combin input valu unit result activ near one henc section describ mathemat underli neural network use unit backpropagationtrain neural network normal activ defin equat 1 2 tabl 1 rephras equat 1 activ unit function sum weight input unit less bia broadli speak result equat 2 sum weight input exceed bia activ unit near one otherwis activ near zero henc ruleextract method search constraint input set weight sum guarante exceed bia first assumpt unit train network activ near zero one simplifi search ensur link carri signal equal weight signal result equat 1 simplifi equat 3 state ruleextract method need concern weight link enter unit reduc rule extract search unit set incom link whose sum weight exce guarante unit bia exceed regardless activ carri incom link rule extract simplifi equat 2 guarante noninput unit alway nonneg activ problem investig input unit alway activ f0 1g therefor negativelyweight link give rise negat anteced positivelyweight link give rise nonneg anteced consider reduc size search space fu 1991 final note short exactli copi unit link way limit kind differ extract rule network reason complex extract rule may make error omiss commiss respect network error gener result cumul effect lowweight link appear extract rule one chief problem rule extract minim error without simpli rewrit network 33 subset algorithm first method rule extract describ fundament similar approach describ saito nakano 1988 well fu 1991 howev particular implement call gener approach subset method explicitli search subset incom weight exceed bia unit paper use subset algorithm straw man show effect new method rule extract present next section subset algorithm repres state art publish literatur simpl breadthfirst subset algorithm start determin whether set contain singl link suffici guarante bia exceed ye set rewritten rule search proce increas size subset possibl subset explor final algorithm remov subsum overlygener rule exampl given link weight bia shown figur 3a subset algorithm would initi find five rule elimin one subsum rule algorithm return four rule list figur 3b assum unit activ near zero one tabl 2 specif subset algorithm hidden output unit extract fi p subset positivelyweight incom link whose sum weight greater bia unit b subset p fi p subset found step 1 extract fi n minim subset negativelyweight link whose sum weight greater sum p less bia unit 2 let z new predic use nowher els 3 subset n fi n subset found step b1 form rule n z 4 form rule p z name unit figur 3 approxim major problem subset algorithm cost find subset grow size power set link unit henc approach expect exactli reproduc behavior simpl network work small problem avoid otherwis prohibit combinator implement subset algorithm use heurist instanc saito nakano 1988 establish ceil number anteced extract rule establish priori ceil number anteced sever shortcom ming instanc ceil one domain set accept tradeoff number extract rule differ extract rule network may accept anoth domain seriou problem occur properti problem studi suggest rule requir larg number anteced instanc initi rule one realworld domain studi indic smallest bound number anteced safe set could requir consid 10 5 set therefor rather set bound number anteced implement use branchandbound algorithm limit term number rule may find subset algorithm present pseudocod tabl 2 see fu 1991 complet descript subset algorithm briefli algorithm iter everi noninput unit train knn unit use branchandbound algorithm positivelyweight link find fi p posit subset whose sum weight exceed unit bia posit subset make new branchandbound search negativelyweight link find minim neg subset whose sum weight greater magnitud differ sum weight posit subset unit bia final algorithm form rule result consequ satisfi anteced posit subset true none neg subset associ posit subset contain anteced true neg subset suffici prevent node activ henc must ensur minim subset contain least one unsatisfi anteced algorithm may discov fi p 1 rule noninput unit network translat describ tradeoff number extract rule accur reproduct network behavior henc set fi p fi n find reasonablys set rule approxim network came set use result find 300 rule realworld domain studi gener accur reproduct knn requir mani rule subset extract larg set rule smaller mani handcraft expert system eg mcdermott 1982 henc subset deliv set rule least potenti tractabl howev rule tend hide signific structur train network instanc figur 3a link b c weight link e neg weight look problem way suggest rule figur 3b could rewritten follow rule provid much clearer statement condit 3 f b c noteg recogn structur share among sever conjunct rule led develop algorithm describ next focu paper 34 mofn method algorithm call mofn address combinatori present problem inher subset algorithm differ subset algorithm explicitli search rule form follow n anteced true suggest previous method aros notic rule set discov 9tabl 3 mofn approach rule extract 1 hidden output unit form group similarlyweight link 2 set link weight group member averag group 3 elimin group significantli affect whether unit activ inact 4 hold link weight constant optim bias hidden output unit use backpropag algorithm 5 form singl rule hidden output unit rule consist threshold given bia weight anteced specifi remain link 6 possibl simplifi rule elimin superflu weight threshold ere subset often contain mofn style concept support method come experi indic neural network good learn mofn concept 1989 well experi variant id3 show bia toward mofn style concept use murphi pazzani 1991 final note pure conjunct rule result set disjunct rule result use mofn rule restrict gener idea underli mofn abstract version appear tabl 3 individu anteced link uniqu import rather group anteced form equival class anteced import interchang member class equival class idea key mofn algorithm allow algorithm consid group link without worri particular link within group 341 mofn algorithm section contain detail descript ruleextract algorithm illustr algorithm exampl follow section step 1 cluster backpropag train tend group link knn loos cluster rather equival class assum mofn algorithm 3 henc first step mofn creat equival class cluster link use standard cluster method join algorithm hartigan 1975 method oper success combin two closest cluster start cluster hold singl link cluster stop pair cluster closer set distanc mofn use 025 step 2 averag group form second step algorithm set weight link group averag group weight thu first two step forc link network equival class requir rest algorithm step 3 elimin equival class place procedur next attempt identifi elimin group unlik bear calcul consequ group gener low link weight member elimin proce via two path one algorithm one heurist first elimin procedur algorithm attempt find cluster link effect whether total incom activ exce bia done calcul total possibl activ cluster send total possibl activ compar level activ reachabl given link weight network cluster chang whether net input exce bia elimin note procedur similar subset howev cluster link weight consider reduc combinator problem heurist elimin procedur base explicitli upon whether net input receiv cluster ever necessari correct classif train exampl procedur oper present train exampl cluster network sequenti zero input cluster result qualit chang activ unit receiv activ cluster cluster mark necessari cluster mark necessari elimin 3 nowlan hinton 1991 neuralnetwork train algorithm draw link weight cluster reduc elimin problem one futur research plan combin train algorithm knowledgeinsert ruleextract method step 4 optim unimport group elimin fourth step mofn optim bia unit step necessari first three step chang time unit activ result alter network may error rate significantli higher end train optim done freez weight link group stay intact retrain bias network use backpropag reflect rulelik natur network activ function slightli modifi moreclos resembl step function step 5 extract step mofn algorithm form rule exactli reexpress network rule creat directli translat bia incom weight unit rule weight anteced rule true sum weight anteced exce bia note equival class elimin group rule consider simpler origin train network fewer anteced anteced tend weight class step 6 simplifi sixth final step rule simplifi whenev possibl elimin weight threshold mofn simplifi rule scan determin possibl combin anteced exceed rule threshold ie bia scan may result one rule henc tradeoff simplif procedur complex individu rule complex result number syntact simpler rule exampl consid rule 4 simplif rewrit rule follow three rule 2 b c e 1 b c e 2 x z x z elimin weight bias requir rewrit singl rule five rule rule left origin state 4 function numbertru return number anteced follow set true 342 exampl mofn figur 4 illustr process singl unit seven incom link transform mofn procedur rule requir two three anteced true first two step group link two cluster one four link weight 11 one three link weight 61 third step algorithm elimin cluster weight 11 situat link affect unit fourth step bia optim unnecessari exampl averag elimin procedur significantli chang properti unit fifth sixth step simpl singl cluster remain henc final mofn written inspect figur approxim 343 complex analysi mofn complex mofn precis analyz biasoptim phase use backpropag note problem address bia optim consider simpler initi train network usual network order magnitud fewer link bia optim initi train moreov bias allow chang result step take reason short time 5 initi cluster requir ou theta l 2 time u number unit l averag number link receiv unit cluster elimin requir theta u theta l time n number train exampl step use ou theta l time 35 subset mofn summari ruleextract algorithm strength respect exampl individu rule return subset often easili understood return mofn howev subset gener mani rule repetit mofn rule set return mofn usual easier understand subset moreov measur time respect number link unit subset exponenti algorithm wherea mofn train simpl class neural network proven npcomplet judd 1988 hinton 1989 suggest practic backpropag usual run ou theta l 3 time approxim cubic final result present later paper indic rule set deriv mofn approxim equal accuraci network extract rule extract subset significantli wors next section contain seri empir test demonstr differ two algorithm 4 experi realworld dataset 41 dataset test efficaci ruleextract procedur realworld problem studi two problem domain molecular biolog use dataset member small collect realworld problem exist approximatelycorrect domain theori set classifi exampl also dataset previous studi theori revis literatur eg towel et al 1990 ourston mooney 1990 thompson et al 1991 noordewi et al 1991 make possibl comparison perform section 411 notat dataset special notat use simplifi specifi locat dna sequenc dna sequenc linear string nucleotid nucleotid drawn fa g cg idea number locat respect fix biologicallymeaning refer point neg number indic site preced left refer point posit number indic site follow refer point henc rule anteced refer input featur first state locat rel refer point sequenc vector dna nucleotid sequenc nucleotid must occur eg 3 biolog convent posit number zero use rule specif indic nucleotid suffic exampl first rule conform tabl 5 say must 45 nucleotid refer locat anoth must posit 44 two nucleotid appear final must locat 41 final use standard ambigu code given tabl 4 refer accept altern particular locat tabl 4 ambigu code dna nucleotid code mean code mean code mean c r g w c g c k g v c g h c g b c g x g c problem 1 promot recognit first problem investig prokaryot promot recognit origin describ towel et al 1990 promot short dna sequenc initi express gene basic promot site protein rna polymeras bind dna accord rule tabl 5 two site bind must occur minu 10 minu 35 region addit conform rule attempt captur twist dna helix therebi ensur bind site spatial align set rule deriv straightforward manner biolog literatur harley reynold 1987 hawley mcclure 1983 koudelka et al 1987 consensu sequenc promot consensu sequenc describ probabl nucleotid given locat howev nucleotid appear everi promot instanc minus10 rule probabl nucleotid 085 also rule deriv multipl sourc prune subsum rule extract rule strictli less gener other figur 5 approxim rule set translat kbann neural network topolog shown figur 5 recal kbann add addit lowweight link shown addit sequenc inform relev algorithm captur inform train input featur promot recognit 57 sequenti dna nucleotid locat dna sequenc translat 4 input unit one nucleotid henc promot network 228 input unit problem refer point site gene transcript would begin exampl contain promot point locat 50 nucleotid preced seven follow tabl 5 initi rule promot recognit promot contact conform contact minus35 minus10 conform 45 aaa conform 45 aa 28 ttaat04 conform 49 27 tattg 01 conform 47 caattac 22 gtc 08 gcgcccc refer point thu posit exampl contain first seven nucleotid transcrib gene set exampl contain 53 sampl promot 53 nonpromot sequenc 53 sampl promot obtain compil produc hawley mcclure 1983 deriv neg train exampl randomli select contigu substr 15 kilobas sequenc provid prof record univers wisconsin chemistri depart sequenc fragment e coli bacteriophag isol restrict enzym haeiii virtu fact fragment bind rna polymeras believ contain promot site record person commun prior train rule tabl 5 classifi 106 exampl promot result rule use say 42 problem 2 splicejunct determin second problem examin primat splicejunct determin origin describ learn problem noordewi et al 1991 splice junction point dna sequenc superflu dna remov process protein creation higher organ problem pose dataset recogn given sequenc dna boundari exon ie part dna sequenc retain splice intron ie part dna sequenc splice problem consist two subtask recogn exonintron boundari recogn intronexon boundari dataset problem contain 3190 exampl approxim 25 exonintron boundari 25 intronexon boundari remain 50 neither exampl consist 60nucleotid long dna sequenc categor accord type boundari center sequenc center sequenc refer locat use number nucleotid experi present paper randomli select 1000 exampl 3190 exampl avail addit exampl inform splicejunct includ set 21 rule deriv standard biolog textbook rule set shown appear noordewi et al 1991 towel 1991 promot recognit success rate splice junction rule due larg tendenc say rule correctli classifi 40 ie 3 ei exampl 43 experi section present set experi design determin rel strength weak two ruleextract method describ section 3 compar ruleextract techniqu use two measur qualiti measur accuraci rule fidel network extract comprehens measur character whole set rule look individu rule final part section examin mean individu rule includ sampl rule extract train knn subset mofn 431 system methodolog addit compar mofn algorithm subset compar mofn three symbol algorithm either ourston mooney 1990 c45 quinlan 1987 linu dzeroski lavrac 1991 first algorithm either ourston mooney 1990 method empir adapt set proposit rule correct train exampl c45 quinlan 1987 distinct algorithm compar build decis tree without use background knowledg howev extract rule tree like system consid final result c45 set rule final algorithm linu augment set input featur boolean featur repres truth valu consequ rule set henc promot domain linu 244 featur avail 228 origin plu 16 rule use c45 induct compon linu henc result linu set rule may includ consequ origin rule train test methodolog neural network train network either train exampl correct within 020 desir output activ b everi exampl present 500 time c improv classif occur five present everi train exampl last termin criterion base upon fahlman lebier 1989 patienc metric follow hinton 1989 suggest improv network interpret weight subject gentl decay train 6 addit network train use crossentropi error function hinton 1989 experi indic better abl handl type error occur knn standard error function rumelhart et al 1986 test exampl consid correctli classifi output within 05 correct train test methodolog linu c45 c45 train use default code provid r quinlan specif use ten trial window procedur train set build ten decis tree tree transform ten rule set final optim set rule deriv ten rule set optim rule set use assess gener train test methodolog either neither train test either rather number report deriv ourston thesi 1991 either unabl work domain theori includ negat report result either splicejunct domain 432 qualiti issu overrid import work qualiti extract rule measur qualiti least two dimension first rule must accur categor exampl seen train rule lose advantag accuraci kbann provid symbol learn algorithm towel et al 1990 littl valu rule extract would simpler use symbol method 6 standard weight chang function term oe ad 0 1 thu weight standard weight adjust rumelhart et al 1986 weight chang exampl present use gentl develop rule use kbann develop highlyaccur understand abl classifi second extract rule must captur inform contain knn necessari extract rule use gain understand exactli knn learn train measur show mofn superior subset also show accuraci rule extract mofn equal superior symbol algorithm importantli show mofn method extract rule equival network classifi test exampl accuraci assess accuraci system use ten repetit 10fold crossvalid weiss kulikowski 1990 figur 6 plot averag tenfold crossvalid run comparison figur 6 includ accuraci train knn prior rule extract bar label network figur 6 approxim recal initi rule set promot recognit splicejunct determin correctli categor 50 61 respect exampl henc system plot figur 6 superior initi rule promot problem c45 linu either subset approxim equival testset accuraci method lag significantli behind mofn method somewhat surprisingli outperform linu although differ statist signific accuraci rule extract either subset approxim equal method achiev accuraci quit differ wherea either perfect train set subset margin better train test set final rule extract mofn significantli superior least 99 confid rule extract method investig moreov differ accuraci rule extract mofn network came statist signific pattern result somewhat differ splice junction problem larg result rel improv c45 linu domain result c45 linu mofn origin network statist indistinguish rule gener subset method much wors perhap interest result dataset mofn rule outperform network came term train set accuraci earlier test towel shavlik 1991 show error tabl fidel extract rule train knn train exampl rule overal probabl agreement extract percent knn extract rule given method agreement knn correct knn incorrect splice junction subset 86 087 038 mofn 93 095 031 promot subset 87 090 024 mofn 99 099 010 rate extract rule promot problem also network rule extract howev alter train method reduc overfit improv accuraci network without significantli affect accuraci extract rule section 44 analyz result error rate subset rule test exampl statist wors rule learn method fidel fidel mean abil extract rule mimic behavior network extract fidel import two circumst 1 extract rule tool understand behavior network 2 extract rule use method transfer knowledg contain network tabl 6 indic mofn superior subset reproduc behavior network exampl seen train result obtain trial use previou section instanc splice junction data rule extract use mofn give answer train knn 93 time rule extract subset match 86 time addit tabl 6 show method rule extract much better mimick behavior network network correct incorrect 433 comprehens use extract rule must accur also must understand abl illdefin concept sever way understand might measur one approach look statist describ whole set rule altern examin whether individu rule meaning follow section present result measur global comprehens first dimens along character comprehens set rule ruleset size size concern set larg number rule difficult imposs understand figur 7 address issu ruleset size plot ruleextract method space span number extract rule total number anteced rule data figur 7 repres averag crossvalid studi report figur 6 unfortun count rule anteced mofn network straightforward mofn simplif phase may increas number rule requir reus anteced data figur 7 8 blith ignor complic reflect rule anteced count unsimplifi rule set train network count anteced includ link whose weight within two order magnitud bia unit receiv link weight lesser size count littl effect final rule anteced count linu includ anteced deriv featur linu use rule deriv featur count singl anteced rule set extract linu would size extract c45 figur 7 approxim take initi rule set domain standard interpret rule refin symbol method like easi understand recal howev rule significantli less accur promot domain rule set extract mofn also like easili understood contain fewer rule approxim number anteced initi rule set hand rule subset extract much less like comprehens second import global statist number anteced per rule valu larg individu rule unlik understand bruner et al 1956 furthermor negat anteced add difficulti evalu rule nessier ween 1962 howev effect negat anteced difficult quantifi weight anteced appear mofn rule implicitli appear train network cloud pictur rather arbitrarili assign difficulti rank type anteced figur 8 simpli show number neg posit anteced averag rule figur approxim measur ruleset size symbol method clear winner mofn rule slightli larger subset rule contain neg teced still method return rule well within limit human comprehens miller 1956 recal mofn extract mani fewer rule individu comprehens global statist discuss suffici indic whether whole rule set like comprehens determin rule set potenti comprehens necessari look individu rule assess mean make assess examin rule set extract mofn subset method train knn entir set exampl problem domain tabl 7 8 present rule mofn subset extract network promot recognit rule extract splicejunct domain paper much charact promot domain appear towel 1991 rule set extract subset larg set fi p fi n valu small deliv reason accur rule set result rule tabl 8 25 error rate train set rule extract mofn tabl 7 somewhat murki vastli comprehens network 3000 link induc moreov rule rewritten form similar one use biolog commun name weight matric stormo 1990 one major pattern appar rule extract mofn subset specif knn learn disregard conform conform rule also drop either often use linu suggest drop rule artifact method rather dna nucleotid outsid minus35 minus10 region less import conform hypothesi koudelka et al 1987 suggest henc demonstr machin learn method provid valuabl evid confirm refut biolog theori gener rule mofn extract confirm import base identifi initi rule howev wherea initi rule requir match everi base extract rule allow less perfect match addit extract rule point tabl 7 promot rule extract mofn promot minus35 minus10 12 cat 1 12 rb 31 31 x nt35 ac minus3536 ctgac 10 x nt12 ta minus3535 ttdca 30 x nt12 tabl 4 mean letter g c nt return number name anteced match given sequenc nt14 c g would return 1 match sequenc 14 aaacaaaaa place chang sequenc import instanc final minus10 rule posit 8 strong indic rule true howev replac g prevent rule ever satisfi difficult get clear pictur promot subset rule tabl 8 three minus35 rule left column encod simpl 2of3 concept rule approxim 3of7 concept note pattern support idea implement mofn method bia toward mofn style concept use 44 discuss result present section indic mofn method abl extract good set rule train network particular data support content 1 mofn method abl extract comprehens rule train knn reproduc behavior knn extract 2 extract rule equival superior rule obtain neurallybas symbol rulerefin method rule set produc mofn algorithm tabl 8 promot rule extract subset promot minus35 minus10 minus35 minus35b minus35d minus35 37 tta minus35 minus35a minus35b minus35 37 tta minus35 minus35a minus35d minus35 37 gca minus35 37 tc minus35b 37 aca minus35d 37 ttc minus35d 37 tgc minus35d 37 tac minus35d 37 gac minus35d 37 tac abbrevi set rule extract subset test set accuraci 75 set whose statist report previous section contain 300 rule slightli larger produc symbol approach mofn rule set small enough comprehens domain expert much ac curat henc although weigh tradeoff accuraci understand problem userspecif mofn algorithm networktorul translat offer appeal mixtur two result section deserv addit consider superior mofn rule obtain symbol rulerefin techniqu occasion superior mofn rule network extract first glanc might seem power mofn algorithm deriv use express languag rulerefin system true anteced consequ mofn rule boolean henc mofn rule written disjunct conjunct rule great increas number rule hypothesi must reject still two hypothes explain superior mofn rulerefin method directli modifi rule first rerepresent rule set neural network allow finegrain refin cast neural network rule modifi small step may make possibl close fit target concept take larg step requir direct rule refin second hypothesi explain rel superior mofn symbol method rule refin mofn may better fit natur problem hand instanc promot problem sever potenti site hydrogen bond form dna protein enough bond form promot activ occur symbol method investig easili express mofn rule henc advantag mofn method may result output languag better fit natur languag dna sequenceanalysi prob lem gener viewpoint problem may natur languag parsimoni solv languag use learn system similar natur languag learn system abl effect learn solv problem hypothesi correct expect problem close fit induct bia symbol rulerefin system outperform mofn algorithm observ mofn rule superior network extract attribut languag bia mofn style rule subset languag express use neural network instead advantag mofn rule like occur ruleextract process reduc overfit train exampl sever piec evid support hypothesi first note previous revis network train procedur reduc overfit promot domain elimin advantag mofn rule network extract reduc degre network fit train data elimin advantag mofn rule network extract second differ abil correctli categor test train exampl smaller mofn rule train knn word rule mofn method extract slightli better classifi train exampl classifi test exampl differ train test set perform smaller statist signific 995 confid use onetail pairedsampl ttest rule subset extract also properti much wors train set mofn rule train knn test set asid expect subset algorithm abl exceed perform mofn two problem investig howev subset algorithm might expect equal accuraci mofn problem whose solut match bia toward set conjunct rule third piec evid support overfit hypothesi come work prune neural network elimin superflu part mozer smolenski 1988 le cun et al 1989 7 rule extract extrem form prune link unit prune action taken remain network transform network set rule prune effort also led gain test set perform gener research attribut gain reduc overfit train exampl 5 test artifici problem previou section explor util mofn method context two realworld problem advantag realworld problem selfevid disadvantag realworld problem particular difficult close control studi investig abil algorithm instanc test previou section left unaddress question concern robust mofn method flaw initi domain theori know way domain theori incorrect therefor section step away real world look two artifici problem monk problem thrun et al 1991 gain control distanc correct theori theori provid learn system control allow us make addit predict abil ruleextract algorithm 51 monk problem chose monk problem test domain wide test thoroughli document problem afford easi replic monk problem origin describ thrun et al 1991 report author describ test machin learn algorithm monk problem consist popul 432 exampl defin six 7 also larg bodi literatur symbol machin learn suggest method reduc overfit train set improv gener eg quinlan 1987 featur appear top tabl 9 first monk problem learn classifi exampl accord domain theori appear middl tabl 9 domain theori simpli disjunct four conjunct theori easili express rule extract knn use either subset mofn second monk problem given rule near bottom tabl 9 consider complex express concept disjunct conjunct requir 15 rule six anteced altern concept express singl conjunct rule two claus express mofn concept rule appear bottom tabl 9 addit complex second problem signific effect abil 25 algorithm test thrun et al 1991 learn concept first problem test algorithm suppli 124 train exampl nine system test problem correctli classifi whole popul overal system averag 888 correct despit suppli exampl 169 second problem four 25 system test correctli classifi popul overal system averag 763 correct system better second problem first 52 experi question address experi section difficult recov correct domain theori provid theori quit correct defin difficulti averag size train set need correctli identifi entir popul definit difficulti similar teach dimens goldman kearn 1991 except teach dimens learningsystem specif experi compar abil knn learn concept abil mofn subset extract rule express concept modifi domain theori three way first delet anteced rule test robust miss anteced second add negat unneg anteced rule test robust rule contain unnecessari anteced third swap unnecessari anteced correct anteced test abil simultan add delet anteced modifi everi rule theori instanc ad one anteced rule first monk problem see tabl creat rule set three rule three anteced one rule two anteced addit three type chang modifi domain theori accor featur name valu smile 2 fye nog hold 2 fsword balloon flagg jacketcolor 2 fred yellow green blueg featur valu monk problem headshap round bodyshap round monk headshap squar bodyshap squar monk headshap octagon bodyshap octagon monk jacketcolor red monk correct theori first monk problem exactli two headshap round bodyshap round smile ye hold sword jacketcolor red hasti ye monk correct theori second monk problem two headshap round bodyshap round smile ye hold sword jacketcolor red hasti ye three headshap round bodyshap round smile ye hold sword jacketcolor red hasti ye monk reformul second monk problem tabl 9 domain correct theori monk problem danc represent first domain theori negat anteced case system must learn anteced effect exactli opposit effect indic provid domain theori second domain theori alter requir number present absent anteced instanc rather requir exactli two anteced provid domain theori requir exactli anteced n 2 f1 3 4 5g also provid domain theori requir n anteced n 2 f1 2 3 4 5g ie match 3 4 5 6 anteced would satisfi rule examin five variant first monk problem fifteen variant second monk problem figur result result obtain creat knn base corrupt domain theori copi knn train use small percentag popul learn correctli classifi whole train set rule extract knn use mofn subset knn two set extract rule test entir popul three correctli classifi popul trial finish otherwis procedur repeat use new copi knn slightli larger train set chosen includ member previous train set size train set increas three system correctli identifi entir popul entir popul use train result procedur size smallest train set requir knn two set extract rule correctli classifi entir popul figur 9 plot averag 25 repetit procedur five corrupt first monk theori eight corrupt second monk theori figur 10 use data trial figur 9 plot averag size term number anteced rule set extract subset mofn note figur short bar prefer knn unabl complet learn train data second monk problem sever nois condit describ particular knn fail even singl requir anteced swap unnecessari anteced knn also fail learn second problem told exact number match anteced three told n suffici total seven fifteen corrupt second domain theori result knn unabl learn train data seven case plot figur 9 10 figur 9 approxim figur approxim 53 discuss signific trend figur 9 one case mofn learn concept fewer exampl knn requir result support suggest made section 4 effect mofn attribut action postprun method network make suggest case mofn learn concept knn knn perfect train exampl knn problem classifi full popul spuriou correl among lowlyweight link impact categor exampl seen train ruleextract process use mofn act elimin link caus knn problem hand subset explicitli prune network mere attempt reproduc behavior network use boolean logic henc unsurpris problem subset requir popul correctli identifi concept either mofn knn yet subset occasion quit well sever problem requir fewer train exampl knn one problem fewer mofn although occasion success often spectacularli bad one case complet unabl learn first problem despit knn reliabl acquir concept see 50 popul look size concept identifi plot figur 10 clear case mofn exactli identifi concept first problem mofn extract origin rule four five trial fifth trial mofn includ sever useless anteced extract rule interestingli one problem subset fail everi case mofn abl learn second problem extract correct rule final moder surpris knn unabl learn second problem corrupt rule set none corrupt particularli sever hope network would simpli resort knowledgefre start point would expect perform along line standard neural network fullyconnect randomlyiniti neural network singl layer hidden unit train use backpropag requir 39 dataset reliabl learn first problem 47 percent data reliabl learn second problem instead problem knn unabl learn fell local minima unabl escap observ prior knowledg hinder learn signific observ previous made pazzani 1992 focu paper surprisingli knn unabl learn concept mofn subset rare extract rule express concept conclus experi show knn capabl learn rule underli concept mofn method abl extract set rule close approxim thereof knn 6 relat work two distinct set work close relat ruleextract method present paper first set contain symbol method learn rule exampl eg ourston mooney 1990 thompson et al 1991 dzeroski lavrac 1991 method avoid extract rule learn perform manipul directli rule method appeal requir shift symbol neural represent result present figur 6 indic accur problem investig mofn method present second set relat research attempt extract rule randomlyweight ann singl layer hidden unit saito nakano 1988 fu 1991 report method similar subset algorithm saito nakano look inputoutput behavior train network form rule map directli input output domain theori provid name hidden unit limit combinator inher algorithm like subset saito nakano limit rule four anteced howev even limit extract 400 rule one output unit ann 23 output thu method potenti use understand network may drown research sea rule sever group report attempt extract rule network like knn welldefin architectur sestito dillon 1990 avoid combinatori problem approach rule extract transform network j input k output network j input train look link origin j input similar weight pattern one k addit input method discov hierarch rule set discov relationship robin isa bird isa anim network must output robin bird anim anoth method extract rule speciallyconfigur network mcmillan mozer smolenski 1991 connectionist scientist game use neural network iter learn set proposit rule method similar mofn algorithm except assum two group one larg posit weight one zero weight mani problem includ monk problem studi section 5 assumpt quit use significantli constrain search space howev realworld problem assumpt may prove overli restrict final recent attempt extract fuzzi rule neural network instanc berenji 1991 describ method much like kbann except begin end fuzzi rule sever techniqu extract fuzzi rule neural network also report hayashi 1990 masuoka et al 1990 bochereau bourgin 1990 7 limit futur work result present section 4 indic mofn method abl effect extract rule train knn therebi make kbann excel method refin exist rule howev method also sever limit heretofor briefli mention signific limit along brief discuss plan address limit ffl mofn method requir network knowledg base network must initi comprehens investig differ method train network knowledgebas yield network upon mofn method effect instanc nowlan hinton 1991 train method group link loos cluster may result network amen mofn ffl larg shift mean unit result train make extract rule difficult comprehend minimum system flag rule review better solut would give kbann way analyz extract rule ffl domain theori may provid sufficientlyrich vocabulari allow knn accur learn concept knn miss term requir express concept modifi exist term cover vocabulari shortfal often lead larg shift mean term discuss previou point case necessari augment knn addit hidden unit howev ad hidden unit open mani issu rais section 6 extract rule network initi domain theori ffl system yet test broad rang problem discuss sequenc analysi problem often contain aspect mofnlik mofn method may ideal suit sequenceanalysi problem two problem also share aspect relat sequenc analysi exampl initi domain theori problem overli specif empir test suggest kbann slightli effect domain theori overli specif towel 1991 henc test broader rang dataset need prove gener method addit extend kbann mofn method address limit current work ruleextract algorithm oper train knn rather allow link weight freeli take arbitrari valu algorithm period cluster link weight train thu consist altern cycl standard weight adjust b round quit similar approach rule extract taken mcmillan mozer smolenski 1991 form rule produc method similar mofn rule howev search path weight space taken algorithm quit differ path taken mofn algorithm train instead undergo transit interpret set rule blackboxish knn back interpret set rule onlin cluster algorithm preserv comprehens knowledg base train also expect insight train process gain abl inspect knn knowledg base variou point train lastli investig way enhanc comprehens rule return mofn rule extract network mofn much comprehens network extract complet satisfi comprehens hope altern form present enhanc mofn algorithm differ network train method improv comprehens result rule conclus paper present empir valid mofn method extract rule knowledgebas neural network shown mofn method part kbann system form rulerefin algorithm result rule gener better exampl seen train rule produc allsymbol rule refin algorithm attribut gener abil shift represent initi domain theori symbol neurallybas shift alter bia system way enhanc abil accur refin initi rule particular neural represent natur admit mofn style concept addit neural represent allow gradat import anteced difficult achiev symbol learn system represent shift one use kbann system difficult effect pay handsom improv perform easiest represent shift involv train exampl rel eas shift result plethora comparison among empir learn system domainspecif knowledg much difficult shift represent initi work kbann provid method shift domainspecif knowledg form proposit horn claus neural network towel et al 1990 shift made knowledg avail neural learn algorithm backpropag result initi effort classifi accur obtain use train exampl towel et al 1990 noordewi et al 1991 one sens earlier result dead end refin knowledg train network inaccess previou paper provid method shift knowledg symbol neural provid method shift back symbol henc paper present method complet symbol circl open dead end make highlyaccur neural classifi access humaninspect learn symbol orient system experiment result indic mofn method extract concis intellig rule train knn without seriou loss accuraci fact extract rule accur classifi test exampl network came moreov extract rule show util machin learn techniqu method valid refin realworld case biolog theori final extra work requir system comparison symbol rulerefin method shown worthwhil method provid superior rule small cost comprehens henc work show valu shift finegrain represent detail correct back commun correct 9 acknowledg work partial support offic naval research grant n0001490j1941 nation scienc foundat grant iri9002413 depart energi grant de fg0291er61129 wish thank michiel noordewi construct two biolog rule data set gener comment work comment richard maclin mark craven deni kibler three anonym review also grate acknowledg final thank ross quinlan provid code c45 promot recognit splicejunct determin dataset part collect dataset ucirvin avail via anonym ftp icsuciedu directori pubmachinelearningdatabas r refin approxim reasoningbas control reinforc learn extract semant featur logic rule multilay neural network studi think learn relat noisi exampl empir comparison linu foil cascadecorrel learn architectur empir comparison id3 back propag rule learn search adapt net complex teach analysi e cluster algorithm compil analysi escherichia coli promot dna sequenc neural expert system autom extract fuzzi ifthen rule advanc neural inform process system vol connectionist learn procedur complex load shallow neural network effect noncontact base affin 434 oper 434 repressor cro neurofuzzi system fuzzi infer use structur neural network r1 rulebas configur comput system connectionist scientist game rule extract refin neural network magic number seven skeleton techniqu trim fat network via relev assess hierarchi concept attain train knowledgebas neural network recogn gene dna sequenc simplifi neural network soft weightshar advanc neural inform process system vol use explanationbas empir method theori revis phd thesi chang rule comprehens approach theori refin prior knowledg hinder learn direct transfer learn inform among neural network simplifi decis tree medic diagnost expert system base pdp model use multilay neural network learn symbol knowledg world scientif symbol neural net learn algorithm empir comparison consensu pattern dna two problem backpropag steepest descent learn procedur network use background knowledg concept format monk problem perform comparison differ learn algorithm symbol knowledg neural network insert interpret artifici neural network map knowledgebas neural network rule refin approxim correct domain theori knowledgebas neural network comput system learn tr ctr koji fujimoto sampei nakabayashi appli gmdh algorithm extract rule exampl system analysi model simul v43 n10 p13111319 octob milan zorman peter kokol bruno stiglic transform backpropag neural network decis tree use nndt cascad method second intern workshop intellig system design applic p7580 august 0708 2002 atlanta georgia khosrow kaikhah sandesh doddameti discov trend larg dataset use neural network appli intellig v24 n1 p5160 februari 2006 rudi setiono huan liu symbol represent neural network comput v29 n3 p7177 march 1996 petra povalej mitja leni peter kokol combin multipl specialist opinion cellular automata improv medic decis make proceed 4th wsea intern confer appli informat commun p15 decemb 1719 2004 tenerif canari island spain rudi setiono wee kheng leow fernn algorithm fast extract rule fromneur network appli intellig v12 n12 p1525 januaryapril 2000 marco muselli diego liberati binari rule gener via ham cluster ieee transact knowledg data engin v14 n6 p12581268 novemb 2002 steffen hlldobler yvonn kalink hanspet strr approxim semant logic program recurr neural network appli intellig v11 n1 p4558 julyaugust 1999 gari w flake eric j glover steve lawrenc c lee gile extract queri modif nonlinear svm proceed 11th intern confer world wide web may 0711 2002 honolulu hawaii usa witold pedrycz neural network handbook data mine knowledg discoveri oxford univers press inc new york ny 2002 l mangasarian set contain character journal global optim v24 n4 p473480 decemb 2002 yaochu jin bernhard sendhoff extract interpret fuzzi rule rbf network neural process letter v17 n2 p149164 april ron sun knowledg extract reinforc learn new learn paradigm soft comput physicaverlag gmbh heidelberg germani 2002 rudi setiono extract rule neural network prune hiddenunit split neural comput v9 n1 p205225 jan 1 1997 johan huysman bart baesen jan vanthienen new approach measur rule set consist data knowledg engin v63 n1 p167182 octob 2007 sankar k pal sushmita mitra pabitra mitra roughfuzzi mlp modular evolut rule gener evalu ieee transact knowledg data engin v15 n1 p1425 januari toni plate joel bert john grace pierr band visual function comput feedforward neural network neural comput v12 n6 p13371353 june 2000 judi goldsmith robert h sloan theori revis queri extend abstract proceed thirtysecond annual acm symposium theori comput p441448 may 2123 2000 portland oregon unit state amit gupta sang park siuwa lam gener analyt rule extract feedforward neural network ieee transact knowledg data engin v11 n6 p985992 novemb 1999 glenn fung sathyakama sandilya r bharat rao rule extract linear support vector machin proceed eleventh acm sigkdd intern confer knowledg discoveri data mine august 2124 2005 chicago illinoi usa shlomo argamonengelson mosh koppel hillel walter maxim theori accuraci select reinterpret machin learn v41 n2 p123152 novemb 2000 peter haddawi vu ha angelo restificar benjamin geisler john miyamoto prefer elicit via theori refin journal machin learn research 4 1212003 zhihua zhou rule extract use neural network neural network journal comput scienc technolog v19 n2 p249253 march 2004 hongjun lu rudi setiono huan liu neurorul connectionist approach data mine proceed 21th intern confer larg data base p478489 septemb 1115 1995 robert h sloan gyrgi turn theori revis queri proceed twelfth annual confer comput learn theori p4152 juli 0709 1999 santa cruz california unit state warodom geamsakul tetsuya yoshida kouzou ohara hiroshi motoda hideto yokoi katsuhiko takabayashi construct decis tree graphstructur data applic fundamenta informatica v66 n12 p131160 januari 2005 judi goldsmith robert h sloan new horn revis algorithm journal machin learn research 6 p19191938 1212005 judi goldsmith robert h sloan gyrgi turn theori revis queri dnf formula machin learn v47 n23 p257295 mayjun 2002 kazumi saito ryohei nakano extract regress rule neural network neural network v15 n10 p12791288 decemb 2002 boonserm kijsirikul boonserm kijsirikul lerdlamnaochai firstord logic neural network intern journal hybrid intellig system v2 n4 p253267 decemb 2005 anna l buczak wojciech ziarko neural rough set base data mine method engin handbook data mine knowledg discoveri oxford univers press inc new york ny 2002 artur avila garcez gerson zaverucha connectionist induct learn logic program system appli intellig v11 n1 p5977 julyaugust 1999 samuel h huang hao xing extract intellig concis fuzzi rule neural network fuzzi set system v132 n2 p233243 decemb 2002 c tan c p lim v c rao hybrid neural network model rule gener applic process fault detect diagnosi engin applic artifici intellig v20 n2 p203213 march 2007 volker tresp jrgen hollatz subutai ahmad repres probabilist rule network gaussianbasi function machin learn v27 n2 p173200 may 1997 ioanni hatzilygeroudi jim prentza neurosymbol approach knowledg represent expert system intern journal hybrid intellig system v1 n34 p111126 decemb 2004 zhihua zhou yuan jiang shifu chen extract symbol rule train neural network ensembl ai commun v16 n1 p315 januari zhihua zhou yuan jiang shifu chen extract symbol rule train neural network ensembl ai commun v16 n1 p315 may ismail taha joydeep ghosh symbol interpret artifici neural network ieee transact knowledg data engin v11 n3 p448463 may 1999 andrea nrnberger witold pedrycz rudolf kruse data mine task method classif neural network approach handbook data mine knowledg discoveri oxford univers press inc new york ny 2002 zijian zheng construct xofn attribut decis tree learn machin learn v40 n1 p3575 juli 2000 martin holea piecewiselinear neural network relationship rule extract data neural comput v18 n11 p28132853 novemb 2006 ron sun todd peterson edward merril hybrid architectur situat learn reactiv sequenti decis make appli intellig v11 n1 p109127 julyaugust 1999 henrik jacobsson rule extract recurr neural network taxonomi review neural comput v17 n6 p12231263 june 2005 russel greiner christian darken n iwan santoso effici reason acm comput survey csur v33 n1 p130 march 2001