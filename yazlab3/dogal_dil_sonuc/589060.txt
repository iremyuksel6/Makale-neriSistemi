algorithm constrain weight nonlinear least squar hybrid algorithm consist gaussnewton method secondord method solv constrain weight nonlinear least squar problem develop analyz test one advantag algorithm arbitrarili larg weight handl weight merit function get unnecessarili larg iter diverg saddl point local converg properti gaussnewton method thoroughli analyz simpl way estim calcul local converg rate gaussnewton method given assumpt constrain weight linear least squar subproblem attain gaussnewton method ill condit global converg toward firstord kkt point prove b introduct assum f r n continu differenti function diagon matrix weight discuss gaussnewton method second order method solv problem min x2r denot 2norm simplic without loss gener assum weight normal sort normal easili done first sort zero weight reduc problem divid remain nonzero weight smallest posit weight knowledg exist algorithm solv 11 base unweight problem min assum ordinari gaussnewton method use solv 13 search direct p got solv min p2 1 rg note 14 solv unweight problem thu condit problem determin kkk kk k k pseudo invers k hand linear 11 without explicitli multipli weight solv weight linear least squar problem obtain search direct p condit problem 15 mainli determin kbk kjk detail discuss condit number 15 see 11 problem 14 may ill condit regard unweight linear least squar problem despit fact 15 well condit regard weight linear least squar problem obvious import look 11 class weight nonlinear least squar problem anoth import advantag use 11 instead 13 former defin gener problem class latter evid allow weight infinit larg precis defin vector equat weight correspond zero element note lagrang multipli correspond ith constraint consequ defin 16 return proper way calcul lagrang multipli problem 11 rewritten use 16 henc allow infinit weight origin problem formul 11 defin class weight nonlinear least squar problem nonlinear equal constraint even specif assum p infinit weight problem 17 state theta f equival formul problem 18 use min 2 cours could start defin problem one 19 instead 15 without need 17 18 notat would get unnecessarili complic next section describ gaussnewton method solv 11 local converg properti gaussnewton method analyz section 3 section 4 show certain assumpt nondegeneraci global converg achiev gaussnewton method slow converg second deriv avail reason cost newton method may use solv 11 howev larg possibl infinit weight pure newton method base form hessian gx may work infinit weight even defin natur approach use perturb method 9 call gener newtonraphson method gnr method section 5 construct analyz algorithm solv 11 base gnr method comput experi present section 6 final discuss result give hint possibl futur work 2 gaussnewton method use system equat gaussnewton method nonlinear least squar problem 11 linear around current iter point x k search direct p k comput solut next iter x steplength presenc larg weight possibl infinit adequ reformul 21 gammaf simplic drop iter index k sever name linear system equat 22 equilibrium equat system equat augment system equat call 22 system equat matrix 22 call system matrix less obviou reason use 22 element correspond infinit weight approxim lagrang multipli use second order method describ section 5 follow lemma give relev condit system matrix nonsingular lemma 21 system matrix 22 nonsingular row j correspond infinit weight linearli independ j full column rank exist sever stabl algorithm solv 22 see eg 5 refer chosen use modifi qr decomposit see 5 reason follow modifi qr decomposit simpl easi comput ident ordinari qr decomposit weight equal modifi qr decomposit also easili reus second order gnr method see section 5 modifi qr decomposit j 2 r mthetan defin r nthetan upper triangular matrix pi permut matrix decomposit 23 q r nonsingular exist system matrix 22 nonsingular see lemma 21 system equat solv modifi qr decomposit follow way use decomposit 23 22 get6 6 4 r make partit mmgamman solut 24 mgamman 3 local rate converg gaussnewton method section describ local converg properti gaussnewton method describ previou section analysi depend much upon perturb analysi constrain weight linear least squar problem done 11 12 defin invers system matrix use notat 11 state prove two import theorem local converg rate project residu fact local converg properti two quantiti shall see similar final show j k p k local converg rate x x j k p k independ parametr r n assum b x solut 11 defin b correspond notat quantiti evalu b x necessari condit algorithm converg without regular system matrix 22 full rank conveni make follow definit definit 31 system matrix 22 nonsingular x say x nondegener point nondegener point invers system matrix 22 given gener invers j see 11 25 immedi get follow theorem describ local behaviour x theorem 31 assum fp k g gener solv 22 point x nondegener b x solut 11 b vector 22 b x r 1f 00 proof x f use taylor expans first term 34 express express second term gammab k f 34 use perturb ident 22 p 11 say use ident z 1f 00 equat 36 becom equat 35 37 insert 34 give theorem gaussnewton method written b theorem 31 conclud 8 get follow theorem theorem 32 defin eigenvalu h x lim sup xk xk easi get estim local converg rate use matrix defin 32 b r r gammat pi use quantiti estim close x k solut b x project residu obliqu project f k onto rj k follow theorem show j k p k local converg behaviour theorem 33 assum fp k g gener solv 22 point x nondegener x k vector 22 x k r 1f 00 proof denot project j k b k p k use taylor expans multipli p k1 obtain equal b k hold identifi last term equat 314 31 get henc perturb ident 21 p 16 11 get use 318 fact k1 ffij k b k equat 317 becom last equal follow 316 ident gammap k togeth taylor expans ffij k give theorem follow insert 315 319 314 matrix correspond h x project residu k b easi show h x h nonzero eigenvalu henc theorem 33 follow corollari corollari 31 defin b k invers system matrix 31 lim sup ks eigenvalu matrix h x defin 311 relat 312 also use determin ks k1 kk k k reflect linear converg rate second order method use converg gaussnewton method slow use higher order method if2 see also algorithm 61 sever quantiti invari chang parametr exampl follow theorem theorem 34 matrix b independ parametr r n proof assum fx want show b gener invers ry b consid taylor expans delta x 00 delta x 00 compar taylor expans 321 taylor expans use j 323 final get prove theorem consequ theorem 34 local converg x main argument choos jp measur close solut follow theorem direct consequ 323 theorem 35 project f rj independ parametr r n 4 global converg section assum x k k iter index nondegener p k solut 22 x k noth els state assum limit denot k 1 sum explicitli state upper lower limit one infin 41 merit function merit function chosen goal find matrix k merit weight step length ff k iter global converg toward first order kuhntuck point prove comput k use approxim fix matrix defin obvious suffici condit p k descent direct phix x k oe 0 realiz determin good matrix upsilonx k merit weight solv min kupsilonk st ffi small posit constant lower limit weight determin previous comput weight see alway solut 42 lim argf min ff note keep weight larg import practic global converg constraint 42 must satsifi describ algorithm comput merit weight k use upsilonx k becom unnecessarili larg first describ method solv 42 algorithm comput actual merit weight k solv 42 chosen use maxnorm sinc give simpl algorithm problem 42 rewritten min kuk1 u diagon upsilonx k diagon w jp given problem 43 consist vector matric first step algorithm reduc 43 u get new problem correspond part u left reduct ae readi solut otherwis choos e vector one thu attain equal constraint respect reduc problem copi 44 vector shorter ae smaller procedur repeat whole u found easili realiz infinit weight chang algorithm algorithm termin solut 44 determin actual merit weight k solut upsilonx k 42 weight may get larg close saddl point iter diverg saddl point alway case gaussnewton method would like weight decreas accomplish save say older version merit weight matric initi iter kth iter updat algorithm 41 algorithm 41 solv 42 vector ux k k new sequenc 1 algorithm 42 gaussnewton algorithm describ line search quadrat merit function algorithm 42 initi start vector x k converg comput comput use modifi qr decomposit j k determin k algorithm 41 determin step length ff k 42 prove global converg need follow two technic lemma prove algorithm global converg lemma use k arbitrari diagon element k lemma 41 assum k 0 fd k g bound let subsequ fd k g k j1 k j posit seri converg converg proof take converg assum b n converg b n henc k g bound sequenc increas limit b gamma converg b lemma 42 assum arbitrari compon k diagon k stay bound k 1 let v k correspond diagon element v lim seri converg proof let us first exclud trivial case v k becom equal upper bound finit k sequenc fv k g increas infinit sequenc henc lim v k exist denot v take ffl arbitrari small fix posit number k kvalu henc v sinc ffl 0 arbitrari impli v k v k follow thu v v consequ k v let fd k g subsequ fd k g k1 k lemma 41 know seri converg converg let us prove latter seri converg v k k follow henc sinc subseri increas v seri converg sinc posit seri suffici prove bound henc remain prove seri converg sinc save older weight updat step 1 reach 1t updat v 1t equal one earlier way elimin v 1t correspond j way seen v 1t1 equal one j pair also elimin seri go elimin element way get thu posit seri bound converg complet proof main global converg theorem cover bound unbound sequenc merit weight theorem 43 let fx k g fd k g gener algorithm 42 assum bound system matrix 22 nonsingular closur g sequenc fx k g either finit termin kkt point accumul point kkt point 11 proof trivial finit termin kkt point let us assum infinit sequenc algorithm 42 impli suffici consid follow two case case treat separ exist subsequ fx k g fx k g kd bound possibl choos subsequ fx j k g fx k g x x e x algorithm 42 follow kd k k 1 continu point closur fx k g except kkt point e x accumul point fx k g kkt point ii inequ one prove point e x accumul point fx k g exist proof 45 trivial extens similar proof 7 pp 2122 lemma 42 know converg goldstein armijo condit algorithm 42 given k follow everi point e x closur fx k g kkt point exist constant ffl 0 45 satisfi henc kkt point remain possibl accumul point prove theorem case ii 43 line search chosen keep thing simpl therefor use standard cubic interpol 3 approxim minimum merit function oeff anoth effici line search algorithm found 6 44 regular use simpl form subspac minim describ unweight constrain case 7 abl prove gener global converg result one theorem 43 shall see comput experi regular seem work appropri 5 gener newtonraphson method constrain newton method solv 19 base quadrat subproblem gp first order approxim lagrang multipli solut p 51 given linear system equat g gammaf main disadvantag use 52 larg weight w 2 quadrat subproblem 51 matrix 52 may ill condit avoid ill condit due larg weight w 2 solv gammaf 22 method gener newtonraphson method 9 gnr method gnr method interest theoret motiv assum reach point x k first order approxim 15 known x k solv perturb problem min project onto rj k henc know solut x k 54 want comput solut perturb problem min use quadrat approxim zx x k comput solut problem 55 whose error okp k f k k 2 chang back origin notat fx perturb solut found solv problem 53 53 seen exist matrix n k x solut 11 take x quadrat approxim 56 get 56 also seen j k n k depend surfac parameter x consequ j k p k independ parameter r n gener newtonraphson method fact quadrat converg method j k p k independ parametr see assum exist anoth method comput e e seri expans 56 uniqu j k e impli e defin z 1 matrix whose column span null space j 1 call p descent direct p z drawback constrain newton method base 52 gnr method nonsingular matrix 52 53 suffici p descent direct howev use gnr method close solut see 320 algorithm 61 therefor use gnr method undamp 22 get need g gaussnewton search direct matrix 53 singular use alreadi avail gaussnewton direct use modifi qr decomposit solv 22 possibl reduc size system 53 ignor permut matrix possibl rewrit r impli q reduc 57 r gammag gamma first n element q q respect matrix 58 may indefinit must either use stabl method indefinit system see eg 4 add condit submatric 58 one possibl latter kind assum r well condit use r reduc 58 r gammag gamma solut matrix rmnr gammat g nonsingular take gaussnewton step 6 comput experi algorithm use test shown algorithm 61 initi determin jacobian j vector f comput gn direct p solv 22 regular need second fals close second rate 05 comput gnr direct p gnr solv 53 matrix 53 nonsingular gn comput merit weight algorithm 41 determin step length ff use line search describ section 43 merit function oeff x use pure gn method variabl second fix valu fals test algorithm three differ problem describ ap pendix schittkowski 308 10 bogg 2 bogg 8 2 intent test show algorithm faster exist algorithm show algorithm handl larg weight inadequ model ill condit linear problem anoth import aim test verifi theoret result local converg rate therefor natur use small simpl test problem defin two differ measur converg rate gaussnewton method emphas k excel way estim converg rate regular need b x known first problem schittkowski 308 first solv gaussnewton method result tab 1 largest weight 10 20 weight multipli explicitli f form algorithm break numer instabl note slow growth merit weight first problem schittkowski 308 gaussnewton method 5 73e3 66e5 27e3 46e2 44e2 30 99 10 6 34e4 30e6 12e4 46e2 46e2 29 39 10 8 72e7 65e9 27e7 46e2 47e2 30 10e2 10 9 33e8 30e10 12e8 46e2 46e2 30 10e2 10 tabl schittkowski 308 gnr method 5 59e5 56e12 22e5 10 6 29e11 23e16 11e11 10 solv gnr method show tab 2 asterisk indic gnr method use step second problem bogg 2 constrain problem solv gaussnewton method tab 3 gnr method tab 4 merit weight gaussnewton method equal one shown tab 3 remain two test problem illustr regular rank problem shown headlin rank tab 5 second test problem bogg 2 solv gaussnewton method jacobian rank defici start point third problem bogg 8 jacobian solut rank defici result shown tab 6 7 discuss claim develop effici fairli robust algorithm solv 11 possibl infinit weight discuss intro duction howev difficult us measur effect algorithm bogg 2 gaussnewton method 3 12e2 28e2 23 013 050 26 10 5 24e4 25e4 73e3 010 19e2 16e2 10 6 64e5 66e5 30e4 027 42e2 16e2 10 tabl bogg 2 gnr method 3 12e2 28e2 23 10 5 24e4 25e4 73e3 10 6 64e5 66e5 30e4 10 9 82e16 10e15 19e15 10 knowledg algorithm solv gener problem 11 local converg properti well understood gaussnewton algo rithm especi interest local converg result valid whole problem class defin 11 independ parametr r n merit function especi suit weight constrain problem techniqu choos merit weight effect lead unnecessari larg weight bogg 2 gaussnewton rank defici start point 9 047 071 014 10 012 3 robust shown algorithm global converg iter point nondegener remain find way regular row j correspond larg weight becom almost linearli depend believ difficult challeng problem solv appendix test problem appendix defin three test problem weight sequenc also give start point x start solut b residu fbx exampl 10 2 includ unconstrain well constrain problem schittkowski 308 10 unconstrain problem modifi incorpor weight constrain problem jacobian rank defici second bogg 8 gaussnewton rank defici solut 28 11 10 065 10 34e10 5 29 11 099 16 35 95e7 4 53 42e9 025 050 35 10 4 54 10e9 025 050 35 10 3 start point x start2 bogg 8 2 constrain problem jacobian rank defici solut r strategi global converg sequenti quadrat program algorithm numer method unconstrain optim nonlinear equat matrix comput modifi qr decomposit weight constrain linear least squar iter solut nonlinear equat sever variabl comparis algorithm nonlinear least squar problem test exampl nonlinear program code perturb theori condit number gener constrain linear least squar problem tr ctr hiroshi hosob hierarch nonlinear constraint satisfact proceed 2004 acm symposium appli comput march 1417 2004 nicosia cypru