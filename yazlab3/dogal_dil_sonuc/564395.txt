bayesian onlin classifi text classif filter paper explor use bayesian onlin classifi classifi text document empir result indic classifi compar best text classif system furthermor onlin approach offer advantag continu learn batchadapt text filter task b introduct face massiv inform everyday need autom mean classifi text document sinc handcraft text classifi tediou process machin learn method assist solv problem15 7 27 yang liu27 provid comprehens comparison supervis machin learn method text classif paper show certain bayesian classifi compar support vector machines23 one best method report 27 particular evalu bayesian onlin perceptron17 20 bayesian onlin gaussian process3 text classif filter initi train set larg onlin approach use allow continu learn without store previous permiss make digit hard copi part work person classroom use grant without fee provid copi made distribut profit commerci advantag copi bear notic full citat first page copi otherwis republish post server redistribut list requir prior specif permiss andor fee sigir02 august 1115 2002 tamper finland seen data continu learn allow util inform obtain subsequ data initi train bay rule allow onlin learn perform principl way16 20 17 evalu bayesian onlin perceptron togeth inform gain consider batchadapt filter task18 2 classif filter text classif task defin lewis9 set predefin categori set document categori document set partit two mutual exclus set relev irrelev document goal text classif system determin whether given document belong predefin cate gori sinc document belong zero one categori system collect binari classi fier one classifi classifi one categori text retriev confer trec task known batch filter consid variant batch filter call batchadapt filtering18 task test document retriev classifi relev judgement fed back classifi feedback use improv classifi 21 corpora data text classif use modapt version reuters21578 corpu 1 unlabel document remov version 9603 train document test document follow 7 27 categori least one document train test set retain reduc number categori 90 batchadapt filter attempt task trec 918 ohsum collection6 use evalu ohsu topicset consist 63 topic train test materi consist 54710 293856 document respect addit topic statement topic purpos treat addit train document topic use titl abstract author sourc section document train test 22 represent variou way transform document represent conveni classif use avail via httpwwwdaviddlewiscomresourc testcollectionsreuters21578 bagofword approach retain frequenc word tokenis stem stopword moval frequenc normal use variou schemes19 6 use ltc normal l l id jterm l jd subscript denot ith term dth document respect tf id frequenc ith term dth document n documentfrequ ith term n total number document 23 featur select metric given set candid term select featur set use likelihood ratio binomi distribut advoc dunning5 number relev nonrelev train document contain term r n number relev nonrelev train document n total number train document asymptot 2 ln 2 distribut 1 degre freedom choos term 2 ln 1213 ie 005 signific level detail featur select procedur given section 4 24 perform measur evalu text classif system use f1 measur introduc van rijsbergen22 measur combin recal precis follow way number correct posit predict number posit exampl number correct posit predict number posit predict recal eas comparison summar f1 score dierent categori use micro macroaverag f1 scores11 27 categori document averag withincategori f1 valu micro macroaverag f1 emphas perform system common rare categori spectiv use averag observ eect dierent kind data text classif system addit compar two text classif system use micro signtest stest macro signtest stest two signific test first use compar text classif system 27 stest compar binari decis made system stest compar withincategori f1 valu similar f1 averag stest stest compar perform two system common rare categori respect evalu batchadapt filter system use t9p measur trec918 number correct posit predict max50 number posit predict precis penalti retriev 50 document 3 bayesian onlin learn section base work opper17 solla suppos document describ vector x relev indic x categori given label 1 1 1 1 indic irrelev relev respect given instanc past data predict probabl relev document describ x z da pyx apadm introduc classifi assist us predict bayesian approach random variabl probabl densiti padm integr possibl valu obtain predict aim obtain reason descript bayesian onlin learn framework16 20 17 begin prior pad0 perform increment bay updat obtain posterior data arriv py t1 x t1 apad r da py t1 x t1 apad make learn onlin explicit depend posterior pad t1 past data remov approxim distribut paa t1 t1 character distribut time 1 exam ple paa t1 gaussian t1 refer mean covari henc start prior new exampl t1 x t1 compris two step updat posterior use bay rule approxim updat posterior parameteris approxim step done minim kullbackleibl distanc approxim approxim distribut amount inform gain learn new exampl express kullbackleibl distanc posterior prior distribu igi t1 x t1d z da pad t1 log 2 z da paa t1 log 2 instanc data replac summari approxim simplifi notat henceforth use p denot paa averag taken paa respect exampl predict probabl rewritten z da pyx ap pyx follow section scalar field use simplifi notat calcul 31 bayesian onlin perceptron consid case describ perceptron defin likelihood probit model ya x 0 fix nois varianc cumul gaussian distribut z u p0 spheric unit gaussian p gaussian approxim opper16 17 solla obtain follow updat equat mean covari paa t1 paa t1 x t1 py t1 h t1 h 311 algorithm train bayesian onlin perceptron data involv success calcul mean covari c posterior 1 1 initi 0 0 c0 1 ident matrix ie spheric unit gaussian centr origin 2 3 t1 relev indic document x t1 4 calcul t1 t1 h py t1 h 5 calcul 6 calcul py t1 h 7 calcul 2 py t1 h py t1 h 8 calcul t1 c t1 predict datum x simpli involv calcul pyx 32 bayesian onlin gaussian process gaussian process gp constrain problem small data set recent csato opper3 william seeger24 introduc ecient eectiv approxim full gp formul section outlin approach 3 gp framework describ function consist function valu ax use probit model likelihood express 0 describ section 31 addit p0a gp prior specifi gaussian distribut zero mean function covariancekernel function k0 x x function space p also gaussian process csato opper obtain follow updat equat mean covari paa t1 paa t1 x t1 py t1 h t1 h notic similar updat section 31 main dierenc kernel trick introduc equat new input x t1 ad sequenti system via 1th unit vector e t1 result quadrat increas matrix size drawback larg data set text classif csato opper overcom introduc spars gp idea replac e t1 project approxim introduc error use decid employ approxim henc time algorithm hold set basi vec tor usual desir limit size set accommod csato opper describ procedur remov basi vector set revers process ad new input lack space algorithm bayesian onlin gaussian process given reader refer 3 inform 4 evalu 41 classif reuters21578 evalu compar bayesian onlin per ceptron bayesian onlin gaussian process support vector machin svm23 svm one best perform learn algorithm reuters21578 corpus7 27 bayesian method describ section 3 svm use sv light packag joachims8 sinc svm batch method fair comparison onlin method iter train data 3 time test 2 411 featur select reuters21578 corpu select featur categori set word 2 ln 1213 prune use top 300 featur reduc comput time requir calcul covari bayesian classifi sinc svm known perform well mani featur svm classifi also use set word occur least 3 train documents7 give us 8362 word note word noncategori specif 412 threshold probabilist output bayesian classifi use variou way direct way use bay decis rule determin relev document describ x 3 howev discuss 10 26 optim chosen evalu measur therefor addit 05 threshold also empir optimis threshold categori f1 measur train document scheme shall call maxf1 also employ 27 threshold knn llsf classifi dierenc approach threshold 27 calcul valid set use valid set feel rare categori hard obtain reason valid set train document bayesian classifi also perform analyt threshold optimis suggest lewis10 scheme shall call expectedf1 threshold categori select optimis expect f1 otherwis threshold p probabl assign document classifi set test docu ment set test document probabl higher threshold note expectedf1 appli probabl test document assign henc classif done batch unlik first two scheme classif done onlin 413 result discuss section a2 discuss number pass 3 svm minimis structur risk would classifi document relev w x hyperplan b bia section a3 discuss jitter term ij tabl 1 descript method descript 4 perceptron fix featur bia tabl 2 micromacroaverag f1 perceptron 8512 4523 8669 5216 8644 5308 tabl 1 list paramet algorithm use evalu tabl 2 3 tabul result two set result svm label svma svm b latter use set featur bayesian classifi ie use 2 ln measur former use set 8362 word featur tabl 2 summar result use f1 averag tabl 3 compar classifi use stest stest maxf1 threshold use classif decis row tabl compar method list first column method signific level 27 use sever observ made gener maxf1 threshold increas perform system especi rare categori bayesian classifi expectedf1 threshold improv perform system rare categori perceptron implicitli implement kernel use gp1 henc similar result maxf1 threshold featur select imped perform svm tabl 2 svm 8362 featur slightli lower microaverag f1 bayesian classifi howev stest tabl 3 show bayesian classifi outperform svm significantli mani common cat egori henc addit comput averag f1 measur use perform sign test shown tabl 3 limit featur bayesian classifi outperform svm common rare categori base sign test bayesian classifi outperform use 8362 word common categori vice versa rare categori tabl 3 steststest use maxf1 threshold perceptron mean pvalu 001 mean 001 pvalu 005 mean pvalu 005 last observ suggest one use bayesian classifi common categori svm rare one 42 filter ohsum section bayesian onlin perceptron consid order avoid numer integr inform gain measur instead probit model section 31 use simpler likelihood model output flip fix probabl updat equat also chang accordingli eg py t1 h t1 h use likelihood measur express inform gain datum t1 x t1 log c log 2 c use evalu follow section describ algorithm detail simplifi presen tation divid batchadapt filter task batch adapt phase 421 featur select adapt batch phase word 2 ln 1213 select featur adapt phase obtain feedback updat featur ad new word 2 1213 featur ad distribut perceptron extend one dimens 422 train classifi batch phase classifi iter train document 3 time addit relev document collect use adapt phase adapt phase retriev relev document ad collect document retriev classifi train document given relev judgement classifi train irrelev document time prevent forget relev document due limit capac whenev train irrelev document would also train past relev document past relev document chosen success collect relev document need also new featur might ad sinc relev document last train henc classifi would abl gather new inform document due addit featur note past relev document need chosen success order instead chosen use probabl distribut collect desir handl topicdrift evalu eectiv strategi retrain past retriev relev document denot use rel though use mean algorithm longer onlin asymptot ecienc unaect sinc one past document use train instanc 423 inform gain test two reason retriev document first relev ie repres document second although document deem irrelev classifi classifi would gain use inform document use measur igi xd calcul expect inform gain 0408n ret q target number figur 1 versu nret tune t9p document deem use expect inform gain least optim t9p measur ie target 50 document choos n ret total number document system retriev figur 1 plot n ret note kind activ learn willing tradeo precis learn decreas n ret use inform gain criteria denot ig test eectiv inform gain strat egi altern one altern denot rnd randomli select document retriev base probabl 50n ret 293856 otherwis 293856 number test document 424 result discuss tabl 4 list result seven system first two microsoft research cambridg fudan univers spectiv run trec9 task third system describ full ie bayesian onlin perceptron retrain past retriev relev document use inform gain rest bayesian onlin perceptron dierent combin strategi besid t9p measur sake complet tabl 4 also list measur use trec9 taken togeth measur show bayesian onlin percep tron togeth consider inform gain competit method system rel collect past known relev document kept although microsoft use collect queri reformul anoth collect previous seen document use threshold adapt fudan maintain collect past retriev document use collect queri adapt report result run ok9bfr2po report result slightli better run ok9bf2po averag number relev document retriev averag number featur pptronrelig pptronig pptronrnd pptron figur 2 variat number featur relev document retriev plot pptronrelig pptronig close plot pptronrnd pptron typic oper system retriev relev document usual retain irrelev document usual discard therefor rel practic strategi adopt figur 2 plot averag number featur adapt phase see featur constantli ad relev document seen classifi retrain past document new featur enabl classifi gain new inform document compar result pptronrel pptron tabl 4 find train past document caus number relev document retriev drop 5 similarli pptronrelig pptronig drop 8 tabl 5 break retriev document classifi deem relev classifi actual queri inform pptronig pptronrnd tabl show none document randomli queri relev document surpris sinc averag 0017 test document relev contrast inform gain strategi abl retriev 313 relev document 261 document queri signific result consid pptronig tabl 4 show pptron inform gain strategi remov 731 relev document retriev henc although document queri irrelev inform gain queri help recal classifi ie 815 document versu 731 document import reach target 50 document mackay13 note phenomenon queri irrelev document edg input space suggest maxim inform defin region interest instead find region batch adapt filter remain subject research compar four plot figur 2 find averag inform gain strategi caus 3 featur discov number relev document retriev consequ better recal tabl 4 result batchadapt filter optim t9p measur microsoft 5 fudan pptronrelig pptronig pptronrnd pptronrel pptron total retriev 3562 3251 2716 2391 2533 1157 1057 relev retriev 1095 1061 1227 1128 732 772 731 macroaverag recal 395 379 362 333 200 208 200 macroaverag precis 305 322 358 358 216 619 623 mean t9p 305 317 313 298 192 215 208 mean util 4397 1079 15318 15762 5349 18397 17730 mean t9u 4397 1079 15318 15762 5349 18397 17730 mean scale util 0596 0461 0025 0016 0397 0141 0138 zero return tabl 5 breakdown document retriev pptronig pptronrnd number latter bracket relev relev total doc retriev perceptron classifi proper 815 732 378 345 1193 1077 doc retriev inform gain random strategi 313 0 885 1456 1198 1456 total 1128 732 1263 1801 2391 2533 5 conclus work implement test bayesian onlin perceptron gaussian process text classif prob lem shown perform compar svm one best learn algorithm text classif publish literatur also demonstr eectiv onlin learn inform gain trec9 batchadapt filter task result text classif suggest one use bayesian classifi common categori maximum margin classifi rare categori partit categori common rare one optim way interest problem svm employ use relev feedback drucker et al 4 retriev group 10 doc ument essenc form adapt rout would instruct see bayesian classifi perform without store mani previous seen document would also interest compar merit increment svm21 1 bayesian onlin classifi acknowledg would like thank lehel csato provid detail implement gaussian process wee meng soon assist data prepar yime yang clarifi represent use 27 loo nin teow proofread manuscript would also like thank review mani help comment improv paper 6 r increment decrement support vector machin learn analysi binari data relev feedback use support vector machin accur method statist surpris coincid ohsum interact retriev evalu new larg test collect research text categor support vector machin learn mani relev featur make largescal svm learn practic represent learn inform retriev evalu optim automom text classif system train algorithm linear text classifi bayesian interpol mont carlo implement gaussian process model bayesian regress classif featur select onlin versu bayesian approach onlin learn trec9 filter track final report optim perceptron learn onlin bayesian approach increment learn support vector machin inform retriev natur statist learn theori use nystrom method speed kernel machin bayesian mean field algorithm neural network gaussian process studi threshold strategi text categor tr termweight approach automat text retriev represent learn inform retriev bayesian interpol informationbas object function activ data select ohsum natur statist learn theori evalu optim autonom text classif system train algorithm linear text classifi featur select percept learn usabl case studi text categor make largescal support vector machin learn practic bayesian approach onlin learn optim perceptron learn reexamin text categor method studi threshold strategi text categor inform retriev text categor suport vector machin relev feedback use support vector machin ctr kian ming adam chai expect fmeasur tractabl exact comput empir observ properti proceed 28th annual intern acm sigir confer research develop inform retriev august 1519 2005 salvador brazil hwanjo yu chengxiang zhai jiawei han text classif posit unlabel document proceed twelfth intern confer inform knowledg manag novemb 0308 2003 new orlean la usa reylong liu dynam categori profil text filter classif inform process manag intern journal v43 n1 p154168 januari 2007 randa kassab jeancharl lamirel toward synthet analysi user inform need effect person filter servic proceed 2007 acm symposium appli comput march 1115 2007 seoul korea vaughan r shank hugh e william adam cannan index fast categoris proceed twentysixth australasian confer comput scienc research practic inform technolog p119127 februari 01 2003 adelaid australia reylong liu wanjung lin adapt sampl threshold document filter classif inform process manag intern journal v41 n4 p745758 juli 2005 aynur dayanik david lewi david madigan vladimir menkov alexand genkin construct inform prior distribut domain knowledg text classif proceed 29th annual intern acm sigir confer research develop inform retriev august 0611 2006 seattl washington usa new topic identif use multipl linear regress inform process manag intern journal v42 n4 p934950 juli 2006 franca debol fabrizio sebastiani analysi rel hard reuters21578 subset research articl journal american societi inform scienc technolog v56 n6 p584596 april 2005