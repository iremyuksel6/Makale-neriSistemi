similaritybas model word cooccurr probabl mani applic natur languag process nlp necessari determin likelihood given word combin exampl speech recogn may need determin two word combin eat peach eat beach like statist nlp method determin likelihood word combin frequenc train corpu howev natur languag mani word combin infrequ occur given corpu work propos method estim probabl previous unseen word combin use avail inform similar wordsw describ probabilist word associ model base distribut word similar appli two task languag model pseudoword disambigu languag model task similaritybas model use improv probabl estim unseen bigram backoff languag model similaritybas method yield 20 perplex improv predict unseen bigram statist signific reduct speechrecognit errorw also compar four similaritybas estim method backoff maximumlikelihood estim method pseudoword sens disambigu task control unigram bigram frequenc avoid give much weight easytodisambigu highfrequ configur similaritybas method perform 40 better particular task b introduct data spars inher problem statist method natur languag process method use statist rel frequenc configur element train corpu learn evalu altern analys interpret new sampl text speech like analysi taken one contain frequent configur problem data spars also known zerofrequ problem witten bell 1991 aris analys contain configur never occur train corpu possibl estim probabl observ frequenc estim scheme gener train data use languag process applic spars data problem occur even larg data set exampl essen steinbiss 1992 report 7525 split millionword lob corpu 12 bigram test partit occur train portion trigram spars data problem even sever instanc research ibm brown dellapietra desouza examin train corpu consist almost 366 million english word discov one expect 147 word tripl new english text absent train sampl thu estim probabl unseen configur crucial accur languag model sinc aggreg probabl unseen event signific focu particular kind configur word cooccurr exampl cooccurr includ relationship head word syntact construct verbobject adjectivenoun instanc word sequenc n gram commonli use model probabl estim previous unseen cooccurr function probabl estim word cooc currenc exampl word bigram model probabl p w 2 w 1 condit word w 2 never occur train follow condit word w 1 typic calcul probabl w 2 estim w 2 frequenc corpu jelinek mercer rouko 1992 katz 1987 method make independ assumpt cooccurr w 1 w 2 frequent w 2 higher estim p w 2 w 1 regardless w 1 classbas similaritybas model provid altern independ assumpt model relationship given word model analog word sens similar given one instanc brown et al 1992 suggest classbas ngram model word similar cooccurr distribut cluster word class cooccurr probabl given pair word estim accord averag cooccurr probabl two correspond class pereira tishbi lee 1993 propos soft distribut cluster scheme certain grammat cooccurr membership word class probabilist cooccurr probabl word model averag cooccurr probabl word cluster dagan marcu markovitch 1993 1995 present similaritybas model avoid build cluster instead word model specif class set word similar use scheme predict unobserv cooccurr like other model howev provid probabl estim use compon larger probabilist model would requir say speech recognit classbas similaritybas method cooccurr model may first sight seem special case cluster weight nearestneighbor approach use wide machin learn pattern recognit aha kibler albert 1991 cover hart 1967 duda hart 1973 stanfil waltz 1986 devroy gyorfi lugosi 1996 atkeson moor schaal 1997 import dierenc method cluster nearestneighbor techniqu often reli repres object point multidimension space coordin determin valu intrins object featur howev languagemodel set know word frequenc cooccurr word certain configur sinc purpos model estim probabl cooccurr cooccurr statist basi similar measur model predict mean measur word similar predict word make word cooccur wherea typic instanc nondistribut cluster learn method word similar defin intrins featur independ predict cooccurr probabl classif associ particular word see instanc work cardi 1993 ng lee 1996 ng 1997 zavrel daeleman 1997 11 main contribut main contribut gener scheme use word similar improv probabl estim backo model compar analysi sever similar measur paramet set two import languag process task languag model disambigu show similaritybas estim inde use initi studi languagemodel evalu use similaritybas model estim unseen bigram probabl wall street journal text compar standard backo model katz 1987 test heldout sampl similar model achiev 20 perplex reduct backo unseen bigram constitut 106 test sampl lead overal reduct testset perplex 24 similaritybas model also test speechrecognit task yield statist signific reduct 32 versu 64 mistak case disagr backo model recognit error disambigu evalu compar sever variant initi method cooccurr smooth method essen steinbiss 1992 estim method katz decis task involv unseen pair direct object verb found similaritybas model perform almost 40 better backo yield 49 accuraci experiment set furthermor scheme base jensenshannon diverg rao 1982 lin 1991 1 yield statist signific improv error rate cooccurr smooth also investig eect remov extrem lowfrequ event train set found contrast backo smooth event often discard train littl discern eect similaritybas smooth method suer notic perform degrad singleton event occur exactli omit paper organ follow section 2 describ gener similaritybas framework particular section 23 present function use measur similar section 3 detail initi languag model experi section 4 describ comparison experi pseudoword disambigu task section 5 discuss relat work final section 6 summar contribut outlin futur direct 2 distribut similar model wish model condit probabl distribut aris cooccurr linguist object typic word certain configur thu consid necessarili disjoint follow use subscript th element condit probabl rather empir estim drawn base languag model true probabl unknown pair second element given first element denot probabl estim accord base languag model w 1 first word pair given second word w 2 p w denot base estim unigram probabl word w similaritybas languag model consist three part scheme decid word pair requir similaritybas estim method combin inform similar word cours function measur similar word give detail three part follow three section concern similar word v 1 condit event probabl p w 2 w 1 want estim 21 discount redistribut data spars make maximum likelihood estim mle word pair probabl unreli mle probabl word pair w 1 w 2 condit appear word w 1 simpli frequenc w 1 w 2 train corpu cw 1 frequenc w 1 howev pml zero unseen word pair pair would predict imposs gener mle unreli event small nonzero count well zero count languag model literatur term smooth use refer method adjust probabl estim smallcount event away mle tri allevi unreli propos address zerocount problem exclus reli exist techniqu smooth small count previou propos zerocount problem good 1953 jelinek et al 1992 katz 1987 church gale 1991 adjust mle total probabl seen word pair less one leav probabl mass redistribut among unseen pair gener adjust involv either interpol mle use linear combin estim guarante nonzero unseen word pair discount reduc mle use seen word pair probabl mass left reduct use model unseen pair backo method katz 1987 prime exampl discount p repres goodtur discount estim katz 1987 seen word pair p r denot model probabl redistribut among unseen word pair w 1 normal factor sinc extens comparison studi chen goodman 1996 indic backo better interpol estim bigram probabl consid interpol method howev one could easili incorpor similaritybas estim interpol framework well origin backo model katz use p w 2 model predict word pair model back unigram model unseen bigram howev conceiv back detail model unigram would advantag therefor gener katz formul write p r w 2 w 1 instead p w 2 enabl us use similaritybas estim unseen word pair instead unigram frequenc observ similar estim use unseen word pair next investig estim p r w 2 w 1 deriv averag inform word distribut similar w 1 22 combin evid similaritybas model make follow assumpt word w 1 similar word w 1 w 1 yield inform probabl unseen word pair involv w 1 use weight averag evid provid similar word neighbor weight given particular word w 1 depend similar w 1 precis let w w 1 w denot increas function similar denot set word similar w 1 gener form similar model consid wweight linear combin predict similar word normal factor accord formula w 2 like occur w 1 tend occur word similar w 1 consider latitud allow defin set sw 1 evidenc previou work put form essen steinbiss 1992 karov edelman 1996 implicitli set sw 1 howev may desir restrict sw 1 fashion ecienc reason especi v 1 larg instanc languag model applic section 3 use closest k fewer word w 1 dissimilar w 1 w 1 less threshold valu k tune experiment one directli replac p r w 2 w 1 backo equat 2 p sim w 2 w 1 howev variat possibl interpol unigram probabl repres eect linear combin similar estim backo estim exactli katz backo scheme languag model task section 3 set experiment simplifi comparison dierent similar model sens disambigu section 4 set 0 would possibl make depend w 1 contribut similar estim could vari among word depend often use interpol model jelinek mercer 1980 jelinek et al 1992 saul pereira 1997 inde advantag howev sinc introduc hidden vari abl requir complex train algorithm pursu direct present work 23 measur similar consid sever word similar measur deriv automat statist train corpu oppos deriv manuallyconstruct word class yarowski 1992 resnik 1992 1995 luk 1995 lin 1997 section 231 232 discuss two relat informationtheoret function kl diverg jensenshannon diverg section 233 describ l 1 norm geometr distanc function section 234 examin confus probabl previous employ languag model task cours mani possibl function opt restrict attent reason divers set function correspond weight function w w 1 w 1 given choic weight function extent arbitrari requir increas similar w 1 w 1 extrem constrain clearli perform depend use good weight function would imposs tri conceiv w w 1 w 1 therefor section 45 describ experi evalu similaritybas model without weight function similar function describ depend base languag model may may katz discount model section 21 discuss complex comput similar function note current implement onetim cost construct wordtoword similar paramet train take place 231 kl diverg kullbackleibl kl diverg standard informationtheoret measur dissimilar two probabl mass function kullback 1959 cover thoma 1991 appli condit distribut induc word v 1 word nonneg zero p w 2 w 1 howev kl diverg nonsymmetr obey triangl inequ 1 defin must case p w 2 w unfortun gener hold mle base sampl must use smooth estim redistribut probabl mass zerofrequ event forc sum 4 w make calcul expens larg vocabulari diverg dw 1 w 1 comput set role free paramet control rel influenc neighbor closest nonneglig w 1 extrem close w 1 wherea low distant neighbor also contribut estim chose neg exponenti function kl diverg weight function analog form cluster membership function relat distribut cluster work pereira et al 1993 also form probabl w 1 distribut aros sampl drawn distribut w 1 cover thoma 1991 lee 1997 howev reason heurist rather theoret sinc rigor probabilist justif similaritybas method 232 jensenshannon diverg relat measur jensenshannon diverg rao 1982 lin 1991 defin averag kl diverg two distribut averag distribut shorthand distribution2 p w 2 w 1 sinc kl diverg nonneg jw 1 w let pw 2 easi see log qw entropi discret densiti q equat show j give inform gain achiev distinguish two distribut p p condit context w 1 w pool two distribut ignor distinct w 1 w 1 also easi see j comput ecient sinc depend condit word occur context inde let group term 6 appropri obtain rang 0 log 2 smooth estim requir probabl ratio involv kl diverg case set w j w 1 w play role 233 l 1 norm l 1 norm defin group term express lw 1 w 1 form depend common follow triangl inequ 0 lw 1 w equal 2 word w 2 p w strictli posit sinc requir weight scheme decreas l set free 2 higher rel influenc accord nearest neighbor interest note follow relat l 1 norm kl diverg jensenshannon diverg cover thoma 1991 give follow lower bound b base logarithm function lin 1991 note l upper bound j 234 confus probabl extend work sugawara nishimura toshioka okochi kaneko 1985 essen steinbiss 1992 use confus probabl estim word cooccurr probabl 3 report 14 improv testset perplex defin small corpu confus probabl also use grishman sterl 1993 estim likelihood select pattern confus probabl estim probabl word w 1 substitut word w 1 sens found context serv normal factor contrast distanc function describ pc curiou properti w 1 may necessarili closest word may exist word w 1 pc w 1 section 44 exampl confus probabl comput empir estim provid unigram estim nonzero assum throughout fact use smooth estim provid katz backo scheme problem atic estim typic preserv consist respect margin estim bayess rule may w2 use consist estim mle safe appli bayess rule rewrit pc follow tabl 1 summari similar function properti name rang base lm constraint tune j 0 log 2 none ye bay consist jensenshannon diverg l 1 norm sum requir comput common w 2 examin equat 8 reveal import dierenc confus probabl function j l describ previou sec tion function rate w 1 similar w 1 roughli p w 2 w 1 high howev greater w 1 p w 1 w 2 larg p w 2 w 1 p w 2 ratio larg may think w 2 except sinc w 2 infrequ expect p w 2 w 1 larg 235 summari sever featur measur similar list summar tabl 1 base lm constraint condit must satisfi probabl estim base languag model last column indic whether weight w w 1 w associ similar function depend paramet need tune experiment 3 languag model goal first set experi describ section provid proof concept show similaritybas model achiev better languag model perform backo therefor use one similar measur success experi convinc us similaritybas method worth examin close result second set experi compar sever similar function pseudoword disambigu task describ next section languag model experi use similaritybas model kl diverg dissimilar measur altern unigram frequenc back bigram model use bigram languag model defin entir vocabulari note earlier estim must smooth avoid divis zero comput employ standard katz bigram backo model purpos sinc v 20 000 applic consid small fraction v comput use tunabl threshold k describ section 22 purpos standard evalu metric languag model likelihood test data accord model intuit testset perplex repres averag number altern present bigram model test word thu better model lower perplex task lower perplex indic better predict unseen bigram evalu model compar testset perplex eect speechrecognit accuraci baselin bigram backo model develop mit lincoln laboratori wall street journal wsj text dictat corpora provid arpa hlt program paul 1991 4 baselin backo model follow katz design except sake compact frequenc one bigram ignor count use model obtain 405 million word wsj text year 198789 perplex evalu tune similar model paramet minim perplex addit sampl 575 thousand word wsj text drawn arpa hlt develop test set best paramet valu found valu improv perplex unseen bigram heldout hlt evalu test set 20 sinc unseen bigram compris 106 sampl improv unseen bigram correspond overal test set perplex improv 24 2374 2317 tabl 2 show reduct train test perplex sort train reduct dierent choic number k closest neighbor use valu best one found k 5 equat 9 clear comput cost appli similar model unseen bigram ok therefor lower valu k comput prefer tabl see reduc k incur penalti less 1 perplex improv rel low valu k appear sucient achiev benefit similar model tabl also show best valu increas k decreas lower k greater weight given condit word frequenc suggest predict power neighbor beyond closest model fairli well overal frequenc condit word bigram similar model also test languag model speech recog nition test data experi prune word lattic 403 wsj tabl 2 perplex reduct unseen bigram dierent model paramet train reduct test reduct 50 25 40 015 1838 2045 100 25 45 01 1823 2054 90 25 45 01 1823 2059 closedvocabulari test sentenc arc score lattic sum acoust score neg log likelihood languagemodel score case neg log probabl provid baselin bigram model given lattic construct new lattic arc score modifi use similar model instead baselin model compar best sentenc hypothesi origin lattic best hypothesi modifi one count word disagr one hypothes correct total 96 disagr similar model correct 64 case backo model 32 advantag similar model statist signific 001 level overal reduct error rate small 214 209 number disagr small compar overal number error recognit setup employ experi tabl 3 show exampl speech recognit disagr two model hypothes label b backo similar boldfac word error similar model seem better model regular semant parallel list avoid past tens form hand similar model make sever mistak function word insert place punctuat would found written text 4 wordsens disambigu sinc experi describ previou section demonstr promis result similaritybas estim ran second set experi design help us compar analyz somewhat divers set similar measur given tabl 1 unfortun kl diverg confus probabl dierent requir base languag model could run direct fourway comparison explain elect omit kl diverg consider tabl 3 speech recognit disagr model commit leader felt three point six billion dollar commit leader fell three point six billion dollar follow franc us agre itali follow franc us greec itali whisper made whisper aid b necess chang exist necess chang exist b without addit reserv centrust would report without addit reserv centrust would report b dark past church dark pass church chose evalu three remain measur word sens disambigu task method present noun two verb ask verb like noun direct object thu measur absolut qualiti assign probabl would case perplex evalu rather rel qualiti could therefor ignor constant factor normal similar measur 41 task definit usual word sens disambigu problem method test present ambigu word context ask identifi correct sens word context exampl test instanc might sentenc fragment rob bank question whether bank refer river bank save bank perhap altern mean sens disambigu clearli import problem languag process applic evalu task present numer experiment dicul tie first notion sens clearli defin instanc dictionari may provid sens distinct fine coars data hand also one need train data correct sens sign acquir correct sens gener requir consider human eort furthermor word mani possibl sens wherea other essenti monosem mean test case uniformli hard circumv diculti set pseudoword disambigu experi schutz 1992a gale church yarowski 1992 format follow first list pseudoword construct combin two dierent word v 2 word v 2 contribut exactli one pseudoword everi w 2 test set replac correspond pseudoword exampl pseudoword creat word make take data alter follow make plan make take plan take action make take action method test must choos two word make pseudoword advantag use pseudoword twofold first altern sens control experiment test instanc present exactli two altern disambigu method altern chosen frequenc part speech secondli pre transform data yield correct answer handtag word sens necessari advantag make pseudoword experi eleg simpl mean test ecaci dierent languag model cours may provid complet accur pictur model would perform real disambigu task although one could creat realist set make pseudoword two word vari frequenc altern pseudosens eas comparison consid interpol unigram probabil iti thu model use experi dier slightli use languag model test summar follow 42 data use statist partofspeech tagger church 1988 pattern match concordanc tool due david yarowski identifi transit main verb noun correspond direct object 44 million word 1988 associ press newswir select nounverb pair 1000 frequent noun corpu pair undoubtedli somewhat noisi given error inher partofspeech tag pattern match use 80 587 833 pair deriv build model reserv 20 test purpos similar measur requir smooth model calcul katz backo model p equat 2 p r w 2 w 1 maximumlikelihood model furthermor wish evalu hypothesi compact languag model built without aect model qualiti delet singleton word pair occur train set claim made particular languag model katz 1987 therefor built four base model summar tabl 4 tabl 4 base languag model singleton singleton katz bo1 boo1 sinc wish test eectiv use similar unseen word cooc currenc remov test data verbobject pair occur train set result 17 152 unseen pair occur multipl time unseen pair divid five equals part 1 5 form basi fivefold crossvalid five run one use perform test set four combin one set use tune paramet necessari via simpl grid search evalu error tune set regularli space point paramet space final test pseudoword creat pair verb similar frequenc control word frequenc decis task method simpli rank verb frequenc creat pseudoword adjac pair thu verb particip exactli one pseudoword tabl 5 list randomli chosen pseudoword frequenc correspond verb tabl 5 sampl pseudoword verb frequenc word meeet typo occur corpu make 14782take 12871 fetch 35renegoti 35 magnifi 13exit 13 meeet 1stupefi 1 relabel 1entomb 1 use error rate perform metric defin asn incorrect choic ties2 n size test corpu tie occur two word make pseudoword deem equal like 43 baselin experi perform four base languag model shown tabl 6 mle1 mleo1 error rate exactli 5 test set consist unseen bigram assign probabl 0 maximumlikelihood estim thu tie method backo model bo1 boo1 also perform similarli tabl 6 base languag model error rate sinc backo model consist perform wors mle model chose use mle model subsequ experi therefor ran comparison measur could util unsmooth data name l 1 norm lw 1 w 1 jensenshannon diverg jw 1 w 1 confus probabl pc w 1 w 1 6 44 sampl closest word section examin closest word randomli select noun guy accord three measur l j pc tabl 7 show ten closest word order base languag model mle1 overlap closest word l closest word j littl overlap closest word measur closest word respect pc word man lot common three also observ word guy fourth list word highest confus probabl respect guy let us examin case noun kid role close accord similar function l j kid second closest word guy role consid rel distant pc case howev role highest confus probabl respect guy wherea kid 80th highest confus probabl account dierenc tabl give ten verb like occur guy kid role indic l j rate word similar tend cooccur verb observ four ten like verb occur kid tabl 7 closest word word guy l j p c use mle1 base languag model rank word role kid also shown among top ten guy kid 123 kid 015 peopl 0024 lot 135 thing 01645 fire 0013 thing 139 lot 0165 guy 00127 man 146 man 0175 man 0012 doctor 146 mother 0184 year 001 girl 148 doctor 0185 lot 00095 rest 1485 friend 0186 today 0009 son 1497 boy 0187 way 0008778 bit 1498 son 0188 part 0008772 role rank 173 role rank 43 kid rank 80 tabl 8 noun w 1 ten verb w 2 highest p w 2 w 1 boldfac verb occur given noun guy base languag model mle1 noun like verb guy see get play let give catch tell pick need kid get see take help want tell teach send give love role play take lead support assum star expand accept sing limit tabl 9 verb highest p w 2 guyp w 2 ratio number parenthes rank 1 electrocut 2 shortchang 3 bedevil 4 admir 5 bore 6 fool also like occur guy wherea verb play commonli occur role guy sort verb decreas p w 2 guyp w 2 dierent order emerg tabl 9 play like verb cooccur role rank higher get like verb cooccur kid thu indic role higher confus probabl respect guy kid final examin eect delet singleton base languag model tabl show ten closest word order base languag model mleo1 rel order four closest word remain howev next six word quit dierent mle1 data suggest tabl closest word word guy l j p c use mleo1 base languag model guy kid 117 kid 015 peopl 0025 lot 140 thing 016 fire 0021 thing 141 lot 017 guy 0018 reason 1417 mother 0182 work 0016 break 142 answer 01832 man 0012 ball 1439 reason 01836 lot 00113 answer 144 doctor 0187 job 001099 tape 1449 boost 0189 thing 001092 rest 1453 ball 019 report 00106 eect singleton calcul similar quit strong born experiment evalu describ section 45 conjectur eect due fact mani lowfrequ verb data 65 verb appear 10 fewer noun common verb occur 710 noun omit singleton involv verb may well drastic alter number verb cooccur two given noun w 1 w 1 sinc similar function consid set experi depend word surpris eect delet singleton rather dramat contrast backo languag model sensit miss singleton goodtur discount small count inflat zero count 45 perform similaritybas method figur 1 show result experi five test set use mle1 base languag model paramet alway set optim valu correspond train set rand shown comparison purpos simpli choos weight w w 1 w set equal v 1 case similaritybas method consist outperform katz backo method mle recal yield error rate 5 larg margin indic inform word pair use unseen pair unigram frequenc inform similaritybas method also much better rand indic enough simpli combin inform word arbitrarili word similar taken account case j edg method averag improv use j instead pc 0082 dierenc signific 1 level p 085 accord pair ttest result mleo1 case depict figur 2 see similaritybas method achiev far lower error rate mle backo rand figur 1 error rate test set base languag model mle1 method go left right rand p c l j perform shown set optim correspond train set rang 40 45 l 20 26 j rand method j alway perform best howev omit singleton amplifi dispar j pc averag dierenc 024 signific 01 level pair ttest import observ method includ rand suer perform hit singleton delet base languag model seem indic seen bigram treat dierent unseen bigram even seen bigram extrem rare thu conclud one creat compress similaritybas languag model omit singleton without hurt perform least task analyz role paramet recal appear weight function jensenshannon diverg l 1 norm control rel influenc similar word influenc increas higher valu figur 3 show valu aect disambigu perform four curv shown correspond choic similar function base languag model error bar depict averag rang error rate five disjoint test set immedi clear get good perform result must set much higher jensenshannon diverg l 1 norm phenomenon result fact rang possibl valu j much smaller error rate test set base languag model mleo1 rand figur 2 error rate test set base languag model mleo1 rang 6 11 l 21 22 j error rate beta effect beta test set error use differ similar jensen mle1 jensen mleo1 figur 3 averag rang testset error rate vari similar function indic point style base languag model indic line style l compress j valu requir larg scale dierenc distanc correctli also observ set low caus substanti wors error rate howev curv level rather move upward long sucient larg valu chosen set suboptim greatli impact perform furthermor shape curv base languag model suggest relat testset perform rel insensit variat train data fact higher valu seem lead better error rate suggest role filter distant neighbor test hypothesi experi use k similar neighbor figur 4 show error rate depend k dierent fix valu two lowest curv depict perform jensenshannon diverg l 1 norm set optim valu respect averag test set perform appear distant neighbor essenti eect error rate contribut sum 9 neglig contrast low valu chosen upper two curv distant neighbor weight heavili case includ distant neighbor caus seriou degrad performance02603034038042100 200 300 400 500 600 700 800 900 1000 error rate effect k test set error use differ similar mle1 jensen beta21 jensen beta2 confus figur 4 averag rang testset error rate k vari base languag model mle1 similar function indic point style dash dot line indic suboptim choic interestingli behavior confus probabl dierent two case ad neighbor actual improv error rate seem indic confus probabl correctli rank similar word order inform howev altern explan pc disadvantag employ context tunabl weight scheme distinguish two possibl ran experi dispens weight altogeth instead took vote k similar neighbor altern chosen like one prefer major similar neighbor note ignor degre altern prefer result shown figur 502803203604044100 200 300 400 500 600 700 800 900 1000 error rate effect k test set error ignor weight probabl jensen mle1 jensen mleo1 confus mle1 confus mleo1 figur 5 averag rang votingschem testset error rate k vari similar function indic point style base languag model indic line style see k similar neighbor accord j l alway inform chosen accord confus probabl largest perform gap occur low k cours method perform sinc case use set neighbor graph provid clear evid confus probabl good measur inform word 5 relat work larg bodi work notion work similar word cluster applic imposs compar method directli sinc assumpt experiment set applic method vari wide therefor discuss mainli descript highlight main similar dierenc method 51 statist similar cluster disambigu languag model work instanc grow bodi research use word similar improv perform languageprocess problem similaritybas algorithm either use similar score word word directli make predict reli similar score word repres precomput similar class earli attempt automat classifi word semant class carri linguist string project grishman hirschman nhan 1986 semant class deriv similar cooccurr pattern word within syntact relat cooccurr statist consid class level use allevi data spars syntact disambigu schutz 1992b 1993 captur contextu word similar first reduc dimension context represent use singular valu decomposit use reduceddimension represent character possibl context word inform use word sens disambigu occurr ambigu word cluster cluster map manual one sens word context vector new occurr ambigu word map nearest cluster determin sens occurr schutz emphas method avoid cluster word predefin set class claim cluster like introduc artifici boundari cut word part semant neighborhood karov edelman 1996 also address data spars problem word sens disambigu use word similar use circular definit word similar measur context similar measur circular resolv iter process system learn set typic usag sens ambigu word given new occurr ambigu word system select sens whose typic context similar current context appli procedur resembl sens select process shutz scheme employ word similar disambigu influenc work dagan et al 1993 1995 method comput word similar measur directli word cooccurr data word model set similar word plausibl unseen cooccurr judg cooccurr statist word set similar measur weight tanimoto measur version also use grefenstett 1992 1994 word associ measur mutual inform follow earlier work word similar hindl 1990 method dagan et al provid probabilist model disambigu decis base compar score dierent altern produc explicit probabl estim therefor integr directli within larger probabilist framework cooccurr smooth model essen steinbiss 1992 like model produc explicit estim word cooccurr probabl base cooccurr statist similar word similaritybas estim interpol direct estim ngram probabl form smooth ngram languag model word similar model comput confus probabl measur describ evalu earlier sever languag model method produc similaritybas probabl estim classbas model method use direct measur similar word word instead cluster word class use global optim criterion brown et al 1992 present classbas ngram model record probabl sequenc word class instead sequenc individu word probabl estim bigram contain particular word aect bigram statist word class word class consid similar cooccurr behavior word class form bottomup hardclust algorithm whose object function averag mutual inform class cooc currenc ushioda 1996 introduc sever improv mutualinform cluster method appli partofspeech tag record class contain particular word bottomup merg process word repres mixtur class rather singl class algorithm kneser ney 1993 ueberla 1994 similar brown et al 1992 although dierent optim criterion use number cluster remain constant throughout membership assign pro cess pereira et al 1993 use formal statist mechan deriv topdown softclust algorithm probabilist class membership word cooccurr probabl model weight averag class cooccurr probabl weight correspond membership probabl word within class 52 thesaurusbas similar approach describ previou section induc word similar relationship word cluster cooccurr statist corpu research develop method quantifi similar relationship base inform manual craft wordnet thesauru miller beckwith fellbaum gross miller 1990 resnik 1992 1995 propos nodebas approach measur similar pair word thesauru appli variou disambigu task similar function informationtheoret measur inform least gener common ancestor two word thesauru classif jiang conrath 1997 combin nodebas approach edgebas approach similar node thesauru influenc path connect similar method test data set word pair similar rate deriv human judgment lin 1997 1998 deriv gener conceptsimilar measur assumpt desir properti similar measur function number bit requir describ two concept well common describ instanti measur hierarch thesauru appli wordnet part word sens disambigu algorithm 53 contextu similar inform retriev queri expans inform retriev ir provid addit motiv automat identif word similar one line work ir literatur consid two word similar occur often document anoth line work consid type word similar concern similar measur deriv wordcooccurr statist grefenstett 1992 1994 argu cooccurr within document yield similar judgement sharp enough queri expans instead extract coars syntact relationship text repres word set wordcooccurr within relat word similar defin weight version tanimoto measur compar cooccurr statist two word similar method evalu measur impact retriev perform ruge 1992 also extract word cooccurr within syntact relationship evalu sever similar measur data focus version cosin measur similar rank obtain measur compar produc human judg 6 conclus similaritybas languag model provid appeal approach deal data spars work propos gener method use similaritybas model improv estim exist languag model evalu rang similaritybas model paramet set import languageprocess task pilot studi compar languag model perform similaritybas model standard backo model improv achiev bigram backo model statist signifi cant rel modest overal eect small proport unseen event second detail studi compar sever similaritybas model paramet set smaller manag wordsens disambigu task observ similaritybas method perform much better unseen word pair measur base jensenshannon diverg best overal experi restrict bigram probabl estim reason simplic comput cost howev rel small proport unseen bigram test data make eect similaritybas method necessarili modest overal task believ benefit similaritybas method would substanti task larger proport unseen event instanc languag model longer context obstacl principl trigram case exampl would still determin probabl pair would consist word pair instead singl word howev number possibl similar event given element v 1 much larger bigram case direct tabul event similar event would thu practic compact approxim represent would investig would also worth investig benefit similaritybas method improv estim lowfrequ seen event howev would need replac backo model anoth one combin multipl estim event exampl interpol model contextdepend interpol paramet anoth area investig relationship similaritybas classbas approach mention introduct reli common intuit name event model extent similar event classbas method comput expens train time nearest neighbor method requir search best model structur number class hard cluster class membership estim hidden paramet class membership probabl soft cluster hand classbas method reduc dimension thu smaller ecient test time dimension reduct also claim improv gener test data evid mix furthermor classbas model theoret satisfi probabilist interpret saul pereira 1997 wherea justif similaritybas model heurist empir present given varieti classbas languag model algorithm describ section relat work beyond scope paper compar perform two approach ever comparison especi one would bring approach common probabilist interpret would well worth pursu acknowledg thank hiyan alshawi joshua goodman rebecca hwa slava katz doug mcil roy stuart shieber yoram singer mani help discuss doug paul help bigram backo model andrej ljolj michael riley provid word lattic speech recognit evalu also thank review paper construct critic editor present issu clair cardi ray mooney help suggest portion work appear previous dagan pereira lee 1994 dagan lee pereira 1997 thank review paper comment part work done first author member technic sta visitor att lab second author graduat student harvard univers summer visitor att lab second author receiv partial support nation scienc foundat grant iri9350192 nation scienc foundat graduat fellowship att grpwalfp grant note 1 best knowledg first use particular distribut dissimilar function statist languag process function implicit earlier work distribut cluster pereira et al 1993 use tishbi pc distribut similar work finch 1993 discuss use word cluster provid experiment evalu actual data 2 experi use 1 well yield poorer perform result 3 actual present two altern definit use model 2b found yield best experiment result 4 arpa wsj develop corpora come two version one verbal punctuat without use latter experi 5 valu refer base 10 logarithm exponenti calcul 6 note howev bo1 data kldiverg perform slightli better l 1 norm r local weight learn empir studi smooth techniqu languag model nearest neighbor pattern classif pattern classif scene analysi find structur languag work statist method word sens disambigu popul frequenc speci estim popul paramet use syntact context produc term associ list text retriev explor automat thesauru discoveri discoveri procedur sublanguag select pattern initi experi noun classif predicateargu structur principl lexic languag model speech recognit semant similar base corpu statist lexic taxonomi academia sinica learn similaritybas word sens disambigu spars data estim probabl spars data languag model compon speech recogn improv cluster techniqu classbas statist languag model inform theori statist use syntact depend local context resolv word sens ambigu morgan kaufmann statist sens disambigu rel small corpora use dictionari definit wordnet onlin lexic databas integr multipl knowledg sourc disambigu word sens exemplarbas approach distribut cluster english word wordnet distribut analysi classbas approach lexic discoveri disambigu noun group respect wordnet sens experi linguisticallybas term associ aggreg mixedord markov model statist languag process word space morgan kaufmann toward memorybas reason isol word recognit use hidden markov model extend cluster algorithm statist languag model tech hierarch cluster word applic nlp task zerofrequ problem estim probabl novel event adapt text compress tr ctr yoichi tomiura shosaku tanaka toru hitaka estim satisfactori select restrict corpu without thesauru acm transact asian languag inform process talip v4 n4 p400416 decemb 2005 kilyoun kim keysun choi dimensionreduc estim word cooccurr probabl proceed 38th annual meet associ comput linguist p571578 octob 0306 2000 hong kong doina tatar word sens disambigu machin learn approach short survey fundamenta informatica v64 n14 p433442 januari 2005 egidio terra charl l clark fast comput lexic affin model proceed 20th intern confer comput linguist p1022e august 2327 2004 geneva switzerland yuseop kim jeongho chang byoungtak zhang compar evalu datadriven model translat select machin translat proceed 19th intern confer comput linguist p17 august 24septemb 01 2002 taipei taiwan mat rooth stefan riezler detlef prescher glenn carrol franz beil induc semant annot lexicon via embas cluster proceed 37th annual meet associ comput linguist comput linguist p104111 june 2026 1999 colleg park maryland anna korhonen yuval krymolowski robust entropybas similar measur evalu subcategor acquisit system proceed 6th confer natur languag learn p17 august 31 2002 maayan geffet ido dagan featur vector qualiti distribut similar proceed 20th intern confer comput linguist p247e august 2327 2004 geneva switzerland egidio terra c l clark frequenc estim statist word similar measur proceed confer north american chapter associ comput linguist human languag technolog p165172 may 27june 01 2003 edmonton canada chinyew lin guihong cao jianfeng gao jianyun nie informationtheoret approach automat evalu summari proceed main confer human languag technolog confer north american chapter associ comput linguist p463470 june 0409 2006 new york new york jianfeng gao hisami suzuki wei yuan empir studi languag model adapt acm transact asian languag inform process talip v5 n3 p209227 septemb 2006 yair evenzohar dan roth classif approach word predict proceed first confer north american chapter associ comput linguist p124131 april 29may lillian lee measur distribut similar proceed 37th annual meet associ comput linguist comput linguist p2532 june 2026 1999 colleg park maryland lillian lee fernando pereira distribut similar model cluster vs nearest neighbor proceed 37th annual meet associ comput linguist comput linguist p3340 june 2026 1999 colleg park maryland maria lapata scott mcdonald frank keller determin adjectivenoun plausibl proceed ninth confer european chapter associ comput linguist june 0812 1999 bergen norway sabin schult im wald experi automat induct german semant verb class comput linguist v32 n2 p159194 june 2006 yuseop kim byoungtak zhang yung taek kim colloc dictionari optim use wordnetand knearest neighbor learn machin translat v16 n2 p89108 june 2001 viktor pekar acquisit verb entail text proceed main confer human languag technolog confer north american chapter associ comput linguist p4956 june 0409 2006 new york new york juli weed david weir diana mccarthi characteris measur lexic distribut similar proceed 20th intern confer comput linguist p1015e august 2327 2004 geneva switzerland maria lapata frank keller scott mcdonald evalu smooth algorithm plausibl judgement proceed 39th annual meet associ comput linguist p354361 juli 0611 2001 toulous franc zoltn szamonek istvn bir similar base smooth languag model acta cybernetica v18 n2 p303314 januari 2007 kristina toutanova christoph man andrew ng learn random walk model induc word depend distribut proceed twentyfirst intern confer machin learn p103 juli 0408 2004 banff alberta canada pablo gamallo alexandr agustini gabriel p lope cluster syntact posit similar semant requir comput linguist v31 n1 p107146 march 2005 frank keller maria lapata olga ourioupina use web overcom data spars proceed acl02 confer empir method natur languag process p230237 juli 06 2002 alexand budanitski graem hirst evalu wordnetbas measur lexic semant related comput linguist v32 n1 p1347 march 2006 maria lapata disambigu nomin comput linguist v28 n3 p357388 septemb 2002 juli weed david weir cooccurr retriev flexibl framework lexic distribut similar comput linguist v31 n4 p439475 decemb 2005 claudio carpineto renato de mori giovanni romano brigitt bigi informationtheoret approach automat queri expans acm transact inform system toi v19 n1 p127 jan 2001 clair grover alex lascarid mirella lapata comparison pars technolog biomed domain natur languag engin v11 n1 p2765 march 2005 frank keller mirella lapata use web obtain frequenc unseen bigram comput linguist v29 n3 p459484 septemb john chen sriniva bangalor k vijayshank autom extract treeadjoin grammar treebank natur languag engin v12 n3 p251299 septemb 2006