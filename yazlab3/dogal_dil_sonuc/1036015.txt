commun lower bound distributedmemori matrix multipl present lower bound amount commun matrix multipl algorithm must perform distributedmemori parallel comput denot number processor ipi dimens squar matric ini show wide use class algorithm socal twodimension 2d algorithm optim sens algorithm use ioiinisup2supipi word memori per processor least one processor must send receiv inisup2supipisup12sup word also show algorithm anoth class socal threedimension 3d algorithm also optim algorithm use replic reduc commun show algorithm use ioiinisup2supipisup23sup word memori per processor least one processor must send receiv inisup2supipisup23sup word furthermor show continu tradeoff size local memori amount commun must perform 2d 3d bound essenti instanti tradeoff also show input distribut across local memori multipl node without replic inisup2sup word must cross bisect cut machin bound appli convent inisup3sup algorithm appli strassen algorithm ioiinisup3sup algorithm b introduct although commun bottleneck mani comput run distributedmemori parallel comput cluster workstat server commun lower bound prove know great deal amount commun specic algorithm perform know littl much commun must perform present lower bound amount commun requir multipli matric convent algorithm distributedmemori parallel comput analysi use uni framework also appli analysi capac cach miss sequenti matrixmultipl algorithm use simpl yet realist comput model prove lower bound model parallel comput collect p processormemori node connect commun network memori distribut among node commun across network analysi bound number word must sent receiv least one node bound appli even processormemori node includ sever processor fairli common today machin rang cluster dualprocessor workstat sgi origin 2000 ibm sp aggarw chandra snir 5 present lower bound amount commun matrix multipl number comput bound howev assum sharedmemori comput model model well exist comput lpram model assum p processor privat cach connect larg share memori furthermor assum comput begin cach empti comput end output must return main memori analysi bound amount data must transfer share main memori privat cach bound matrix multipl essenti quanti number compulsori capac cach miss sharedmemori multiprocessor lpram model model well system memori physic distribut among process node eg cluster worksta tion parallel comput sgi origin 2000 ibm sp distinct lpram model model highli relev matrix multipl lower bound matrix multipl nearli alway subroutin larger comput distribut memori machin mul tiplicand alreadi distribut manner matrix multipl subroutin call product must left distribut processor local memori return thu lpram bound essenti show processor must access irrelev distributedmemori machin sinc element may alreadi resid processor mem ori lpram lower bound depend amount local memori data allow store perhap replic local memori comput begin end commun may necessari contrast lower bound allow initi data distribut input trice includ data distribut replic input element 3d algorithm lower bound even count commun necessari perform replic input element except section 6 explicitli forbid replic analyz commun across bisect machin lower bound hold even data allow replic prior invoc algorithm bound also allow distribut use standard asymptot notat paper specic use denit 10 gn set function fn exist posit constant c 1 c 2 0 c 1 gn fn c 2 gn n n 0 ogn dene similarli use weaker condit 0 fn c 2 gn gn dene condit 0 c 1 gn fn set ogn consist function fn c 2 0 exist constant n 0 0 0 fn c 2 gn n n 0 commun lower bound matrix multipl 5 output matrix c constraint place algorithm upon complet everi element c must resid processor local memori possibl sever state prove lower bound paper use concret constant rather asymptot notat sinc bound amount commun depend three paramet size matric n number processor p size local memori asymptot notat make less clear paramet must grow order function show asymptot behavior also use concret constant clari depend amount commun three paramet constant appear statement lemma theorem howev chosen make proof simpl possibl chosen tight possibl bound assum matric involv squar wherea other appli matric shape restrict matric squar shape feel bound rectangular matric would complic statement result proof unnecessarili analysi appli convent matrix multipl algorithm appli strassen algorithm 32 3 algorithm lower bound commun complex strassen nonconvent algorithm beyond scope paper rest paper organ follow section 2 present technic tool underli uni approach commun cachetrac lower bound section 3 present basic memorycommun tradeo show lack memori increas commun section 4 use provabl tradeo analyz socal twodimension 2d matrixmultipl algorithm 1 9 12 13 37 algorithm use n 2 p word memori per processor constant factor requir store input output algorithm use 3 word per processor 6 dror ironi sivan toledo alexand tiskin minim amount requir store input output without compr sion show amount commun perform per processor asymptot optim amount memori section 5 use sophist argument show socal threedimension 3d algorithm also optim 3d algorithm 1 5 6 12 14 19 replic input matric need n word memori per processor allow reduc amount commun n 2 p 23 per processor show amount commun optim amount memori use argument case somewhat complex sinc continu tradeo prove section 3 appli amount local memori per processor n 2 2p 23 section 6 prove replic input element allow must cross bisect machin final section 7 use basic lemma underli result prove wellknown lower bound number cach miss sometim refer page fault io lowerbound literatur main point section 7 show kind lower bound deriv use uni approach io commun lower bound relat 2 basic lemma section present technic lemma underli lower bound paper lemma show processor access n element n element b contribut comput n element product perform 32 use arithmet oper hong kung 17 prove weaker form lemma lemma consid access element b contribut element c weak use proof distributedmemori lower bound commun lower bound matrix multipl 7 also hong kung state result use asymptot notat wherea state prove use concret constant formal prove follow lemma dene formal matrixmultipl model hong kung use similar directedacyclicgraph model lemma 21 hong kung 17 consid convent matrix multipl c r processor local memori cach size word must read write least word secondari memori comput product state prove lemma must dene precis kind algorithm appli inform want deal algorithm use element addit multipl comput element c ik explicit sum product ij b jk thu rule eg strassen algorithm 32 save comput use element subtract furthermor must assum comput involv valu ij b jk c ik take place thu rule eg boolean matrix multipl algorithm 33 comput explicit sum still save commun memori use intermedi compact represent matric definit 21 convent matrix multipl b n r c r dene direct acycl graph dag mn nr input node repres element ij b jk matric b mr output node repres element c ik matrix c mnr comput node repres elementari multipl v arc repres data depend particular input node unbound outdegre correspond replic input output node unbound indegre correspond combin partial sum output thu denit cover whole class algorithm may perform replic combin dierent order readi prove basic lemma note hold matric shape long shape allow multipl lemma 22 consid convent matrix multipl mn b n r c r processor contribut nc element c access na element nb element b perform multipl proof lemma immedi corollari discret loomiswhitney inequ 26 15 8 relat cardin nite set z cardin ddimension orthogon project 1 applic discret loomiswhitney inequ matrixmultipl lower bound suggest paterson 29 see also 34 2 let v nite set point z 3 let va vb vc orthogon project v onto coordin plane discret loomiswhitney inequ state notat number elementari multipl perform processor therefor nanbnc 12 lemma 22 main tool prove commun lower bound fact import would like restat dierent form new commun lower bound matrix multipl 9 version slightli weaker lemma 22 allow direct proof feel may benet reader lemma 23 assumpt lemma 22 processor perform min elementari multipl proof statement follow lemma 22 arithmeticgeometr mean inequ give altern direct proof base idea similar 17 denot sa set element index pair processor access sb set element b processor access sc set element c processor contribut rst show nb nc n 12 bound number elementari multipli cation partit row two set set contain row least n 12 element sa fa contain rest row n 12 row sinc row c product correspond row b nbn 12 elementari multipl involv row sinc element c product row column b sinc row fa less n 12 element sa ncn 12 elementari multipl involv row fa similar argument show na nc n 12 b bound number elementari multipl partit column b set mb consist column least n 12 b element sb set fb contain rest column sinc column c product correspond column b nan 12 elementari multipl involv column mb sinc element c product row column b ncn 12 elementari multipl involv row fb final show na nb n 12 c bound number elementari mul tiplic partit row c set mc fc row c product row b c elementari multipl involv row mc element use comput element one row c row c contain less n 12 c element sc element us use less n 12 cation henc number elementari multipl involv row c fc less nan 12 c 3 memorycommun tradeoff section prove tradeo memori commun matrix multipl algorithm analysi show reduc amount memori forc algorithm perform commun shall use provabl tradeo next section prove 2d matrixmultipl algorithm asymptot optim amount memori use algorithm use littl extra memori beyond storag requir store matri ce henc lie extrem end memorycommun tradeo section 5 shall extend tradeo deal larger memori size enabl us prove 3d algorithm also asymptot optim amount memori use lemma 31 consid convent matrix multipl mn b n r c r p processor distributedmemori parallel commun lower bound matrix multipl 11 comput consid processor word local memori perform elementari multipl processor must send receiv least wp word proof decompos schedul comput processor phase phase begin total number word sent receiv far processor exactli thu phase except perhap last phase processor send receiv exactli word number na element processor may access phase 2m sinc one element must resid processor memori phase begin els must receiv anoth processor phase argument show nb 2m dene element c ik product c live phase 1 processor comput ij b jk j phase 2 partial sum contain ij b jk either resid processor memori end phase sent anoth processor phase number nc live element c phase 2m sinc live element either use one word memori end phase sent anoth processor lemma 22 show number elementari multipl phase nanbnc 12 2 total number elementari multipl algorithm w therefor number full phase phase exactli word sent receiv least wp wp total amount commun least wp wp conclud proof note proof allow input valu ij b jk pre distribut multipl copi dierent processor memori free input replica tion also ignor need collect add togeth individu processor contribut output valu c ik free output combin also note lower bound degener zero w 23 2 inevit sinc commun inde zero eg input output local memori gener commun requir input replic output com bine account proof howev latter case 3w 23 therefor threshold constant factor away best achiev lemma prove concentr singl processor next theorem take global view run time typic determin heavili load processor therefor show least one processor must perform lot commun deriv lower bound amount time whole algorithm must spend commun theorem 31 memorycommun tradeoff consid convent matrix multipl c r p processor distributedmemori parallel comput word local memori per processor total number word sent receiv least one processor least proof least one processor must perform mnrp multipl result follow appli lemma 31 commun lower bound matrix multipl 13 lower bound degener zero eg 4 commun lower bound almostinplac algorithm among mani exist parallel matrix multipl algorithm recent algorithm mccoll tiskin 27 knowledg one whose perform match asymptot lower bound memorycommun tradeo valu howev two class earlier algorithm match lower bound specic valu one end spectrum socal 2d algorithm use littl extra memori beyond requir store matric end spectrum socal 3d algorithm use extra memori replic input matric reduc com munic special theorem 31 2d algorithm section 5 analyz algorithm use extra memori rst distributedmemori parallel matrixmultipl algorithm probabl one due cannon 9 cannon origin propos algorithm parallel comput connect twodimension mesh gener cannon algorithm larger blockdistribut matric due dekel nassimi sahni 12 algorithm also gener hypercub interconnect topolog fox otto hey 13 describ dierent algorithm unlik cannon algorithm use broadcast anoth 2d algorithm propos agarw gustavson zubair 3 independ almost simultan van de geijn watt 37 algorithm call summa use mani broadcast rel small matrix piec allow broadcast pipelin occur concurr comput storag requir 2d algorithm proport size matric squar matric amount memori per processor proport n 2 p clearli 3n 2 p word per processor necessari store 14 dror ironi sivan toledo alexand tiskin multiplicand product 2d algorithm eg summa need storag beyond storag requir matric simpler 2d algorithm block implement cannon algorithm requir addit word per processor order store two block two block b reduc 2 p break commun phase mani small messag possibl result increas commun overhead next theorem show 2d algorithm asymptot optim amount commun per processor algorithm use word memori per processor must perform per processor order keep theorem simpl state prove squar matric theorem 41 2d commun lower bound consid convent multipl two n n matric p processor distributedmemori parallel comput processor n 2 p word local memori least one processor must send receiv least word proof theorem 31 amount commun least one processor bound commun lower bound matrix multipl 15 inequ reli fact p 12 4 5 extend tradeoff n 2 2p 23 tradeo section 3 fail provid meaning bound n 2 2p 23 regim may even singl full phase sens proof lemma 31 sinc proof lemma 31 take account either amount commun last phase commun necessari input replic output combin provid use bound case section analyz amount commun must perform includ commun necessari output combin still input replic show regim amount commun per processor bound match asymptot upper bound achiev 3d algorithm use input replic algorithm reduc commun tradit 2d algorithm although dekel nassimi sahni 12 perhap rst propos 3d algorithm algorithm communicationeci total number word commun n 3 communicationeci 3d algorithm rst propos berntsen 6 aggarw chandra snir 5 time berntsen paper submit public 1988 paper aggarw chandra snir present confer 1988 essenti algorithm 5 propos later independ gupta kumar 14 johnsson 19 berntsen algorithm somewhat complex rest aggarw chandra snir also prove amount commun per processor matrix multipl algorithm must perform sharedmemori parallel comput explain introduct bound appli matrix multipl distribut memori machin bound reli privat cach processor empti comput begin contrast distributedmemori machin matric typic alreadi distribut matrix multipl subroutin invok main result section hing follow lemma lemma 51 consid convent multipl two n n matric p processor distributedmemori parallel comput consid processor word local memori perform least n 3 p elementari multipli cation let processor must send receiv least word proof na theorem statement hold sinc element resid processor local memori comput begin rest must receiv processor argument hold nb theorem statement hold sinc processor must send contribut least n 2 p 23 element c processor na nb nc less claim three quantiti must greater commun lower bound matrix multipl 17 let w number multipl processor perform use lemma 22 notat 1 1 fact na nb less therefor ident argument show express 2 also bound na nb number element c processor comput without contribut processor small everi c ik processor must access entir ith row entir kth column b na nb less processor comput n n element c suppos processor particip comput c ik comput c ik resid processor end comput processor must receiv contribut c ik least one processor c ik resid anoth processor processor must sent contribut processor either way one word data must either receiv sent c ik therefor processor must send receiv least word particip comput element c subtract 3 2 hypothes p rst two inequ true sinc third hold sinc p 128 impli p 23 turn impli show number word must sent receiv least claim state main result section proof essenti theorem 31 omit theorem 51 3d commun lower bound consid convent multipl two n n matric p processor distributedmemori parallel comput processor n 2 p 23 word local memori least one processor must send receiv least min word commun lower bound matrix multipl 19 6 bisectionbandwidth bound section analyz amount data must cross bisect distributedmemori parallel comput partit memoryprocessor node two subset establish lower bound amount data must cross cut separ subset commun network comput assum element input matric store exactli distribut memori machin input evenli split subset inde allow replic input matric output comput without commun across bisect exampl 3d algorithm perform commun across bisect cut network follow initi data replic phase anoth way deriv lower bound commun across cut appli lower bound section 4 5 group processor bound also bound amount commun group p processor must perform p p processor machin commun must transmit edg cut commun network two processor group henc bound amount commun must travers cut network techniqu howev unlik provid use bound larg p say gener memorycommun tradeo degener special bound theorem 41 51 hold larg p therefor need specic bound commun across bisect cut theorem assum matric b evenli distribut proof easili modi show asymptot bound also appli two processor subset initi store n 2 element n 2 element b constant 1 2 1 2 complex proof would requir theorem 61 consid convent multipl two n n matric p processor distributedmemori parallel comput input element initi store local memori exactli one processor least word must transfer across cut split input distribut multiplicand b evenli proof let consid cut commun network split node two subset hold exactli n 2 2 element n 2 2 element b n 2 element n 2 element b transfer across cut theorem statement hold otherwis claim subset machin comput element c sum product ij b jk comput local comput element requir access entir row entir column b n 2 element b cross cut subset access n row column b comput element c henc commun lower bound matrix multipl 21 element c must comput two subset machin togeth mean least mani word must cross cut sinc 13 34 theorem statement hold 7 io lower bound section use lemma 22 bound number compulsori capac cach miss matrix multipl establish lower bound number word must transfer slow memori fast cach arithmet instruct access data cach result new show proof techniqu use parallel commun bound appli analysi cach miss specic bound prove asymptot prove hong kung 17 toledo 36 bound howev specifi constant unlik hong kung result state use asymptot notat constant slightli stronger given 36 proof techniqu similar eect use toledo proof techniqu use lemma 22 simpli structur proof lower bound use lax memorysystem model equival hong kung redblu pebbl game therefor appli cach organiza tion lower bound also match asymptot perform recurs matrix multipl block matrix multipl assum block size chosen appropri cach fulli associ use lru replac polici matrix multipl algorithm whose asymptot perform match lower bound old comput rutledg rubinstein 31 30 describ librari block matrix subroutin design togeth herbert f mitchel implement univac rstgener comput 22 dror ironi sivan toledo alexand tiskin becam oper 1952 mckeller coman 28 provid rst rigor analysi data reus matrix comput includ matrix multipli cation show block algorithm transfer fewer word fast slow memori algorithm oper row column highqual implement ioecient matrixmultipl algorithm wide avail frequent use 4 2 7 11 16 20 23 21 22 24 25 38 proof next theorem similar proof lemma 31 theorem 71 consid convent multipl two n n matric comput larg slow memori fast cach contain word arithmet oper perform word cach number word move slow memori fast cach least proof decompos schedul comput phase phase begin total number word move memori cach exactli thu phase except perhap last phase exactli word transfer memori cach number na element processor may oper upon phase 2m sinc one element must either resid cach phase begin must read cach phase argument show nb 2m dene element c ik product c live phase processor comput ij b jk k phase partial sum contain ij b jk either resid cach end phase written slow memori phase number nc live element c phase commun lower bound matrix multipl 23 2m sinc live element either use one word cach end phase written slow memori lemma 22 show number elementari multipl phase nanbnc 12 2 total number elementari multipl algorithm n 3 therefor number full phase phase exactli word transfer least total number word transfer least conclud proof next corollari show matric sever time larger cach number cach miss proport n 3 12 constant corollari essenti exampl pick stronger bound size matric rel cach could prove stronger bound number cach miss corollari 71 io lower bound 17 condit theorem 71 assum n number word must transfer cach least proof n 32 number word must transfer least n 2pd r f februari 2 2004 8 conclus present rigor lower bound amount commun distributedmemori parallel matrix multipl algorithm must perform bound hold directedacyclicgraph dag model convent matrix multipl nari summat dag allow summat order bound hold 3 matrix multipl algorithm strassen hold case arbitrari comput matrix element allow even elementari product comput explicitli main signic result rigor valid algorithmdesign long suspect 2d algorithm asymptot optim littl replic allow 3d algorithm asymptot optim replic allow therefor search ecient algorithm must concentr improv constant involv eort design nonconvent algorithm specic domain use compress nondag techniqu anoth import conclus research 3d algorithm somewhat unlik becom competit bound show asymptot reduct commun rel 2d algorithm exceed factor p 16 typic machin size valu unlik high enough make replic protabl note although author found 3d algorithm faster 2d algorithm practic 1 nearli wide use exist commun lower bound matrix multipl 25 librari implement 2d algorithm also note eort rst two author design 3d factor algorithm suggest constant 3d algorithm high constant higher triangular factor matrix multipl 18 acknowledg thank two anonym refere help comment suggest sivan toledo support part ibm faculti partnership award grant 57200 906099 israel scienc foundat found israel academi scienc human r threedimension approach parallel matrix multipl exploit function parallel power2 design highperform numer algorithm improv perform linear algebra algorithm dens matric use algorithm prefetch commun complex pram commun ecient matrix multipl hypercub optim matrix multipli use phipac portabl geometr inequ cellular comput implement kalman parallel matrix graph algorithm matrix algorithm hypercub scalabl matrix multipl algorithm parallel comput perform intel tflop supercomput io complex redblu pebbl game trade replic commun parallel distributedmemori dens solver minim commun time matrix multipl mul tiprocessor local basic linear algebra subroutin lbla connect machin system cm200 local basic linear algebra subroutin lbla cm55e inequ relat isoperimetr inequ privat commun high order matrix comput univac matrix algebra program univac gaussian elimin optim bulksynchron parallel random access machin survey outofcor algorithm numer linear algebra robert van de geijn jerrel watt automat tune linear algebra softwar tr commun complex pram minim commun time matrix multipl multiprocessor improv perform linear algebra algorithm dens matric use algorithm prefetch exploit function parallel power2 design highperform numer algorithm highperform matrixmultipl algorithm distributedmemori parallel comput use overlap commun threedimension approach parallel matrix multipl optim matrix multipli use phipac bulksynchron parallel random access machin survey outofcor algorithm numer linear algebra organ matric matrix oper page memori system introduct algorithm high order matrix comput univac bulksynchron parallel multipl boolean matric io complex automat tune linear algebra softwar cellular comput implement kalman filter algorithm