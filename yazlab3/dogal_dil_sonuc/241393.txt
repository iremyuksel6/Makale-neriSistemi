block distribut memori model abstractw introduc comput model develop analyz parallel algorithm distribut memori machin model allow design algorithm use singl address space assum particular interconnect topolog captur perform incorpor cost measur interprocessor commun induc remot memori access cost measur includ paramet reflect memori latenc commun bandwidth spatial local model allow initi placement input data pipelin prefetchingw use model develop parallel algorithm variou data rearrang problem load balanc sort fft matrix multipl show algorithm achiev optim near optim commun complex simultan guarante optim speedup comput complex ongo experiment work test evalu algorithm thu far shown promis result b introduct parallel process promis offer quantum leap comput power like substanti impact variou aspect comput field particular exploit investig wide rang call grand challeng problem scienc engin wide recogn 23 import ingredi success technolog emerg comput model use algorithm develop accur predict perform algorithm real machin take similar view 24 comput model bridg model link two layer hardwar softwar exist comput model tend bias toward one layer except except bulk synchron parallel bsp model advoc valiant 24 one except paper introduc comput model specif attempt bridg model share memori singl address program model distributedmemori messag pass architectur distribut memori system configur singl address space usual refer scalabl share memori multiprocessor machin achiev scalabl distribut memori architectur simpl program style provid singl address space model also use predict perform data parallel algorithm run distribut memori architectur sinc comput model predict perform real machin start discuss basi measur commun cost incur access remot data indic 8 hardwar organ massiv parallel processor mpp seem converg toward collect power processor connect commun network model complet graph commun subject restrict impos latenc bandwidth properti network accord common ganiz commun differ processor handl point topoint messag whose rout time control paramet relat network latenc processor commun bandwidth overhead prepar me sage network capac model avoid descript exact structur network sinc algorithm exploit specif featur network less like robust enough work well varieti architectur adapt easili possibl futur technolog chang howev program machin messagepass level impos heavi burden programm make algorithm develop evalu quit complic hand dataparallel sharedmemori program model appeal term eas use term close relationship sequenti program model assum singl address space block distribut memori bdm model introduc next section captur perform share memori singl address space algorithm incorpor cost measur interprocessor commun caus remot memori access cost model use latenc commun bandwidth processor sinc remot memori access involv transmiss packet typic contain number consecut word model encourag use spatial local incorpor paramet repres cost associ access consecut word cost incur even singl word need model allow initi placement input data includ memori latenc hide techniqu pipelin prefetch sinc measur amount local comput amount commun separ abl normal commun cost drop one paramet make analysi correspond algorithm simpler use model develop parallel algorithm variou data rearrang problem load balanc sort ing fast fourier transform fft comput matrix multipl show algorithm achiev optim near optim commun complex simultan guarante optim speedup comput complex next section provid detail model section 3 describ collect algorithm handl data rearrang occur frequent share memori algorithm load balanc problem address section 4 commun effici algorithm present section 5 devot present effici algorithm sort fft matrix multipl result algorithm seem share common structur highperform algorithm test real machin 2 block distribut memori bdm model comput model block distribut memori bdm defin term four paramet p oe see later paramet oe drop without loss gener paramet p refer number pro cessor processor view unit cost random access machin ram addit processor interfac unit interconnect network handl commun among differ processor data commun processor via pointtopoint messag messag consist packet hold word consecut locat local processor memori sinc assum share memori program model request remot locat involv prepar request packet inject packet network recept packet destin processor final send packet contain content consecut locat includ request valu back request processor model cost handl request remot locat read write formula maximum latenc time take request processor receiv appropri packet oe rate processor inject receiv word network moreov processor send receiv one packet time result note follow two observ first permut p element remot memori request issu processor destin processor p complet moe time processor simultan second k remot access request issu k distinct processor destin processor requir k moe time complet addit make assumpt rel order request complet current interconnect network multiprocessor use sever hardwar softwar techniqu hide memori latenc model allow pipelin prefetch hide memori latenc particular k prefetch read oper issu processor complet underli commun model bdm consist logp postal model 8 13 5 addit paramet incorpor spatial local howev model allow lowlevel handl messag pass primit except implicitli data access particular algorithm written model specifi initi data placement among local memori p processor use processor id refer specif data item use synchron barrier synchron activ variou processor whenev necessari remot data access charg accord commun model specifi synchron barrier make assumpt bdm model provid primit oper two main reason make assumpt first barrier implement hardwar effici rel small cost second make latenc paramet larg enough account synchron cost result commun cost conserv side affect overal structur result algorithm complex parallel algorithm bdm model evalu term two measur comput time comp commun time tcomm measur comp refer maximum local comput perform processor measur standard sequenti ram model commun time tcomm refer total amount commun time spent overal algorithm access remot data main goal design parallel algorithm achiev optim nearoptim comput speedup sequenti complex problem consider way total commun time tcomm minim sinc tcomm treat separ comp normal measur divid oe underli commun model bdm view postal model 5 ad paramet reflect spatial local henc access oper remot locat take time k prefetch read oper execut time note paramet view upper bound capac interconnect network ie upper bound maximum number word transit processor estim bound commun time make simplifi reason assumpt integr multipl believ local import factor taken consider design parallel algorithm larg scale multiprocessor incorpor paramet model emphas import spatial local notion processor local also seem import current multiprocessor architectur architectur tend hierarch henc latenc much higher access processor hierarchi close featur incorpor model modifi valu reflect cost associ level hierarchi need use remot memori access done similar fashion memori hierarchi model studi 2 sequenti processor howev paper opt simplic decid includ processor local consider sever model discuss literatur logp postal model refer earlier relat bdm model howev signific differ model model exampl asynchron pram 9 block pram 1 assum presenc share memori intermedi result held particular assum data initi store share memori make data movement oper consider simpler model anoth exampl direct connect machin dcm latenc 14 use messag pass primit particular model allow pipelin prefetch bdm model 3 basic algorithm data movement design commun effici parallel algorithm depend exist effici scheme handl frequent occur transform data layout section consid data layout specifi twodimension array say size q theta p column contain subarray store local memori processor transform pi layout map element layout pia necessarili size present optim near optim algorithm handl sever transform includ broadcast oper matrix transposit data permut algorithm describ determinist except algorithm perform gener permut start address sever broadcast oper simplest case broadcast singl item number remot locat henc layout describ onedimension array assum element a0 copi remain entri view concurr read oper locat a0 execut processor next lemma provid simpl algorithm solv problem later use algorithm deriv optim broadcast algorithm lemma 31 given pprocessor bdm array a0 resid processor p j element a0 copi remain entri time proof simpl algorithm consist round pipelin rth round processor p j read aj a0 copi aj sinc round realiz prefetch read oper result commun complex readi follow theorem essenti establish fact kari balanc tree broadcast algorithm best possibl recal earlier made assumpt integr multipl theorem 31 given pprocessor bdm item processor broadcast remain processor 2d log p log e commun time hand broadcast algorithm use read write synchron barrier instruct requir least log p log log p commun complex 4 proof start describ algorithm let k integ determin later algorithm view kari tree root locat a0 dlog k pe round first round a0 broadcast locat use algorithm describ lemma 31 follow synchron barrier second round element locat broadcast distinct set locat commun cost incur round given 31 therefor total commun cost tcomm set md log p log log e next establish lower bound state theorem broadcast algorithm use read write synchron barrier instruct view oper phase phase end synchron barrier whenev singl phase suppos phase amount commun execut phase least maximum number copi read processor phase henc total amount commun requir least note end phase desir item reach remot locat follow end phase desir item reach processor must 1 commun time minim k logk1 commun time least logk1 complet proof theorem prove follow claim logk1 log k 1 proof claim let logk1 logk1 logk1 case decreas f 2 k increas rang claim follow easili note f 1 log 4 logarithm base 2 unless otherwis state case show fk increas k r1 show 1 note sinc k least larg posit nonzero integ valu k henc fk f claim follow 2 sum p element pprocessor bdm comput 2d log p log e commun time use similar strategi base observ easi show follow theorem theorem 32 given n number distribut equal among p processor bdm comput sum n log time 2d log p log e commun time comput time reduc n anoth simpl broadcast oper processor broadcast item remain processor oper execut minf time shown next lemma lemma 32 given pprocessor bdm array a0 distribut one element per processor problem broadcast element processor done minf commun time proof bound follow simpl algorithm describ lemma 31 p significantli larger use follow strategi use previou algorithm processor element next block element broadcast circular fashion appropri p processor one verifi result commun complex 2 next data movement oper matrix transposit defin follow let q p let p divid q evenli without loss gener data layout describ suppos rearrang layout 0 first column 0 contain first qp consecut row laid row major order form second column 0 contain second set qp consecut row clearli correspond usual notion matrix transpos effici algorithm perform matrix transposit bdm model similar algorithm report 8 round fulli pipelin use prefetch read oper first round appropri block qp element ith column read processor p i1modp appropri locat second round appropri block data column read processor p i2modp result total commun time given pm amount local comput oq clearli algorithm optim whenev pm divid q henc follow lemma lemma 33 q theta p matrix transposit perform pprocessor bdm pm e bound reduc next discuss broadcast oper block n element resid singl processor p processor describ two algorithm first suitabl number n element rel small second suitabl larg valu n algorithm base circular data movement use matrix transposit algorithm detail given proof next theorem theorem 33 problem broadcast n element processor p processor complet 22d log p log use kari balanc tree algorithm hand problem solv 2 pm e commun time use matrix transposit algorithm proof first algorithm use kari tree singl item broadcast algorithm describ theorem 31 1 use matrix transposit strategi distribut n element broadcast among k processor processor receiv contigu block size n k view p processor partit k group group includ exactli one processor contain block item broadcast procedur repeat within group similar revers process gradual read n item processor forward backward phase carri use cyclic data movement matrix transposit algorithm one check commun time bound follow km log p log pm broadcast n element 2 pm commun time use matrix transposit algorithm lemma 33 twice distribut n element among p processor processor receiv block size second time circul block processor 2 problem distribut n element singl processor solv use first half either two broadcast algorithm henc follow corollari corollari 31 problem distribut n element one processor processor processor receiv n p element complet minf2d log p log pm eg commun time 2 final address follow gener rout problem let n array n element initi store one column per processor pprocessor bdm machin element consist pair datai index processor data reloc assum ff n element rout singl processor constant ff 1 describ follow random algorithm complet rout 2 n comput time c constant larger maxf1 1 ffg complex bound guarante hold high probabl probabl posit constant ffl long 6 logarithm base e overal idea algorithm use variou random rout algorithm mesh follow close scheme describ 20 random rout mesh bound queue size describ algorithm introduc terminolog use auxiliari array 0 size cn theta p manipul data intermedi stage hold final output c ffg column 0 held processor array 0 divid p equal size slice slice consist cn consecut row 0 henc slice contain set cn consecut element column set refer slot readi describ algorithm algorithm random rout input input array a0 n element consist pair datai processor index data rout processor destin ff n p element constant ff output output array hold rout data c constant larger maxf1 ffg begin processor p j distribut randomli n element p slot jth column 0 jth slice store jth processor processor p j distribut local cn element everi element form resid slot perform matrix transposit 0 henc jth slice layout gener end step 3 resid p j next two fact allow us deriv complex bound random rout algorithm analysi assum lemma 34 complet step 1 number element slot cn high probabl c pproof procedur perform processor similar experi throw n bin henc probabl exactli cn ball place particular bin given binomi distribut use follow chernoff bound estim tail binomi distribut obtain probabl particular bin cn ball upper bound therefor probabl bin cn ball bound lemma follow 2 lemma 35 complet step 3 number element processor destin processor cn high probabl ffproof probabl element assign jth slice end step 1 1 henc probabl cn element destin singl processor fall jth slice bound b cn processor destin ffn element sinc p slice probabl cn element processor destin processor bound pe gamma c henc lemma follow 2 previou two lemma easi show follow theorem theorem 34 rout n element store initi n array pprocessor bdm ff n p element destin processor complet high probabl 2 comput time c constant larger maxf1 ffg remark sinc assum 6 effect paramet domin bound c n n balanc balanc load among processor import sinc poor balanc load gener caus poor processor util 19 load balanc problem also import develop fast solut basic combinatori problem sort select list rank graph problem 12 21 problem defin follow load processor p given array repres number use element p max n suppos redistribut element p processor n p element store processor assum without loss gener p divid n section develop simpl effici load balanc algorithm bdm model correspond commun time given tcomm 5 overal strategi describ next overal strategi load balanc algorithm describ follow first load balanc problem n 01 n store p array consid henc output array 0 array 0 may km pm step 2 3 next processor element appropri processor step 4 detail given next algorithm assum simplic n power two algorithm load balanc processor p contain input array 0 element redistribut way n p element store output array 0 begin processor p read held remain processor step perform 2 commun time lemma 32 perform follow local comput 21 22 comput prefix sum 23 els remark index chosen way read n element p read n element indic l r use next step determin locat n p n element move p notic step take op comput time read appropri number element l r respect remark step need special attent sinc case set consecut processor read element one processor say p h processor p read appropri element p notic h npgammam 1 step divid two substep follow first substep read element substep done commun time appli corollari 31 second substep rest rout perform use sequenc read prefetch oper sinc remain element processor access singl processor henc total commun time requir step n read remain element appropri processor correspond indic l 0 comput local step 2 remark step complet processor read element processor read prefetch thu one show follow theorem theorem 41 load balanc n element p processor element resid processor realiz 5 commun time 2 5 sort fft matrix multipl section consid three basic comput problem sort fft matrix multipl present commun effici algorithm solv problem bdm model basic strategi use wellknown implement model requir care attent sever technic detail 51 sort first consid sort problem bdm model three strategi seem perform best model 1 column sort 15 2 sampl sort see eg 6 relat refer 3 rotat sort 18 turn column sort algorithm best n sampl sort rotat sort better column sort algorithm particularli use n implement 4 time column sort algorithm practic sinc constant term grow exponenti n decreas sampl sort algorithm provabl effici 6 implement 3 p gamma 1d 5 time n log n probabl rotat sort algorithm implement 8 comput time whenev n 6p 2 begin descript column sort algorithm column sort column sort algorithm gener oddeven mergesort describ seri elementari matrix oper let q theta p matrix element initi entri matrix one n element sort complet algorithm sort column major order form column sort algorithm eight step step 1 3 5 7 element within column sort step 2 4 entri matrix permut permut similar matrix transposit lemma 33 sinc case two step done 2 commun time step 6 8 consist qshift oper clearli done commun time henc column sort algorithm implement model within 4 thu follow theorem theorem 51 given n element n p element store local memori set p processor n element sort column major order form 4 comput time 2 second sort algorithm consid section sampl sort algorithm random algorithm whose run time depend input distribut key depend output random number gener describ version sampl sort algorithm sort bdm model 3 em comput time whenev complex bound guarante high probabl use random rout algorithm describ section 3 overal idea algorithm use variou sampl sort algorithm algorithm describ follow close scheme describ 6 sort connect machin cm2 howev first three step differ algorithm sampl sort input n element distribut evenli pprocessor bdm output n element sort column major order begin processor p randomli pick list 5 ln n element local memori processor p read sampl processor henc processor 5p ln n sampl execut step processor p sort list 5p ln n sampl pick 5 sampl processor p partit n element set ij belong interv jth pivot j 1st pivot 0th pivot gamma1 pth pivot 1 processor p read element p set 0i use algorithm random rout processor p sort element local memori follow lemma immedi deduc result 6 lemma 51 ff 0 probabl processor contain element step 5 ne next show follow theorem theorem 52 algorithm sampl sort implement pprocessor bdm n log n 3 em time high probabl 6 proof step 2 done em commun time use techniqu similar use prove lemma 32 lemma 51 total number element processor read step 5 2 n element high probabl henc step 5 implement commun time high probabl use theorem 34 comput time step clearli n log n 6 theorem follow 2 rotat sort rotat sort algorithm 18 sort element mesh altern appli transform row column algorithm run constant number rowtransform columntransform phase 16 phase assum n 6p 2 naiv implement origin algorithm model requir 14 simpl permut similar matrix transposit 14 local sort within pro cessor slightli modifi algorithm algorithm implement model 8 simpl permut 14 local sort within processor sinc simpl permut perform model commun time algorithm implement 8 commun time n log n comput time bdm model simplic assum n 2t result gener valu n p slice subarray size p p theta p consist row l block subarray size p p theta p p consist posit j l r describ algorithm briefli detail appear 18 begin specifi three procedur serv build block main algo rithm procedur consist sequenc phase accomplish specif transform array procedur balanc input array size v theta w sort column downward b rotat row mod w posit right c sort column downward procedur unblock rotat row mod p p p p posit right b sort column downward procedur shear sort evennumb column downward oddnumb column upward b sort row right overal sort algorithm follow algorithm rotatesort 1 balanc input array size n p theta p 2 sort row right 3 unblock array 4 balanc slice p theta p p array lie side 5 unblock array 6 transpos array 7 shear array 8 sort column downward complet correct proof algorithm see 18 easili prove algorithm perform 14 local sort step within processor also prove simpl permut done time similar way lemma 33 step 1 3 5 6 done one simpl permut step 2 4 also done one simpl permut overlap second permut first permut step 3 5 respect origin step 7 repeat shear three time design remov six dirti row left step 5 henc step requir 6 simpl permut model sinc assum 6p length column larger row reduc number applic shear procedur step 7 transpos matrix step 6 thu sinc assumpt n 6p impli two dirti column execut step 6 one applic procedur shear enough step 7 remov two dirti column follow theorem theorem 53 given n 6p 2 element n element p processor bdm model n element sort column major order form 8 commun time n log n notic need repeat shear dlog1 e time step 7 remov dirti column commun time algorithm rotatesort k e sort algorithm given element integ 0 p o1 local sort need previou algorithm done n appli radix sort henc follow corollari corollari 51 pprocessor bdm machin n integ 0 p o1 sort column major order form n comput time 1 4 commun time n e 3 3 em commun time high probabl two sort algorithm worth consid 1 radix sort see eg 6 relat refer 2 approxim median sort 2 22 radix sort perform model b r r tcomm n p commun time b number bit represent key r algorithm examin key sort rbit time tcomm n p commun time rout gener permut n element henc bound corollari appli approxim median sort similar sampl sort random use processor sort element processor done model n log n 3 commun time n 52 fast fourier transform next consid fast fourier transform fft comput algorithm comput discret fourier transform dft ndimension complex vector x defin co 2 gamma1 log n arithmet oper implement bdm model base follow wellknown fact eg see 17 let ndimension vector x store n p theta p matrix x rowmajor order form p arbitrari integ divid n dft vector x given w n submatrix w n consist first n row first p column twiddlefactor scale elementwis multipl notic result output p theta n matrix hold vector w n x column major order form equat 1 interpret comput dft n p column x follow twiddlefactor scale final comput dftp row result matrix let bdm machin p processor p divid n n p 2 initi data layout correspond row major order form data ie local memori processor p hold x 1 algorithm suggest 1 perform follow three stage first stage involv local comput dft size n p processor follow twiddlefactor scale elementwis multipl w n second stage commun step involv matrix transposit outlin lemma 33 final n local fft size p suffici complet overal fft comput n point therefor follow theorem theorem 54 comput npoint fft done n log n divid n commun time reduc remark algorithm describ 8 also implement model within complex bound howev algorithm somewhat simpler implement 2 53 matrix multipl final consid problem multipli two nthetan matric b assum log n partit matric b p 2 3 submatric say ij b ij size theta n assum without loss gener p 1 3 integ divid n simplic view processor indic arrang cube size p 1 3 theta p 1 3 theta p 1 given p ijk 0 show product comput n 3 comput time 62d log p commun time overal strategi similar one use 1 10 relat experiment result support effici algorithm appear 10 present algorithm establish follow lemma lemma 52 given p matric size n theta n distribut one matrix per proce sor sum comput 2 comput time 22d log p log commun time proof partit p processor p k group group contain processor 1 use matrix transposit algorithm put first set nk row matrix group first processor group second set nk row second processor processor add k submatric local point processor group hold n k theta n portion sum matrix correspond initi matric store processor continu strategi ad set k submatric within group k processor howev time submatric partit along column result submatric size n theta n repeat procedur log p log e time time processor n portion overal sum matrix collect submatric singl processor complex bound follow proof theorem 33 2 algorithm matrix multipl input two n theta n matric b p n 3 log n initi submatric ij b ij store processor p ij0 0 output processor p ij0 hold submatrix c ij c ij size n theta n begin block ij b jk initi store processor respect block read concurr p 13 processor step perform 42d log p commun time use first algorithm describ theorem 33 processor multipli two submatric store local memori step done n 3 comput time 0 sum product submatric p 1processor p ijk comput store processor p ij0 step done n 2 comput time 22d log p commun time use algorithm describ lemma 52 therefor follow theorem theorem 55 multipli two n theta n matric complet n 3 time 62d log p commun time pprocessor bdm model log n 2 remark could use second algorithm describ theorem 33 execut step 1 3 matrix multipl algorithm result commun bound would 6 r commun latenc pram comput hierarch memori block transfer april processor architectur multiprocess design broadcast algorithm postal model messagepass system multipl messag broadcast postal model comparison sort algorithm connect machin cm2 overview ksri comput system logp toward realist model parallel comput asynchron pram algorithm scalabl parallel algorithm matrix mul tiplic cachecoher protocol data diffus machin load balanc rout hypercub relat network optim broadcast summat logp model complex theori effici parallel algorithm tight bound complex parallel sort stanford dash multiprocessor comput framework fast fourier transform sort constant number row column phase mesh probabilist analysi local maintain load balanc algorithm optim rout algorithm meshconnect processor array effici algorithm list rank solv graph problem hypercub parallel sort regular sampl report purdu workshop grand challeng comput architectur support high perform comput bridg model parallel comput tr ctr david r helman david bader joseph jj parallel algorithm person commun sort experiment studi extend abstract proceed eighth annual acm symposium parallel algorithm architectur p211222 june 2426 1996 padua itali assefaw hadish gebremedhin moham essadi isabel gurin lassou jen gustedt jan arn tell pro model design analysi effici scalabl parallel algorithm nordic journal comput v13 n4 p215239 decemb 2006