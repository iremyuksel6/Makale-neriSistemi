perform predict evalu parallel process numa multiprocessor effici basic oper numa nonuniform memori access multiprocessor determin parallel process perform numa multiprocessor author present sever analyt model predict evalu overhead interprocessor commun process schedul process synchron remot memori access network content memori content consid perform measur support model analys sever numer exampl done bbn gp1000 numa sharedmemori multiprocessor analyt experiment result give comprehens understand variou effect import effect use numa sharedmemori multiprocessor result present use determin optim strategi develop effici program environ numa system b distribut memori multicomput environ data share commun conduct messagepass network busbas share memori multiproc sor encor multimax sequent symmetri alway make uniform memori access uma share data exclus use bu per data access simpl bu structur limit size uma multiprocessor small scale exampl cessor numa architectur share memori environ built distribut architectur processor local memori also abl access memori model switch network therefor numa architectur scale larg number processor share memori multiprocessor design exampl current numa architectur includ bbn butterfli famili see eg 35 16 23 cedar univers illinoi see eg 14 26 ibm rp3 see eg 21 cm plu carnegiemellon univers see eg 9 17 22 hector see 25 paradigm see 11 bbn butterfli machin system commerci avail rest research model architectur 11 program model numa architectur program model numa architectur classifi three type distribut mem partial share memori fulli share memori distribut program model node view complet comput support processor local memori io facil physic one board connect node system import factor effici distribut memori model effect data exchang among mani node partial share memori program model provid noncach access share memori program code privat data store local memori program requir partit applic across node load time explor processor local best provid dynam process schedul run time share memori synchron primit barrier support synchron processor end group parallel task fulli share memori program model impli processor access memori modul time except one except singl memori modul access one processor simultan user point view processor share singl pool memori differ memori access time schedul mechan support schedul process dynam among processor run time sever relat studi conduct understand improv parallel process perform numa multiprocessor larow elli see 19 take experiment approach compar widerang memori manag polici target numa system bbn gp1000 system experi conclud placement movement code data crucial numa perform perform gener multistag interconnect network omega network evalu analyt see eg 6 7 15 analysi work independ numa architectur although multistag interconnect network commonli use numa system perform factor numa multiprocessor exampl bbn gp1000 data access time schedul overhead other measur variou applic program see eg 10 30 memori architectur interconnect network becom complex perform predict evalu numa architectur becom difficult paper studi three type program model support numa multiprocessor architectur present sever analyt model measur predict evalu overhead interprocessor commun process synchron process schedul remot memori access network content memori content consid perform measur support model analys differ measur done bbn gp1000 numa share memori multiprocessor goal provid reason accur numa perform model incorpor interconnect network effect numa system effect analys experi 12 perform model perform analys start amdahl law 1 simplest form execut time versu number processor p model view separ program perfectli parallel time section p strictli sequenti time section run p node multiprocessor amdahl law incomplet model evalu parallel process perform practic model ignor sever signific effect commun synchron memori manag memori network content other amdahl model may modifi ad overhead function term p includ practic effect modifi amdahl model use evalu parallel process perform differ architectur vector supercomput see eg 18 distribut memori multicomput hypercub see eg 13 uma share memori multiprocessor see eg 28 overhead function p affect structur applic influenc necess commun task dispatch algorithm use control assign process processor well hardwar softwar mechan commun synchro nizat similar distribut memori multicomput commun delay major overhead distribut program model appli numa architectur comput bottleneck partial share memori program model barrier synchron set end group parallel task typic parallel comput process share memori program model numa architectur describ follow step system spend amount time gener parallel task place share memori visibl processor interconnect network processor turn enter critic region select assign task end comput time expend wait last processor finish parallel task anoth import sourc runtim overhead numa multiprocessor share memori model come remot memori access ie processor access read write memori model local therefor distribut memori program model overhead function mainli contribut commun cost barrier synchron remot memori access partial share memori model process schedul share memori program model respect figur 1 twolevel interconnect network connect 16 processor 16 memori modul 13 bbn gp1000 gp1000 see 35 base origin butterfli architectur mimd system incorpor 256 motorola 68020 processor node connect via multistag interconnect switch network exampl 16 processor gp1000 system describ figur 1 network compos 4 2 4 switch form plog 4 p switch interconnect p number processor connect bandwidth path switch processor node 68851 page memori manag unit virtual memori process memori machin share among processor way processor node includ 4 mbyte memori access processor system via network memori locat physic local host processor although global access processor system memori access processor memori direct path call local access memori access processor memori model network call remot access time ratio local access remot access processor activ gp1000 115 depend type access see eg 10 gp1000 provid parallel program environ call uniform system see 5 parallel task may distribut process without regard physic locat data associ task uniform system uma uniform memori access processor uniform memori access time data share memori program model implement numa architectur gp1000 thu uniform system use share memori data structur call task gener specifi parallel oper approach processor manag implement treat processor equival worker processor work task finish current task look next task perform best possibl load balanc dynam total ignor processor local memori manag mechan uniform system make global share data visibl process allow program control data alloc provid mean copi block data one memori anoth evalu measur numa perform base four major overhead sourc commun barrier synchron process schedul remot memori access provid sever time model experiment result section 2 present perform evalu distribut memori model commun overhead messag pass measur gp1000 multiprocessor section 3 give two model evalu static dynam task schedul perform synchron overhead partial fulli share memori program model synchron cost dynam schedul overhead also measur gp1000 multiprocessor sever numer exampl remot access delay studi section 4 along analyt model experiment measur final summari given section 5 commun overhead numa multiprocessor system memori modul distribut interconnect network use connect processor local memori processor memori modul type architectur bbn gp1000 also support distribut memori multicomput environ data share commun conduct messagepass interconnect network messag pass pair node system rout number switch network content switch consid multilevel connect network use see figur 1 ff fi gp1000 1812 240 topolog 1000 215 tabl 1 alpha beta interprocessor commun gp1000 compar five type distribut memori multicomput head messag pass pair node ident thu basic commun time test distribut memori model measur time requir transmit messag packet one node anoth node network test also call echo test test node send messag echo node directli connect test node echo node receiv messag send back test node interprocessor commun time requir transmit messag two directli connect node may approxim express k number byte contain messag ff overhead startup time send packet fi bandwidth commun channel sbyte conduct echo test measur interprocessor commun overhead bbn gp1000 commun primit machin support set mach 1000 system call use differ size messag packet 1 byte 8k byte experi use least squar fit approxim ff fi tabl 1 give ff fi gp1000 compar five type distribut memori multicomput see eg 29 experiment result show messagepass gp1000 effici bandwidth commun channel fi one intel ipsc1 repres first gener hypercub multicomput startup time ff send packet 4 time longer one ipsc1 connect processor remot memori modul remot memori access establish two level switch therefor distribut program model bbn gp1000 prefer unless larg data set need exchang occasion see 24 3 process schedul model synchron overhead two major process schedul model avail numa multiprocessor preschedul partial share memori program model selfschedul fulli share memori program model evalu overhead two schedul respect give quantit comparison two model differ numer exampl section 31 preschedul barrier preschedul task preschedul assign processor load time process must wait synchron point call barrier slowest finish synchron barrier defin logic point control flow process must arriv allow proceed often use synchron processor end process group parallel task preschedul model thu consequ fluctuat execut time imbalanc task load maxim choos task load normal probabl distribut deriv simpl analyt time model predict effect imbalanc task load caus preschedul scheme model assum p processor begin work section simultan time take mean standard deviat oe assum mutual independ instant last processor complet work section w given thu keep task load balanc among independ process reduc oe reduc number barrier decreas potenti larg perform penalti caus preschedul process advantag preschedul dynam load schedul perform task distribut decis made determinist task process effici among processor degre imbalanc task load minim preschedul prefer simpl algorithm barrier synchron preschedul accumul counter barrier see eg 2 implement bbn gp1000 consist two lock share counter first lock control access share counter record number process arriv barrier counter must global share access serial share counter alloc local memori one processor process processor share counter arriv barrier point simpli atom oper counter local memori atom oper includ busywait type lock unlock immedi updat counter rest processor busywait access counter use remot memori access interconnect network process arriv barrier worst case situat occur processor arriv barrier time share counter updat sequenti order barrier synchron delay time unit numa share memori architectur may describ p number processor use atom time spent atom oper lock updat unlock counter remot memori access conduct processor respect gp1000 constant word remot memori access equal distant among processor use r repres ident remot access delay 32 becom linear function 33 simplifi fl repres critic section delay protect updat share counter local memori ffi overhead caus remot updat share counter interconnect network comput matrix dotproduct n 2 n matrix b vector n element gp1000 n row matrix distribut block processor processor hold copi b vector order measur overhead associ barrier implement minim fluctuat execut time multipl oe describ 31 evenli preschedul task among processor experi run program differ number processor 1 12 experi use least squar fit approxim fl ffi ideal barrier synchron overhead independ size evenli distribut dotproduct problem comput dotproduct problem differ size 120 240 480 1200 variabl differ approxim fl ffi use least squar fit differ size problem trivial get averag fl ffi experi obtain synchron overhead gp1000 imbalanc load comput cycl consum barrier two major sourc complet synchron overhead preschedul may express sum second term 31 33 effici barrier algorithm propos numa share memori architectur interest reader may refer 20 8 32 selfschedul share memori program order balanc process load task dynam schedul selfschedul processor runtim selfschedul algorithm consist processor fetch task one time requir mutual exclus access share variabl read modifi appropri data memori modul uma architectur busbas share memori multiprocessor processor requir exclus access share bu reach share memori numa architectur gp1000 access share memori perform interconnect network without network content problem multistag interconnect switch network provid uniqu path sourc processor destin memori modul pair howev path differ pair disjoint therefor conflict may occur simultan commun establish sever sourcedestin pair may degrad parallel perform consid comput job may divid n task requir averag comp unit time execut singl processor comput job execut p processor selfschedul routin creat initi task data structur place share memori visibl processor differ distanc processor numa archi tectur process spend init time unit initi task processor requir extra time unit access data schedul task may also denot constant r ident remot access delay one gp1000 addit processor requir overhead arri unit synchron barrier end comput arri unit spent notifi processor arriv final first schedul processor process task last termin program exit thu special processor need chek unit check processor arriv assum n integr multipl p parallel execut time numa share memori multiprocessor may describ first term 37 time pure spent comput rest term overhead schedul figur 2 give time line selfschedul 33 comparison two schedul model preschedul selfschedul provid static dynam load balanc scheme compar 36 38 overhead caus preschedul overhead selfschedul quantit equal oe p 2logp overhead preschedul quantit larger one selfschedul oe p overhead preschedul quantit less one selfschedul oe p figur 2 selfschedul exampl 8 task schedul run 4 processor oe standard deviat time task use one processor repres degre imbalanc task load base analysi varianc distribut task process expect larg dynam chang execut advantag use selfschedul accord 311 selfschedul decreas arriv time varianc cost schedul overhead 310 exist selfschedul gain 34 numer experi preschedul selfschedul numer experi conduct compar two schedul model group complex nonlinear circuit simul object circuit simul determin accur voltag current waveform circuit period time specifi user given topolog electr element circuit simul conduct multiprocessor one method partit circuit processor simul one set subcircuit concurr result circuit partit lead us solv special class nonlinear system equat block border structur use newton method n detail mathemat analys nonlinear block border equat reader may refer 27 circuit equat usual highli nonlinear newton step easili may result increas function norm addit mani block border equat result nearli singular singular jacobian iter process thu newton step need modifi dynam converg solut modif subsystem line search matrix perturb see eg 12 requir extra comput time predict static run program test circuit problem simul 741 opamp 27 use preschedul model block border equat 741 opamp circuit distribut among 1 2 4 node gp1000 respect addit function f q1 assign anoth node play control role comput load among differ node reason balanc static obtain circuit partit runtim simul subsystem perturb independ comput time node slightli differ use selfschedul model subcircuit system schedul runtim system subcircuit system data structur place share memori visibl processor differ distanc processor gp1000 use 1 3 processor respect comput comput perform schedul model given figur 3 experi show comput perform selfschedul model poor compar one preschedul model partit system well balanc runtim therefor dynam schedul becam real overhead multiprocess also simul analog filter connect 3 block 741 opamp circuit see 27 figur 3 preschedul selfschedul opamp 741 simul gp1000 12 subcircuit system gener 12 block equat analog filter distribut among 1 3 6 12 node gp1000 respect nonlinear system harder comput singl 741opamp system unbalanc block border system due singular subsystem runtim subsystem perturb quit often newton iter appli preschedul selfschedul model unbalanc system figur 4 give comput curv sinc preschedul abl handl dynam load schedul runtim selfschedul show effect solv system 4 remot memori access delay 41 background memori architectur becom complex interconnect network introduc nonuniform memori access remot memori access predict evalu numa system dynam environ becom difficult remot memori access delay measur bbn butterfli system processor memori modul pair without consid memori network content without consid random content see eg 3 10 howev real parallel process numa system remot memori access delay complic memori network content give analyt model predict averag remot memori access delay consider differ network memori architectur effect numa system figur 4 preschedul selfschedul analog filter connect 3 opamp 741 simul multistag switch interconnect network commonli effect use numa system bbn butterfli system ibm rp3 multiprocessor figur 1 show twostag switch network connect 16 processor 16 memori modul switch 4 input 4 output network content defin conflict two messag need access portion path time network design either block form nonblock form blockingnetwork protocol organ messag queue conflict traffic come standstil conflict messag sit hold path path clear next select messag proce problem block network call cascad effect new messag tend run block messag get block tie resourc switch increas chanc subsequ messag also block nonblock network greatli reduc traffic conflict practic see eg 23 conflict happen switch first messag retreat back sourc free path select altern rout random delay tri model base nonblockingnetwork architectur use numa system 42 model remot memori access gelenb 15 describ behavior remot memori access nonblock multistag interconnect network state transit diagram call drop approach see figur 5 processor make remot memori access formul request access set switch figur 5 state transit diagram remot memori access nstage interconnect network along path obtain switch abandon request point tri later time figur 2 state 0 repres processor quiescent state repres ongo success access state b repres processor drop request switch content make analyt model tractabl certain approxim assumpt necessari assum multiprocessor system processor ident uniform refer model differ uma concept urm uniform refer model impli processor make memori request global memori request direct memori modul probabl destin address memori request uniformli distribut among memori modul symmetr properti significantli simplifi model averag remot memori access delay estim make use semimarkov model length path n request state 1 n success obtain first switch path state go b 1th request success otherwis go state 1 process continu state n 1 reach switch request grant final goe state n 1 state 0 processor access memori modul releas path assum 0 rate number request per time unit quiescent processor make remot memori access 1 0 averag time spent processor state make access processor state 1 n assum request next switch averag time probabl success q follow notat use later mathemat work practic switch network therefor ident averag durat access denot 1oe processor return state 0 similarli use 1oe b denot averag time spent state b conflict detect processor return quiescent state base kirchhoff current law kcl flow balanc assumpt steadyst probabl associ state model may obtain follow equat steadyst probabl state n last equat deriv previou n 2 one solv system equat one addit equat base sum success fail probabl success probabl ith state q depend traffic condit express base steadyst probabl inputoutput size switch network steadyst probabl state k inputoutput size multistag interconnect network use substitut q get n new equat system equat abl solv get q probabl memori refer request may fail ith stage network averag delay unsuccess memori access caus either network content memori content success one averag delay remot access 4 probabl success remot access averag delay caus remot access one comput 43 experi remot memori access difficult use limit number experi cover case interpret 414 random content variou structur applic program howev remot memori access delay practic determin two import factor 1 delay establish connect path processor remot memori modul network switch 2 network content connect delay constant time unit without consid network content architectur depend exampl gp1000 spend 05 establish remot memori access connect 2level switch connect establish read write oper perform data commun rate 0125 everi 4bit see eg 3 network content basic determin remot access rate defin number remot access per time unit denot 41 construct two program measur compar remot memori access effect gp1000 one matrix multipl c2b one matrix addit n 2 n squar matric structur program design way singl oper multipl addit pair data need two remot memori access therefor number remot access matrix multipl addit 2 2 n 3 2 2 n 2 respect n size matric comput order compar remot memori access effect comput made number remot memori access two problem ident chose size matric addit n nm nm n matrix size addit nm size multipl figur 6 give remot access time two comput differ number processor size matrix multipl 80 716 matrix addit comput figur remot access time matrix addit matrix multipl gp1000 perform total approxim 1024210 3 time remot memori access gp1000 howev time spent remot access comput matrix addit almost twice much comput matrix multipl total time multipl oper perform matrix multipl program approxim number addit perform matrix addit program comput time ratio multipl oper addit oper mc68020 processor gp1000 17 thu remot memori access rate matrix addit program 17 time higher one matrix multipl give differ overal remot access time similar factor two program rune gp1000 plot figur 6 higher remot memori access rate higher chanc network content occur therefor remot memori access rate simpli use predict remot memori access delay 5 summari examin effect schedul synchron remot memori access parallel process perform numa share memori multiprocessor analyt model base gener numa machin develop test verifi gp1000 multiprocessor sever numer exampl analyt experiment result paper may use advic determin optim parallel process strategi effect use numa share memori multiprocessor develop effici parallel program environ run applic program current work includ develop graphic tool monitor tune perform numa multiprocessor base analysi model present paper acknowledg author wish thank p srinivasan w wu univers texa san antonio j zhou univers ohio multiprocessor tese technic discuss r valid singleprocessor approach achiev larg scale comput capabl effect synchron barrier multiprocessor perform bbn advanc comput inc bbn advanc comput inc bbn advanc comput inc design perform gener interconnect network perform multiprocessor interconnect network simpl mechan effici barrier synchron mimd machin perform evalu predict parallel algorithm bbn gp1000 paradigm highli scalabl sharedmemori multicomput architectur perform parallel processor cedar larg scale multiprocessor john wiley son overview butterfli gp1000 largescal parallel unix comput softwar manag cm distribut multiprocessor measur parallel processor perform experiment comparison memori manag polici numa multiprocessor barrier synchron multistag interconnect network ibm research parallel processor prototyp rp3 introduct architec ture cm modular multimicroprocessor behavior butterfli parallel processor presenc memori hot spot experiment studi differ program model bbn gp1000 hector hierarch structur share memori multiprocessor architectur cedar parallel supercomput parallel partit simul largescal circuit local memori mul ticomput perform measur model evalu variou effect share memori multiprocessor system effect interprocessor commun latenc multicomput distribut task process perform numa share memori multiprocessor tr effect synchron barrier multiprocessor perform design perform gener interconnect network perform multiprocessor interconnect network multiprocessor perform measur parallel processor perform paradigm hector perform measur model evalu variou effect share memori multiprocessor perform evalu predict parallel algorithm bbn gp1000 plu system effect interprocessor commun latenc multicomput experiment comparison memori manag polici numa multiprocessor ctr xiaodong zhang robert castaeda elisa w chan spinlock synchron butterfli ksr1 ieee parallel distribut technolog system technolog v2 n1 p5163 march 1994 l boyd johndavid wellman santosh g abraham edward davidson evalu commun perform mpp use synthet spars matrix multipl workload proceed 7th intern confer supercomput p240250 juli 1923 1993 tokyo japan xiaodong zhang robert castaeda elisa w chan spinlock synchron butterfli ksr1 ieee parallel distribut technolog system technolog v2 n1 p5163 march 1994 xiaodong zhang yong yan robert castaeda compar perform evalu hot spot content minbas ringbas sharedmemori architectur ieee transact parallel distribut system v6 n8 p872886 august 1995 k harzallah k c sevcik hot spot analysi larg scale share memori multiprocessor proceed 1993 acmiee confer supercomput p895905 decemb 1993 portland oregon unit state yongsheng song weim lin perform predict base loop schedul heterogen comput environ proceed 1997 acm symposium appli comput p413421 april 1997 san jose california unit state