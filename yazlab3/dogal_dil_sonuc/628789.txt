combin belief network neural network scene segment concern problem imag segment pixel assign one predefin finit number label bayesian imag analysi requir fuse togeth local predict class label prior model label imag follow work consid use treestructur belief network tsbn prior model paramet tsbn train use maximumlikelihood object function em algorithm result model evalu calcul effici code label imag number author use gaussian mixtur model connect label field imag data paper compar approach scaledlikelihood method local predict pixel classif neural network fuse tsbn prior result show higher perform obtain neural network evalu classif result obtain emphas maximum posteriori segment also uncertainti evidenc eg pixelwis posterior margin entropi also investig use condit maximumlikelihood train tsbn find give rise improv classif perform mltrain tsbn b introduct concern problem imag segment pixel assign one nite number class work appli imag outdoor scene class label sky road veget etc scene typic complex involv mani dierent object object highli variabl eg tree mean modelbas approach readili applic much work scene segment base approach rst segment whole imag region classifi region carri task success import classifi region use attribut also take account context region take account context handl two way either search consist interpret whole scene take account local context region nd 16 exampl wholescen method 34 29 localcontext method use 50 51 major problem approach process region creation unreli lead oversegment altern approach allow segment emerg along classic process formul bayesian framework use prior model repres knowledg like pattern label imag likelihood function describ relationship observ class label 1 two main type prior model investig call noncaus markov random eld mrf causal mrf statist imag model literatur graphic model commun two type model known undirect direct graphic model respect 21 earli work bayesian imag model concentr noncaus mrf see eg 3 13 27 one disadvantag model suer high comput complex exampl problem nding maximum posteriori map interpret given imag gener nphard altern causal mrf formul use direct graph commonli use form model treestructur belief network tsbn structur illustr figur 1 imag model standard depend structur quadtre one attract featur tsbn model hierarch multiscal natur longrang correl readili induc contrast noncaus mrf typic nonhierarch structur also shall see infer tsbn carri time linear number pixel use sweep tree leav root back graphic model literatur infer procedur known pearl messagepass scheme 35 algorithm also known upwarddownward algorithm 40 24 generalis tree standard baumwelch forwardbackward algorithm hmm see eg 37 one disadvantag tsbn random eld nonstationari exampl figur 1 common parent fourth fth pixel left x l root node whilst third fourth pixel share parent layer give rise blocki segment tsbn model use number author imag analysi task bouman shapiro 5 introduc model use discret label node imag segment task perez et al 36 discuss map mpm maximum posterior margin infer tsbn imag process 1 earli work direct carri feldman yakimovski 10 task lafert et al 19 20 extend model use multiscal featur pyramid imag decomposit use em algorithm paramet estim cheng bouman 6 investig trainabl multiscal model use decis tree compactli repres condit probabl tabl cpt model tsbn model also use continuouslyvalu gaussian process one two dimens generalis kalman lter model chain tree studi number group notabl prof willski group mit develop theori deriv fast algorithm problem optic ow estim surfac reconstruct textur segment 2 26 11 25 see also 17 also crous et al 7 use multiscal tsbn model wavelet coecient debonet viola 9 use interest treestructur network imag synthesi use nongaussian densiti howev requir prior classlabel imag work tsbn discretevalu node german purpos mention exact infer procedur noncaus mrf gener nphard howev note import recent work approxim infer procedur graph use local probabl propag scheme 46 local scheme guarante give correct answer graph without loop see 35 give approxim answer gridstructur graph typic use imag analysi work messagepass scheme loopi graph includ decod errorcorrect code 12 work 46 criticis basi ie nonhierarch noncaus mrf model use although possibl appli similar messag pass scheme loopi hierarch graph see section 7 discuss work carri databas imag outdoor scene see section 4 detail colour imag correspond label imag avail paper make number contribut investig eect adapt train paramet tree respons data two method consid rst tree train maximis probabl label imag call maximum likelihood ml train similar work lafert et al 20 allow nonstationari parameteris tree ect regular imag databas second method tree train maximis probabl correct label imag given raw input imag call condit maximum likelihood cml train qualiti mltrain tsbn model evalu compar well code test set label imag perform compar number code scheme includ jpegl lossless codec also provid analysi tsbn code allow us quantifi benet use higher level tree correspond longerrang correl tsbn compris prior aspect bayesian model also requir likelihood term wherebi imag data uenc segment direct approach produc gener model probabl densiti pixel featur given imag class exampl 5 class condit densiti model use gaussian mixtur model compar approach altern one neural network use make local predict given pixel featur predict combin prior principl manner use scale likelihood method see section 22 detail eect combin method ml cml train tree also investig evalu perform segment algorithm use pixelwis classic rate also analysi posterior pixelwis entropi condit probabl label imag given colour imag remaind paper organis follow section 2 describ tsbn model scaledlikelihood method detail explain infer carri section 3 deriv equat train tsbn use maximum likelihood ml condit maximum likelihood cml method imag code use tsbn section 4 give detail data train variou model section 5 result present concern imag code estim cpt section 6 analys classic result network neural network model imag segmenta tion 21 gener model model data illustr figur 1 observ data assum gener underli process x x tsbn network arrang layer highest level level one node x 0 children level 1 lower level denot x l level l fundament properti belief network encod condit independ 35 15 layer structur mean distribut x n 1 n l given coarser scale node depend x n 1 inde treestructur network mean node x n depend singl node x n 1 typic experi parent node four children give rise quadtreetyp architectur node multinomi variabl take one c class label label use segment eg road sky vehicl etc 2 link node dene condit probabl tabl cpt parent root node uncondit prior distribut instead cpt node x l onetoon correspond observ data observ data case featur deriv block pixel rather individu pixel raw imag model observ illustr figur 1 observ depend correspond variabl x l 2 note necessari hidden node cclass multinomi variabl use conveni give rise simpl initialis tsbntrain describ section 45 figur 1 1d graphic model illustr small treestructur belief network layer x denot x l case denot raw imag inform 22 likelihood model describ fulli gener model dene cpt root downward sinc pixel compos number compon featur space p densiti function one method use gaussian mixtur densiti use 5 describ section 44 howev databas use provid raw data label segment x l given inform natur train classier eg neural network predict x l well known neural network train variou error function includ crossentropi meansquar error approxim posterior probabl p x l fusion predict belief network x achiev immedi requir p jx l term howev use bay theorem obtain infer x data xed factor p need consid dene scale likelihood lx l locat obtain replac lx l principl method fusion local predict global prior model p x notat p denot estim desir probabl method combin neural network belief network suggest hmm smyth42 morgan bourlard31 interest connect scale likelihood mutual inform ix random variabl x ix mutual inform expect valu log scale likelihood describ would need train separ neural network predict p x pixel clearli undesir term comput eort amount data requir solut adopt train one neural network make posit coecient pixel part input neural network use scale likelihood requir imag turn p x depend posit pixel know ensembl imag regular sky appear top number way approach estim p x one train network predict class label given posit pixel altern would use relationship p x approxim integr averag appropri featur vector experi see section 6 compar spatial one deriv pixelwis margin mltrain tsbn result obtain similar potenti advantag scaledlikelihood method gener model p jx may quit complex although predict distribut p x jy actual quit simpl mean gener approach may spend lot resourc model detail p jx particularli relev task infer x 23 infer given new imag wish carri infer x l given probabilist model comput posterior p x would highli expens would requir enumer possibl c k state x l two altern comput feasibl comput posterior margin p x l give rise segment base maximum posterior margin mpm ii map interpret data x achiev pearl messag pass scheme describ 35 scheme nonit involv one upward one downward pass tree detail given mpm comput appendix along method scale calcul avoid ow comput margin likelihood p x l 3 train tsbn assum paramet use dene p x known fact estim train data let denot paramet prior probabl root node cpt tree let x il denot possibl valu x let pa ik set possibl valu taken pa parent x paramet ikl denot cpt entri l 1 simplic symbol x pa drop probabl written p x il jpa ik train prior model assum number observ imag associ label imag x lm avail index imag train set let denot paramet likelihood model p yjx discuss turn maximum likelihood train x31 condit maximum likelihood train x32 3 note nding congur x like equival nding congur maximis p x x 31 maximum likelihood maximum likelihood train paramet vector estim ml see likelihood model paramet tsbn model paramet estim separ choos likelihood model paramet maximis prior model paramet maximis assum likelihood model xed obtain ml j optimis carri use em algorithm use bottomup topdown messag pass infer posterior probabl hidden node estep use expect count transit reestim cpt 40 24 21 reestim formula deriv directli maximis baum auxiliari function q new estim paramet vector x denot hidden variabl x nx lm pattern updat entri cpt given joint probabl obtain local use messag pass scheme see appendix detail updat give separ updat link tree given limit train data un desir set variabl share cpt denot x em paramet updat given inform avail one still carri maximum likelihood train model paramet set would adapt case known unsupervis learn describ tsbn 20 disadvantag scaledlikelihood method use unsupervis learn p avail 5 section iii c appear paramet reestim test imag unusu standard pattern recognit methodolog model paramet estim train data xed appli test imag follow standard methodolog 32 condit maximum likelihood cml procedur object predict correctli label x l associ evid paramet estim maximis probabl correct label given evid cml analog boltzmann machin observ comput condit probabl requir comput 1 probabl p clamp phase ie x lm xed 2 probabl py j freerun phase xed 4 assum likelihood model p yjx object function view function carri optimis equat 8 take logarithm dene log log p use subscript c f mean clamp free use decomposit simpli log log log nd cml equat 8 need maximis log p 4 use terminolog clamp freerun follow 18 unfortun em algorithm applic cml estim cml criterion express ration function14 howev maximis equat 11 carri variou way base gradient l speech analysi 18 39 method base gradient ascent use scale conjug gradient optimis algorithm 30 4 use work use search method need calcul gradient l wrt let ik jx lm shown see appendix b detail ikl ikl ikl n ikl obtain propag x lm respect see equat 23 maximis l must ensur probabl paramet remain posit properli normalis softmax function use meet constraint dene l 0 e z ikl 0 z ikl new unconstrain auxiliari variabl ikl alway sum one l index construct gradient wrt z ikl express entir term ikl n ikl n n ikl z ikl ikl ikl l 0 33 imag code tsbn provid gener probabilist model label imag evalu qualiti model label process evalu likelihood test set label imag model calcul log 2 p x l label pixel imag obtain code cost bitspixel minimum attain code cost entropi bitspixel gener process comput p intract mrf model compar tsbn result lossless jpegl codec 44 45 avail httpwwwhplhpcomloco 331 code cost tsbn model use tsbn model distribut imag margin likelihood label imag x l calcul ecient root node x 0 tree see appendix a2 also consid eect truncat tree level root tree case instead one larg tree imag model consist number smaller tree correl dierent tree ignor allow us quantifi benet use higher level tree correspond longerrang correl prior smaller tree calcul propag prior downward cpt obtain prior root likelihood imag truncat model simpli product likelihood subimag comput smaller tree 4 experiment detail 41 data colour imag outdoor scene sowerbi imag databas 5 british aerospac use experi databas contain urban rural scene featur varieti everyday object road car hous lane eld variou place near bristol uk scene photograph use smallgrain 35mm transpar lm care control condit imag databas digitis calibr scanner gener high qualiti 24bit colour represent colour imag correspond label imag provid databas label imag creat overseg imag hand label region produc 92 possibl label organis hierarch system combin label produc seven class name sky veget road mark road surfac build street furnitur mobil object instanc class street furnitur combin mani type road sign telegraph pole 5 databas made avail research pleas contact dr andi wright dr gareth ree advanc inform process depart advanc technolog centr sowerbi bae system ltd po box 5 filton bristol bs34 7qw uk email garethsreesbaesystemscom detail undefin veget road mark road surfac build furnitur mobil object figur 2 rural urban scene handlabel classic origin imag b handlabel classic right key describ label use bound object figur 2a show two scene test imag set databas one rural one urban figur 2b show handlabel classic dierent greylevel label imag correspond seven dierent possibl class origin 104 imag divid randomli independ train test set size 61 43 respect fullresolut colour imag size 512 768 pixel downsampl 128 192 region size 4 4 pixel label reduc region chosen major vote within region tie resolv order label categori refer reduc label imag label imag origin label imag longer use 42 featur extract import step classic featur select initi forti featur extract region among six featur base r g b colour compon ie mean varianc overal intens region colour hue angl sine cosin 1 rb 2grb2 use 34 r g b indic mean red green blue compon respect textur featur greylevel dierenc vector gldv textur featur 48 47 contrast entropi local homogen angular second moment mean standard deviat cluster shade cluster promin gldv featur extract base absolut dierenc pair gray level distanc apart four angl x locat region also includ featur space describ section 22 featur normalis use linear transform zero mean unit varianc train set use limit number featur use increas number featur increas free paramet need optimis neural network train phase generalis linear model glm use normalis featur input softmax output 4 use featur select input sum absolut valu weight come input train glm calcul twentyon featur sum larger uniti retain select procedur base idea import featur tend give rise larger weight cf automat relev determin idea mackay neal 32 43 mlp train multilay perceptron mlp use task predict p x l explain section 22 probabl estim mlp take input nonposit featur vector posit pixel retain featur produc featur vector region fed mlp 21 input node 7 output node one hidden layer train classifi region one seven class activ function output node hidden node softmax function tanh sigmoid function respect error function use train process crossentropi multipl class see 4 scale conjug gradient algorithm use minimis error function train perform use 51000 region extract train imag dataset valid independ valid dataset 15000 region valid dataset use order choos optim number hidden node mlp eventu best perform valid set obtain mlp node train dataset mlp train form choos randomli 150 region class singl imag tri use equal number region class train set mlp aim rebalanc train set give net better chanc learn infrequ class see 4 p 224 probabl class train set mlp denot estim simpli evalu fraction train set data point class correspond probabl pixel whole train set imag denot turn 00070 order class sky veget road mark road surfac build street furnitur mobil object two set prior probabl dierent almost uniformli distribut class bias toward class two four correspond veget road surfac respect sinc train set mlp reweight class accord necessari consid eect scale likelihood fact follow 4 p 223 nd z input network pixel network output class k p c k jy compens network output z normalis factor use make one henc see scale likelihood p equal unimport constant call predict p c k jy given equat 14 compens mlp predict segment obtain choos probabl class pixel independ call raw mlp compens mlp segment use uncompens compens predict respect 44 gaussian mixtur model train section 43 describ mlp train relat imag featur label altern approach build classcondit densiti estim class use along bay rule make predict follow 5 20 use gaussian mixtur model gmm task specic cluster program avail httpwwwecepurdueedubouman use train set use mlp consid three dierent featur set averag r g valu region ii 21 featur use train mlp iii 40 featur addit two dierent set cluster program use allow either diagon full covari matric gaussian program select number mixtur compon automat use mdl criterion recommend initialis start three time mani compon featur use gmm class combin prior probabl class p c k given section 43 produc pixelwis classic overal classic accuraci 6872 4976 7595 7138 7745 7192 3full 3diag 21full 21diag 40full 40diag model respect test set gmm model highest pixelwis perform name 40full use experi see section 6 detail number mixtur compon 40full model seven class 9 9 4 9 8 7 6 respect found train gmm sometim make condent misclass caus ow problem evalu condit probabl p tsbn x l jy condit probabl ground truth label x l given imag see section 64 reason replac likelihood term p jx l minimum valu need avoid ow mltsbn 45 tsbn train tsbn use basic quadtre except six children root node take account 23 aspect ratio imag downsampl imag total 128 192 pixel took pixel downsampl imag leaf node belief network built eightlevel tsbn total 32756 link node adjac level link separ cpt larg train set would need ensur cpt well determin turn impli huge comput resourc could need order nd suitabl minimum cml object function practic approach clearli impract one techniqu dimension reduct case tie cpt experi cpt level constrain equal except transit level 0 level 1 tabl separ exibl allow knowledg broad natur scene eg sky occur near top imag learn network inde ect learn cpt see section 5 train mltsbn network paramet initialis number dierent way found highest margin likelihood train data obtain initi valu comput use probabl deriv downsampl version imag sparsedata problem appear initi valu cpt pair occur train data 6 dealt problem ad small quantiti condit probabl pc k jc normalis modi probabl use case least one 1c plot likelihood iter number level iter databas pixel unlabel assum valu miss random treat uninstanti node easili handl belief network framework cml train initialis mltsbn solut plot condit likelihood iter number level 44 iter cml train scale conjug gradient optimis gmm mlp predictor upward propag tree take around 10 downward propag around 40 sgi r10000 processor tree 30000 node made avail c code tsbn train infer along matlab demonstr call function httpwwwdaiedacukdaidbpeoplehomesckiwcodecbnhtml 46 combin pixelwis predict tree gmm mlp local predictor ml cml train tsbn give rise larg number possibl combin pixelwis predictor tree one investig 6 reason import consid cpt entri set zero em algorithm move away zero train 1 raw gmm pixelwis predict 2 compens gmm pixelwis predict spatiallyuniform compens 3 compens gmm pixelwis predict use margin mltsbn 4 gmm likelihood 5 gmm likelihood 6 raw mlp pixelwis predict 7 compens mlp pixelwis predict spatiallyuniform compens 8 compens mlp pixelwis predict use margin mltsbn 9 tsbn method calcul scale likelihood describ section 43 map infer use pixelwis predict entri 3 8 compens use margin mltsbn note dierent compens probabl use six region imag dene six cpt root level 1 perform method investig section 5 6 5 result tsbn train section describ result train tsbn use ml cml train rst discuss labelimag code result use mltrain tree inspect learn cpt mltrain tsbn cmltrain tsbn 51 imag code result section present result compar mltrain tsbn lossless jpeg code relev theori describ section 33 detail tsbn train given section 45 06114truncat level bitspixel figur 3 bit rate bitspixel function truncat level tsbn averag bit rate tsbn model 02307 bitspixel bpp comparison purpos jpegl codec gave averag bit rate 02420 bpp also tri compress label imag use code use unix util gzip gave 03779 bpp fact similar level compress perform obtain jpegl tsbn suggest tsbn reason good model label imag use truncat tree scheme discuss section 33 analys tsbn result figur 3 show bit rate bitspixel evalu function truncat tree level 0 7 time level 4 reach correspond 8 8 block size almost benet attain 52 learn cpt cpt deriv use ml train shown figur 4 note six separ cpt use transit root node level 1 explain section 45 also calcul prior margin node tree simpli take prior root node pass relev cpt path root node consider 7 fact six cpt root level 1 transit mean eect six dierent prior margin level 1 7 dene 23 aspect ratio imag prior margin shown figur 5 may easi interpret cptsmargin permut state label 7 also achiev use pearl propag scheme outlin appendix everi leaf node uninstanti node correspond permut incom outgo cpt would leav overal model unchang howev appear downsampl initialis mean larg problem analys figur 4 5 see 1 prior margin level 7 ect overal statist imag sky veget road surfac class frequent occur sky class like found top half imag road surfac bottom half similar pattern detect level 1 figur 5 although veget label less preval upper half level 2 train cpt level 1 7 exhibit strong diagon structur impli children like inherit parent class 3 level 0 level 1 cpt need read conjunct root prior distribut provid good explan level 1 prior margin although lafert et al 20 carri em train tsbn note estim cpt tie layerbylay basi data figur 4 5 show relax constraint use cpt prior margin obtain cml train similar shown figur 4 5 respect probabl due fact cml train initialis mltsbn solut gmm mlp predictor 6 segment result perform evalu turn classic test imag often classic perform evalu pixelwis accuraci howev complex realworld classic task tell whole stori number factor concern us notabl fact predict label pixel imag spatial coher import also note fraction pixel dierent class tremend dierent groundtruth label use assess perform 100 percent correct downsampl process also inaccuraci handlabel process therefor dicult task assess qualiti classic deriv variou method may also depend use classic put earli refer assess qualiti segment 22 recent prior root node b root node level 1 c level 1 level 2 level 2 level 3 level 3 level 4 f level 4 level 5 g level 5 level level 6 level 7 figur 4 estim prior root cpt ml train eightlevel belief network train train imag area black squar proport valu relev probabl prior probabl root node b six independ cpt link root node six children rst level ch cpt link adjac level level 1 level 7 respect seven label 1ski 2veget 3road mark 4road surfac 5build 6street furnitur 7mobil object cpt entri 11 top lefthand corner read level l index row level l index column level 0 level 1 level 2 level 3 level 4 level 5 level level 7 key veget road mark road surfac build street furnitur mobil object veget road mark road surfac build street furnitur mobil object veget road mark road surfac build street furnitur mobil object veget road mark road surfac build street furnitur mobil object figur 5 prior margin train ml algorithm area black squar proport valu relev probabl see text detail realis aim segment may return singl segment multipl solut 33 probabl distribut segment p x l jy posterior distribut explor mani way describ two name posterior margin entropi ii evalu condit probabl p jy x l ground truth imag given input data section compar perform classic base smooth segment imag section 61 pixelwis predict accuraci section 62 margin entropi section 63 condit probabl section 64 61 smooth rural scene figur 2 figur 6 show classic use combin outlin section 46 classic obtain singlepixel method typic lot highfrequ nois due local ambigu region ml cmltrain tree tend smooth nois similar smooth obtain use major lter 23 one simpli choos common class within window center pixel interest howev one drawback majoritylt smooth reasonablys window tend remov ne detail road mark contrast seem tsbn method yield someth like adapt smooth depend strength local evid also note majoritylt return probabl distribut segment 62 pixelwis classic accuraci tabl 1 show pixelwis classic accuraci class overal accuraci ten method list section 46 tsbn method map segment result report mpm result similar although gener wors tenth one percent notic featur perform obtain mlp method superior gmm method look result detail notic raw result gmm mlp column 1 improv compens column 2 7 resp compens method simpli give figur classic rural scene raw gmm pixelwis predict ii raw mlp pixelwis predict iii compens gmm pixelwis predict iv compens mlp pixelwis predict v map segment segment mlp segment gmm tsbn viii map segment mlp weight frequent occur class seen compar column 1 2 6 7 small dierenc spatial uniform compens column 2 7 mltsbn margin compens scheme column 3 8 column 4 8 combin pixelwis evid mltsbn gmm mlp local model perhap surpris perform decreas compar column 3 7 respect fair comparison method column 3 7 use margin mltsbn correl structur column show perform gmm mlp local model combin tree train use cml method relev data case perform better fusion mltsbn mlp method obtain best overal perform comparison note mccauley engel 28 compar perform bouman shapiro smap algorithm pixelwis gaussian classier remot sens task found overal classic accuraci smap 36 higher 934 vs 898 reason superior perform mlp experi entir clear howev note test imag rel divers set imag although drawn distribut train imag may featur import mlp classier similar train test imag featur whose distribut model gmm vari train test set contrast evalu literatur eg 28 use singl test imag train data drawn subset pixel case issu interimag variabl aris also note comparison gmm mlp classier carri use train set particular size composit dierent result might obtain factor vari 63 pixelwis entropi interest understand uncertainti describ p x l jy appear comput joint entropi condit distribut intract howev posterior margin entropi readili comput posterior margin p x l tabl 1 perform 10 method show percentag correct class overal second column tabl give overal percentag class test imag class percentag veget 4012 6104 7892 7746 6792 7572 7932 9241 9040 8167 9045 road mark 017 5514 4226 4433 4309 2736 7861 6897 6791 7004 6791 road surfac 395 6214 7818 8045 7010 7345 9452 9716 9626 9499 9685 build 611 4419 4698 4967 6370 7492 6769 4443 5273 7940 6460 street furnitur 135 2858 1405 1377 2097 858 2489 396 462 1007 663 mobil object 057 5885 4305 4310 7276 7623 4913 2883 3215 7889 4474 overal 6371 7745 7794 7100 7585 8572 9016 8938 8738 9068 kji 8 imag display posterior margin entropi shown figur 7 pertain origin imag shown right figur 2 expect pixelwis entropi reduc use tsbn particularli eectiv cml tree notic pixel signic posterior margin entropi good indic pixel misclassi especi true cml combin figur 7 properti could well use inform later stage process 64 condit probabl model develop good one p x l jy ascrib high probabl ground truth label x l dierent imag model compar term rel valu p jy particular compar tsbn imag model independ pixel model ignor spatial correl obtain pmlp mlp local predict similarli gmm local predict tsbn p x l jy calcul follow 8 revis paper becam awar calcul posterior margin entropi propos independ perez et al 36 determin condenc map c 00487 figur 7 posterior margin entropi mlp predictor compens pixelwis predict b mltsbn c cmltsbn greyscal black denot zero entropi white denot 245 bit number underneath plot averag pixelwis posterior entropi binari imag show misclassi label bright correctlyclassi label dark equat 16 follow equat 15 p jx l denomin evalu method outlin appendix a2 complex aris calcul pixel label pmlp x jy pixel simpli ignor p tsbn x l jy unlabel pixel ignor numer denomin equat 17 achiev set vector appropri node vector one see appendix detail figur 8 plot 1 log p x l jy variou model panel b show 43 test imag posterior probabl mlpcmltsbn method larger compens mlp use independentpixel model panel show similar comparison use gmm predictor cmltsbn method better 41 43 case notic also rel scale plot especi gmm model make condent mistak pixel therebi drag averag posterior probabl logp gmm logp gmm cmltsbn 05logp mlp logp mlp cmltsbn b figur 8 comparison log p x l jyn compens gmm vs gmm compens mlp larg number similar plot made comparison posterior probabl mltrain tsbn independ model come roughli equal number better code two model gmm mlp predictor cmltrain tsbn mlp predict better method 39 43 test imag remain four mltsbn mlp win paper made number contribut use em algorithm train mltsbn observ learn paramet ect underli statist train imag qualiti probabilist model evalu code term found compar stateoftheart method truncat tree analysi show scale correl import compar perform gmm mlp pixelwis classier sizabl realworld imag segment task perform discriminativelytrain mlp found superior classcondit gmm model also shown scaledlikelihood method use fuse pixelwis mlp predict tsbn prior compar condit maximum likelihood cml train tree maximum likelihood ml train number dimens includ classic accuraci pixelwis entropi condit probabl measur p x l jy problem evalu segment old one full answer may well depend decisiontheoret analysi take account endus segment eg autom drive system howev one attract featur tsbn framework aspect posterior uncertainti comput ecient eg posterior margin entropi discuss section 63 architectur ultim imag model know run gener give rise blocki label imag number interest research direct tri overcom problem bouman shapiro 5 suggest make complex crosslink model problem infer becom much complex one need use junction tree algorithm see eg 21 one interest idea suggest 5 retain pearlstyl messag pass even though exact idea analys 12 46 anoth approach infer use altern approxim scheme recognit network use helmholtz machin 8 meaneld theori 41 altern creat crosslink architectur retain tsbn move away rigid quadtre architectur allow treestructur adapt present imag formul bayesian fashion set prior probabl distribut treestructur initi result approach report 49 43 believ gener area creat gener model imag data nding eectiv infer scheme fruit area research appendix pearl probabl propag procedur describ pearl scheme probabl propag tree comput margin likelihood p x l j scale procedur algorithm avoid ow a1 pearl scheme rst consid calcul probabl distribut p xje node x tsbn given instanti node evid e consid tree fragment depict figur 9 base figur 414 35 p xje depend two distinct set evid evid subtre root x denot e x evid rest tree denot e x shall assum node nite number state c node dierent number state add extra notat necessari applic bay rule togeth independ properti tsbn yield product rule x partit e x e dene recurs assum node x n children ik kth valu node x known messag sent node x child node x given recurs z z 0 2sx z 0 2sx z k kth state node z sx denot sibl x ie children z exclud x normalis factor valu x z sum 1 fact z e sx denot evid sibl x x z known messag sent node x e e x x z figur 9 fragment causal network show incom messag name messag shown solid arrow outgo messag messag broken arrow node x parent z propag procedur complet dene boundari condit root leav tree vector root tree equal prior probabl class leav tree vector vector one node uninstanti equal vector singl entri 1 entri 0 correspond instanti state comput p xje node tree perform use upward phase messag pass downward phase messag pass nd maximum posteriori congur hidden variabl x given evid e use similar messag pass scheme describ section 53 35 posterior margin requir em updat cml deriv given set node sibl node x denot messag sent node pa node show partit e pa e sx rst calcul p use condit independ describ tree obtain pa ik comput divid side equat p e calcul a2 margin likelihood consid procedur comput p ej assum x 0 root node use root node e x0 empti a3 scale pearl probabl propag order understand scale requir implement messag propag consid two distinct messag pass scheme separ firstli consid denit x equat 21 x probabl given evid x give long normalis factor appli time calcul messag case scale need x consid denit x equat 19 x equat 20 valu node x product messag sent children child node form weight sum valu form messag sent parent elementwis multipl messag equat 19 weight sum calcul equat 20 caus numer valu vector decreas exponenti distanc leav tree scale x three goal 1 keep scale x within dynam rang comput node tree 2 maintain local propag mechan pearl probabl propag 3 recov true valu end comput achiev recurs formula children x equat initialis leav x valu give reason scale x use work unscal valu x comput use x x x product scale coecient subtre root x includ x fact interest calcul p xje necessari worri unduli scale factor vector simpli rescal node requir p xje calcul scale vector vector requir p xje sum 1 howev scale import wish calcul margin likelihood p ej 9 refer back equat 26 nd dx0 product scale factor use propag procedur sinc dx0 could machin dynam rang comput log p log dx0 appendix b calcul deriv cml optimis appendix calcul gradient wrt section 32 suppress depend p yjx notat conveni first note p j written sum possibl valu x tsbn use condit independ relat p xj easili decompos product transit probabl link follow idea krogh18 hmm deriv l f wrt ikl ikl ikl ikl 9 scale issu discuss perez et al 36 appear address issu scale comput posterior margin paper explicitli scale comput p ej ikl ikl ikl ikl ikl step equat 30 equat 31 deriv fact ikl appear product state l pa state k deriv term l c calcul similar manner except summat variabl tree taken hidden variabl x acknowledg work fund epsrc grant grl03088 combin spatial distribut predict neural network epsrc grant grl78181 probabilist model sequenc author grate acknowledg assist british aerospac project make sowerbi imag databas avail us also thank dr andi wright bae help discuss dr ian nabney help netlab routin neural network dr gareth ree bae discuss segment metric dr john elgi introduc us work 5 prof kevin bowyer point work 33 also thank three anonym refere associ editor prof charl bouman help comment advic consider improv manuscript r comput vision model estim multiresolut stochast process statist analysi dirti pirtur neural network pattern recognit multiscal random field model bayesian imag segment trainabl context model multiscal segment helmholtz machin decis theori arti revolut belief propag graph cycl stochast relax inequ ration function applic statist estim problem introduct bayesian network statist pattern recognit imag analysi multiresolut gaussmarkov random eld model textur segment hidden markov model label sequenc graphic model dynam measur comput gener imag segment remot sens imag interpret bayesian belief network tool stochast pars likelihood calcul class multiscal stochast model statist method automat interpret digit scan comparison scene segment smap neural network statist recognit continu speech bayesian learn neural network textur imag segment return multipl solut probabilist reason intellig system network plausibl infer tutori hidden markov model select applic speech recognit neural network classi hidden neural network framework hmmnn hybrid paramet estim depend tree model use em algorithm hidden markov model fault detect dynam system dynam posit tree structur imag analysi locoi lossless imag compress algorithm principl standard jpegl correct belief propag gaussian graphic model arbitrari topolog compar studi textur measur terrain classi dynam tree imag label neural network use neural network region label scene un derstand tr ctr neil lawrenc andrew j moor hierarch gaussian process latent variabl model proceed 24th intern confer machin learn p481488 june 2024 2007 corvali oregon todorov michael c nechyba dynam tree unsupervis segment match imag region ieee transact pattern analysi machin intellig v27 n11 p17621777 novemb 2005 amo j storkey christoph k william imag model positionencod dynam tree ieee transact pattern analysi machin intellig v25 n7 p859871 juli sanjiv kumar martial hebert discrimin random field intern journal comput vision v68 n2 p179201 june 2006 todorov michael c nechyba interpret complex scene use dynam treestructur bayesian network comput vision imag understand v106 n1 p7184 april 2007 richard j howarth spatial model widearea visual surveil comput approach spatial buildingblock artifici intellig review v23 n2 p97155 april 2005 simon marinai marco gori giovanni soda artifici neural network document analysi recognit ieee transact pattern analysi machin intellig v27 n1 p2335 januari 2005