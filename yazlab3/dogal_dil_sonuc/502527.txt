proxim support vector machin classifi instead standard support vector machin svm classifi point assign one two disjoint halfspac point classifi assign closest two parallel plane input featur space push apart far possibl formul also interpret regular least squar consid much gener context regular network 8 9 lead extrem fast simpl algorithm gener linear nonlinear classifi mere requir solut singl system linear equat contrast standard svm solv quadrat linear program requir consider longer comput time comput result publicli avail dataset indic propos proxim svm classifi compar test set correct standard svm classifi consider faster comput time order magnitud faster linear proxim svm easili handl larg dataset indic classif 2 million point 10attribut set 208 second comput result base 6 line matlab code b introduct standard support vector machin svm 36 6 3 5 20 power tool data classif classifi point assign one two disjoint halfspac halfspac either origin input space problem linear classifi higher dimension featur space nonlinear classifi 36 6 20 standard svm requir solut either quadrat linear program requir special code 7 contrast propos proxim svm psvm permiss make digit hard copi part work person classroom use grant without fee provid copi made distribut profit commerci advantag copi bear notic full citat first page copi otherwis republish post server redistribut list requir prior specif permiss andor fee kdd 2001 san francisco ca usa classifi point depend proxim one two parallel plane push far apart possibl fact geometr motiv proxim formul consid much gener context regular network 8 9 result give extens theoret statist justif proxim approach contain extens comput implement result given furthermor specif formul lead strongli convex object function alway case 8 9 strong convex play key role simpl proxim code provid well fast comput time obtain obtain linear nonlinear psvm classifi requir noth sophist solv singl system linear equat effici fast linear equat solver freeli avail 1 part standard commerci packag matlab 26 solv larg system fast briefli summar content paper section 2 introduc proxim linear support vector machin give linear proxim algorithm 21 explicit express leaveoneoutcorrect term problem data 16 section 3 introduc proxim kernelbas nonlinear support vector machin correspond nonlinear classifi 28 nonlinear proxim algorithm 31 section 3 contain mani numer test result linear nonlinear classifi base extrem simpl matlab 26 code 6 line linear nonlinear psvm result surpass algorithm compar speed give compar test set correct word notat background materi vector column vector unless transpos row vector prime superscript vector x ndimension real space r n step function stepx defin n scalar inner product two vector x ndimension real space r n denot x 2norm x denot x matrix r mn ith row row vector r n j jth column column vector one arbitrari dimens denot e r mn b r nk kernel kab map r mn r nk r mk particular x column vector r n kx real number kx row vector r kaa mm matrix base natur logarithm denot make use follow gaussian kernel 36 6 20 frequent use svm literatur 1 r mn b r nk posit constant ident matrix arbitrari dimens denot 2 linear proxim support vector consid problem depict figur 1 classifi point ndimension real space r n repres n matrix accord membership point class specifi given mm diagon matrix plu one minu one along diagon problem standard support vector machin linear kernel 35 6 given follow quadrat program paramet 0 min wyr n1m 2 depict figur 1 w normal bound plane bound set respect constant determin locat rel origin two class strictli linearli separ error variabl 2 case shown figur 1 plane x class point plane x class point follow consequ plane midway bound plane 3 separ plane separ complet approxim depict figur 1 quadrat term 2 twice reciproc squar 2norm distanc 2 w two bound plane 3 see figur 1 maxim distanc often call margin maxim margin enhanc gener capabl support vector machin 35 6 class linearli insepar case shown figur 1 two plane bound two class soft margin ie bound approxim error determin nonneg error variabl 1norm error variabl minim parametr weight 2 result approxim separ plane 5 depict figur 1 plane act linear classifi follow 0 x point departur similar 23 24 optim problem 2 replac follow problem min wyr n1m note explicit nonneg constraint need compon neg object function decreas set still satisfi correspond inequ constraint note 2norm error vector minim instead 1norm margin bound plane maxim respect orient w rel locat origin extens comput experi 22 23 24 18 17 indic formul good classic formul 2 ad advantag strong convex object function key idea present paper make simpl fundament chang formul 8 name replac inequ constraint equal follow min wyr n1m modif even though simpl chang natur optim problem significantli fact turn write explicit exact solut problem term problem data show wherea imposs previou formul combinatori natur geometr formul depict figur 2 interpret follow plane x w 1 bound plane anymor thought proxim plane around point class cluster push far apart possibl term w object function noth reciproc 2norm distanc squar two plane w space r n1 x x x x x x x x psfrag replac w separ plane x figur 1 standard support vector machin classifi wspace r n approxim bound plane equat 3 soft ie error margin 2 w plane equat approxim separ x x x x x x x x x x x x psfrag replac separ plane x w figur 2 proxim support vector machin classifi w space r n1 plane point set cluster push apart optim problem 9 note formul 9 also interpret regular least squar solut 34 system linear equat daw e find approxim solut w least 2norm similarli standard svm formul 2 interpret use linear program perturb theori 21 least 2 norm approxim solut system linear inequ e neither interpret howev base idea maxim margin distanc parallel plane 3 key featur support vector machin 36 6 20 karushkuhntuck kkt necessari sucient optim condit 19 p 112 equal constrain problem obtain set equal zero gradient respect w u lagrangian lw u lagrang multipli associ equal constraint 9 set gradient l equal zero give follow kkt optim condit first three equat 11 give follow express origin problem variabl w term lagrang multipli u 12 substitut express last equal 11 allow us obtain explicit express u term problem data follow h defin u 13 explicit solut w problem 9 given 12 solut 13 u entail invers possibl massiv mm matrix make immedi use shermanmorrisonwoodburi formula 14 p 51 matrix invers done 23 10 24 result express well anoth simpl express 29 involv invers much smaller dimension matrix order n complet solv classif problem concret explicitli state simpl algorithm algorithm 21 linear proxim svm given data point r n repres n matrix diagon matrix 1 label denot class row gener linear classifi 7 follow defin h 14 e 1 vector one comput u 15 posit typic chosen mean tune valid set ii determin w 12 iii classifi new x use 7 standard svm support vector consist data point complement data point drop problem without chang separ plane 5 36 20 thu standard svm formul 2 support vector correspond data point lagrang multipli nonzero solv 2 data point give answer solv entir dataset proxim formul howev lagrang multipli u mere multipl error vector given 12 con sequent compon typic nonzero sinc none data point usual lie proxim plane x concept support vector need modifi follow w r n1 given linear function 11 follow basi theorem linear equat 13 theorem 21125 lemma 21 appli last equal 11 fix valu error vector n 1 linearli independ data point need determin basic nonzero compon w r n1 guid fact small number data point character specif w defin concept support vector data point error vector less absolut valu typic pick small enough 1 data support vector resolv proxim svm problem 9 data point adjust typic upward tune set give test set correct essenti ident obtain use entir dataset note explicit express w u term problem data given 12 15 abl get also explicit express leaveoneoutcorrect looc 32 fraction correctli classifi data point point turn left psvm formul classifi classifi 7 omit algebra follow leaveoneoutcorrect step function defin introduct h defin 14 h denot row h h denot h row h remov h u defin 15 h replac h similarli denot row extend result nonlinear proxim support vector machin 3 nonlinear proxim support vector machin obtain nonlinear proxim classifi modifi equal constrain optim problem 9 20 18 replac primal variabl w dual equival du 12 obtain min e object function also modifi minim weight 2norm sum problem variabl u replac linear kernel aa nonlinear kernel defin introduct obtain min use shorthand notat lagrangian 19 written similarli 10 lu v r lagrang multipli associ equal constraint 19 set gradient lagrangian respect u v equal zero give follow kkt optim condit first three equat 22 give follow express u term lagrang multipli v 23 substitut express last equal 22 give explicit express v term problem data follow e 24 g defin note similar g h defin 14 similar allow us obtain g express replac k 14 taken advantag matlab code 41 algorithm 21 written linear classifi 7 thu gener nonlinear classifi algorithm 31 mere replac k algorithm solut v 24 solut u problem 19 given 23 unlik situat linear kernel shermanmorrisonwoodburi formula useless kernel matrix squar invers must take place potenti highdimension r howev reduc kernel techniqu 17 util reduc dimension kernel much smaller dimension rectangular kernel small 1 random submatrix reduc kernel make larg problem tractabl also often lead improv gener avoid data overfit eectiv reduc kernel demonstr mean numer test problem next section paper nonlinear separ surfac correspond kernel equat 81 deduc linear separ surfac 5 follow replac x correspond kernel express substitut 23 u obtain nonlinear separ surfac correspond nonlinear classifi nonlinear separ surfac 0 x give explicit statement nonlinear classifi algorithm algorithm 31 nonlinear proxim svm given data point r n repres n matrix diagon matrix 1 label denot class row gener nonlinear classifi 28 follow choos kernel function kaa typic gaussian kernel 1 ii defin g 25 vector one comput v 24 posit typic chosen mean tune set iii nonlinear surfac 27 comput v constitut nonlinear classifi 28 classifi new point x nonlinear classifi 28 direct gener linear classifi 7 work quit eectiv indic numer exampl present next section 4 numer implement comparison comput perform univers wisconsin data mine institut locop1 machin util 400 mhz pentium ii allow maximum 2 gigabyt memori process comput run window nt server 40 matlab 6 instal even though locop1 multiprocessor machin one processor use experi sinc matlab singl thread applic distribut load across processor 26 algorithm requir solut singl squar system linear equat size number input attribut n linear case size number data point nonlinear case use rectangular kernel 18 size problem reduc k k nonlinear case simplic algo rithm give actual matlab implement use experi consist 6 line nativ matlab code 226 figur 3 spiral dataset consist 97 black point 97 white point intertwin two spiral 2dimension space psvm gaussian kernel gener sharp nonlinear spiralshap separ code 41 psvm matlab code function psvmlinear nonlinear classif note command line matlab code comput directli factor 15 much econom stabl comput invers explicitli multipli h e calcul h e involv transpos typic larg matric time consum instead calcul rsumh wsa respect transpos vector note matlab code work linear classifi also nonlinear classifi well nonlinear case matrix kaa use input instead 20 equat 1 10 pair return instead w nonlinear separ surfac given 27 rectangular kernel 17 also handl code input rectangular matrix ka r mk k given output pair u u u associ reduc matrix final note regard simplif psvm substitut express 15 u 12 obtain algebra follow simpl express w term problem data e direct explicit solut psvm problem written follow singl line matlab code also perform explicit matrix invers e 1 slightli faster matlab code accord matlab command diagd m1 vector gener diagon matrix comput test result use onelin matlab code slightli better obtain code 41 one report tabl comment solut 29 also obtain directli 9 use equal constraint elimin problem solv result unconstrain minim problem variabl w set zero gradient respect w turn comput dataset use numer test follow seven publicli avail dataset uci machin learn repositori 28 wpbc ionospher cleveland heart pima indian bupa liver mush room tictacto censu dataset version us censu bureau adult dataset publicli avail silicon graphic websit 4 galaxi dim dataset use galaxi discrimin neural network 30 two larg dataset 2 million point 10 attribut creat use david music ndc data gener 29 spiral dataset propos alexi wieland mitr corpor avail cmu artifici intellig repositori 37 outlin comput result five group follow 1 tabl 1 comparison seven dierent method adult dataset experi compar perform seven dierent method linear classif dierent size version adult dataset report result sor 22 smo 31 svm light 16 22 result lsvm 24 result comput use locop1 wherea ssvm 18 rlp 2 18 smo experi run 266 mhz pentium ii processor window nt 4 use microsoft visual c 50 compil sor experi run 200 mhz pentium pro 64 megabyt ram also window nt 4 use visual c 50 svm light experi run hardwar sor solari 56 oper system bold type indic best result dash indic result avail 22 although time comparison approxim dierent machin use indic psvm distinct edg speed eg solv largest problem 74 second much faster method time tenfold test correct shown tabl 1 time tenfold 2 tabl 4 compar perform lsvm 24 psvm larg dataset two larg dataset consist 2 million point attribut creat use ndc data gener 29 one call ndceasi highli linearli separ around 90 one call ndchard sinc linear separ around 70 shown tabl 4 linear classifi obtain use method perform almost ident despit 2 million size dataset psvm solv problem 20 second compar lsvm time 650 second contrast svm light 16 fail problem 24 3 tabl 3 comparison psvm ssvm lsvm svm light use linear classifi experi compar four method psvm ssvm lsvm svm light seven publicli avail dataset uci machin learn repositori 28 30 shown tabl 3 correct four method similar execut time includ tenfold cross valid psvm smaller much one order magnitud three method test sinc lsvm ssvm psvm base similar formul classif problem valu use svm light tradeo trade error margin repres paramet c valu c chosen tune pair ttest 27 95 confid level perform compar perform psvm algorithm test pvalu obtain show signific dierenc psvm method test 4 figur 3 psvm spiral dataset use gaussian kernel order classifi spiral dataset dataset consist 194 black white point intertwin shape spiral synthet dataset 37 howev appar di cult test case data mine algorithm known give neural network sever problem 15 con trast sharp separ obtain use psvm seen figur 3 5 tabl 2 nonlinear classifi comparison use psvm ssvm lsvm experi chose four dataset uci machin learn repositori known nonlinear classifi perform significantli better linear classifi use psvm ssvm lsvm order find gaussiankernelbas nonlinear classifi classifi data dataset test three method perform similarli far tenfold cross valid concern howev execut time psvm much smaller two method note mushroom dataset consist point attribut squar 8124 8124 kernel matrix fit memori order address prob lem use rectangular kernel r 2158124 instead describ 17 gener algorithm perform particularli well rectangular kernel sinc system solv size k k k k much smaller number row contrast full squar kernel matrix system solv size pair ttest 27 95 confid level perform compar perform psvm algorithm test pvalu obtain show signific differ psvm method test far tenfold test correct concern 5 conclus futur work propos extrem simpl procedur gener linear nonlinear classifi base proxim one two parallel plane push far apart po sibl procedur proxim support vector machin psvm requir noth sophist solv simpl nonsingular system linear equat either linear nonlinear classifi contrast standard support vector machin classifi requir costli solut linear quadrat program linear classifi need psvm invers small matrix order input space dimens typic order 100 less even million data point cla sifi nonlinear classifi linear system equat order number data point need solv allow us easili classifi dataset mani thousand point larger dataset data select reduct method 11 17 12 util indic numer result subject futur work comput result demonstr psvm classifi obtain test set correct statist compar standard svm classifi fraction time sometim order magnitud less anoth avenu futur research increment classif larg dataset appear particularli promis view simpl explicit solut 24 linear nonlinear psvm classifi updat increment new data point come stream sum princip contribut work ecient classifi requir special softwar psvm easili incorpor sort data mine applic requir fast simpl eectiv classifi acknowledg research describ data mine institut report 0102 februari 2001 support nation scienc foundat grant ccr9729842 cda9623632 air forc oce scientif research grant f496200010085 microsoft corpor grate professor cj lin nation taiwan univers point refer 33 upon read origin version paper least squar also use 33 construct svm explicit requir mercer posit definit condit 35 need fur thermor object function quadrat program 33 strongli convex like import featur psvm influenc speed evidenc mani numer comparison given 33 6 r lapack user guid robust linear program discrimin two linearli insepar set massiv data discrimin via linear support vector machin us censu bureau tutori support vector machin pattern recognit learn data concept cplex optim inc regular network support vector machin regular network support vector machin interior point method massiv support vector machin data select support vector machin classif theori linear econom model matrix comput data mine spars grid make largescal support vector machin learn practic rsvm reduc support vector machin ssvm smooth support vector machin nonlinear program gener support vector machin nonlinear perturb linear program success overrelax support vector machin activ support vector machin classif lagrangian support vector machin lipschitz continu solut linear inequ mathwork machin learn uci repositori machin learn databas ndc normal distribut cluster dataset autom stargalaxi discrimin neural network sequenti minim optim fast algorithm train support vector machin advanc larg margin classifi least squar support vector machin classifi solut illpos problem natur statist learn theori natur statist learn theori twin spiral dataset tr lipschitz continu solut linear inequ program complementar problem natur statist learn theori matrix comput 3rd ed make largescal support vector machin learn practic fast train support vector machin use sequenti minim optim least squar support vector machin classifi data select support vector machin classifi machin learn learn data tutori support vector machin pattern recognit lagrangian support vector machin ctr weny li kinhong lee kwongsak leung largescal rlsc learn without agoni proceed 24th intern confer machin learn p529536 june 2024 2007 corvali oregon soumen chakrabarti shourya roy mahesh v soundalgekar fast accur text classif via multipl linear discrimin project proceed 28th intern confer larg data base p658669 august 2023 2002 hong kong china tsong song hwang tsungju lee yuhjy lee threetier id via data mine approach proceed 3rd annual acm workshop mine network data june 1212 2007 san diego california usa simon hill arnaud doucet adapt twoclass support vector classif method mani class problem proceed 22nd intern confer machin learn p313320 august 0711 2005 bonn germani thorsten joachim train linear svm linear time proceed 12th acm sigkdd intern confer knowledg discoveri data mine august 2023 2006 philadelphia pa usa glenn fung sathyakama sandilya r bharat rao rule extract linear support vector machin proceed eleventh acm sigkdd intern confer knowledg discoveri data mine august 2124 2005 chicago illinoi usa hwanjo yu jiong yang jiawei han xiaolei li make svm scalabl larg data set use hierarch cluster index data mine knowledg discoveri v11 n3 p295321 novemb 2005 kristin p bennett michinari momma mark j embrecht mark boost algorithm heterogen kernel model proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli 2326 2002 edmonton alberta canada hwanjo yu jiong yang jiawei han classifi larg data set use svm hierarch cluster proceed ninth acm sigkdd intern confer knowledg discoveri data mine august 2427 2003 washington dc tonatiuh pea centeno neil lawrenc optimis kernel paramet regularis coeffici nonlinear discrimin analysi journal machin learn research 7 p455491 1212006 yang ali r hurson contentawar search multimedia data ad hoc network proceed 8th acm intern symposium model analysi simul wireless mobil system octob 1013 2005 montral quebec canada bin li mingmin chi jianp fan xiangyang xue support cluster machin proceed 24th intern confer machin learn p505512 june 2024 2007 corvali oregon dacheng tao xuelong li xindong wu weim hu stephen j maybank supervis tensor learn knowledg inform system v13 n1 p142 septemb 2007 hwanjo yu xiaoqian jiang jaideep vaidya privacypreserv svm use nonlinear kernel horizont partit data proceed 2006 acm symposium appli comput april 2327 2006 dijon franc brian whitman deb roy barri verco learn word mean descript paramet space music proceed hltnaacl workshop learn word mean nonlinguist data p9299 may 31 soumen chakrabarti shourya roy mahesh v soundalgekar fast accur text classif via multipl linear discrimin project vldb journal intern journal larg data base v12 n2 p170185 august glenn fung murat dundar jinbo bi bharat rao fast iter algorithm fisher discrimin use heterogen kernel proceed twentyfirst intern confer machin learn p40 juli 0408 2004 banff alberta canada glenn fung l mangasarian multicategori proxim support vector machin classifi machin learn v59 n12 p7797 may 2005 deepak k agarw shrinkag estim gener proxim support vector machin proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli 2326 2002 edmonton alberta canada glenn fung olvi l mangasarian alexand j smola minim kernel classifi journal machin learn research 3 p303321 312003 w chaovalitwongs p pardalo time seri support vector machin use dynam time warp kernel brain activ classif cybernet system analysi v44 n1 p125138 januari 2008 yuhjy lee wenfeng hsieh chienm huang epsilonssvr smooth support vector machin epsiloninsensit regress ieee transact knowledg data engin v17 n5 p678685 may 2005 ryan rifkin aldebaro klautau defens onevsal classif journal machin learn research 5 p101141 1212004 rolando grave de peralta menendez quentin noirhomm febo cincotti donatella mattia fabio alois sara gonzlez andino modern electrophysiolog method braincomput interfac comput intellig neurosci v2007 n2 p111 april 2007 rolando grave de peralta menendez quentin noirhomm febo cincotti donatella mattia fabio alois sara gonzlez andino modern electrophysiolog method braincomput interfac comput intellig neurosci v7 n3 p18 august 2007