data squash empir likelihood data squash introduc w dumouchel c volinski johnson c cort pregibon proceed 5th intern confer kdd 1999 idea scale data set smaller repres sampl instead scale algorithm larg data set report success learn model coeffici squash data paper present form data squash base empir likelihood method reweight random sampl data match certain expect valu popul comput requir rel easi convex optim also theoret basi predict wont produc larg gain credit score exampl empir likelihood weight also acceler rate coeffici learn also investig extent benefit translat improv accuraci consid reweight conjunct boost decis tree b introduct stapl problem data mine construct classic rule data data warehous larg becom impract train classic rule use avail data instead sampl avail data may select train instanc enterpris miner sa institut featur semma process acronym lead stand sampl dumouchel et al 1999 introduc data squash improv upon sampl instead scale algorithm larg data set one scale data suit exist algorithm instead rel passiv sampl larg data set construct data set way make suitabl train algorithm suppos origin data consist n pair x x vector predictor variabl variabl predict x data squash one construct much smaller data set assign weight w necessarili connect point like x 1 x 1 index inde valu like x 1 might correspond x idea train algorithm n weight much faster train n origin data point larg speed gain may expect squash data main memori outlin paper section 2 describ data squash present version use empir likelihood weight point connect data squash numer integr varianc reduct techniqu use mont carlo simul survey sampl find empir likelihood weight reduc tractabl convex optim problem empir likelihood squash also theoret underpin predict wont work outlin section 2 section 3 describ credit score problem data valu simul distort obfusc transform variabl name data sourc hidden condenti assur remain good test case algorithm section 4 appli logist regress small data sampl without empir likelihood reweight reweight acceler rate coecient learn section 5 replac logist regress boost decis tree section 6 present conclus less pleas result squash dumouchel et al 1999 though describ sort problem expect squash add valu dierent conclus could due dierenc algorithm dierenc way result assess simpli data set dierent conclud section refer madigan raghavan dumouchel nason poss ridgeway 2000 oer likelihood base form squash gear exploit userspeci statist model bradley fayyad reina 1998 goal similar dumouchel et al 1999 madigan et al 2000 instead repres data weight set point employ mixtur model element mixtur includ gaussian distribut multinomi distribut product thereof row 1983 describ earlier work direct recent cite work much ambiti bet greater comput power avail today 2 data squash begin outlin data squash method dumouchel et al 1999 cast older method new light special case data squash notat dier somewhat origin dumouchel et al 1999 distinguish predictor respons squash defer distinct train stage allow squash data set use multipl predict problem also choos weight w averag weight 1 train algorithm aect scale case simpl altern convent dumouchel et al 1999 choos w outlin rst step group x vector region suggest sever way construct region simplest method point x region share valu everi discret variabl also share valu discret version everi continu variabl point region low order moment noncategor variabl comput region set point correspond weight w chosen weight moment squash data match nearli match unweight moment origin data function x pair moment within region correspond take g product power noncategor variabl multipli function one insid region zero outsid let z weight would provid perfect match withn given enough moment region ideal weight possibl dumouchel et al 1999 minim zm instead 0 larger valu lower order moment valu 3 minim w x n scalar valu variabl like person age number children household squash data valu need match sampl valu allow go outsid rang data thu squash data may record 22 children record 3 children 21 sampl squash issu data mine echo sampl two good refer sampl cochran 1977 lohr 1999 simpl random sampl cast trivial version squash let subset n distinct simpl random sampl without replac take strati sampl popul partit strata sampl n h valu taken stratum h weight nn h nn h make 1 hold function g indic strata regress estim use sampl theori incorpor known valu popul mean suppos 1n zm known form weight z zs 1 z regress weight satisfi 1 regress estim shown subsum stratic introduc indic variabl z regress stratic also combin sever way regress estim also wide use mont carlo simul known method control variat two gener refer bratley fox schrage 1987 ripley 1987 hesterberg 1995 good present reweight approach control variat 22 empir likelihood squash problem regress weight take neg valu may unus train algorithm one insist w 0 either solut 1 2 els n 1 dimension famili solut solut one might either increas n remov moment consider suppos n 1 dimension famili solut natur pick one somehow closest equal weight empir likelihood weight maxim subject z owen 1990 describ comput weight reduc minim convex function convex domain taken dimension euclidean space splu function avail httpwwwstatstanfordeduowen comput empir likelihood weight empir likelihood provid one way pick weight w closest equal one also use distanc measur kullbackliebl distanc helling distanc w 12 empir likelihood weight advantag comput slightli simpler altern minim euclidean distanc simpler still reduc regress weight 4 may neg owen 1991 23 benet weight stratic gener regress weight advantag reduc varianc associ estim let hx function data case let simpl random sampl estim h h varianc approxim 2 h n main error approxim multipl factor 1 nn take virtual one data squash eect regress weight reduc varianc 1 2 h n correl hx 1 reduct factor 1 r 2 r 2 proport varianc explain linear regress z show empir likelihood reduc asymptot varianc estim mean factor regress estim train method estim mean accur often shown predict accur simplest case like linear regr sion predict construct smooth function sampl moment complic set like maximum likelihood estim paramet vector dene equationsn log estim solv equationsn log fx qin lawless 1994 show empir likelihood weight produc varianc reduct compar unweight estim extent reduct depend well z correl deriv averag 5 baggerli 1998 show reduct hold distanc measur kullbackliebl helling 24 diminish return better paramet estim translat directli better predict rule gener diminish return exampl consid logist regress paramet vector simplic logist regress fact accur know mean know bay rule ordinari sampl estim approach error order n 12 weight misclass loss loss use typic 1 bay loss wol stork owen 1996 reason bay rule deriv respect expect misclass zero expect error approxim form b squash use approxim form b empir likelihood squash use xed list function gener expect 0 bay error b 0 domin estim error 1 regress empir likelihood squash bring small benet logist model fail hold instead take b 0 bay error take best error rate avail within logist famili squash method dumouchel et al 1999 adjust weight also estim new valu x sinc sampl quot result like empir likelihood squash suppos search x w eect match approxim match mani function valu n similar way gauss quadratur rule adjust locat weight numer integr davi rabinowitz 1984 integr higher order polynomi one adjust weight locat match function valu possibl come closer bay error rate cours reduc bay error rate thu could reason expect error form thu expect squash variou form eectiv case bay error domin sampl approxim error particular set zero bay error may benet enorm squash 25 expect benet reason expect better model coecient squash albeit eventu diminish gain predict accuraci order realiz gain coecient must relat quantiti correl valu g x precis vector log fx well approxim linear combin g x expect improv estim help distinguish local global featur data logist regress use global featur data reason expect featur could highli correl judici chosen global featur nearest neighbor method use local featur averag small region determin x valu reason expect one local averag correl global featur data therefor squash global featur g help nearest neighbor much improv one must consid way employ larg number local function g method like classic tree would seem priori intermedi rst split global featur data nal split made least larg tree local featur thu squash global g help rst split later one 3 exampl data data set inspir real commerci problem problem disguis order preserv condenti train data 92000 row 46 column data aris credit score problem sourc known data set transform obfusc describ row data describ one credit case row present random order column contain one variabl respons variabl column 41 0 1 describ bad good credit outcom respect may possibl attribut dollar valu bad good outcom dollar valu data receiv inde may exist data roughli 85 good case although necessarili percentag good popul variabl 2 40 42 predictor variabl describ credit histori case origin data valu transform origin valu given predictor put vector v 92000 element transform valu z v minvmaxv minv p power p chosen random independ predictor variabl miss valu remain miss transform contribut minv maxv column 1 score variabl use predict respons construct knowledg input variabl mean unknown possibl proprietari algorithm use gener column custombuilt score serv benchmark compar perform train method miss valu origin data store 99990 miss valu interpret avail believ 309262 miss valu 85 predictor valu column 19 almost 97 miss drop column 5 column 10 miss left data 78165 miss valu valu imput miss entri describ result 38 remain predictor prior build predict model data transform appli column predictor valu nonmiss valu replac x ij rais power p 0 chosen among valu 10g valu p 0 chosen maxim normal separ mean mean varianc pair x nonmiss x ij n yj number ij miss miss valu x p ij simpli replac imput valu 02 idea replac miss valu one neutral possibl regard classic hand 24430 observ one imput valu 4 logist regress rst classic method appli simpl logist regress train data contain case random order therefor simpl random sampl obtain take x rst n case 1000 2000 4000 8000 92000 weight unweight logist regress run weight 10 make weight unweight analys ident weight chosen 2 f0 1g weight mean x ij match unweight mean x ij reason choic follow simpl global classier base sole respons group condit mean varianc covari predictor reason expect condit mean carri relev inform mani predictor variabl allow use condit second moment condit moment match impos equat 1 take weight shown figur 1 smallest weight 035 largest 325 n increas weight becom nearli equal one possibl reweight data match condit moment use posit weight smallest sampl size use figur show euclidean distanc estim coecient vector full data coecient vector decreas n increas decreas faster empir likelihood weight estim term accuraci estim coecient empir likelihood weight increas eectiv sampl size roughli 4 figur 1 shown empir likelihood weight credit score data increas accuraci coecient estim lead increas accuraci classic diminish return figur 3 show receiv oper characterist roc curv sever classier describ data roc curv plot classier produc score function x predictor interpret score figur 2 shown distanc logist regress coecient 92 000 sampl point base subsampl lower line weight logist regress use empir likelihood weight function larger valu x make like point classi x 0 threshold 0 chosen trade error rate fals posit fals neg predict roc curv plot proport good versu proport bad 0 decreas 1 1 roc curv arc 0 0 1 1 top roc curv figur 3 correspond custom score vector suppli data solid line correspond empir likelihood weight logist regress n point 8000 92000 line increas increas n dash line correspond unweight logist regress 92000 weight unweight roc curv refer point 02 08 describ hypothet classic rule accept 80 good case 20 bad one custom rule nearli good roc curv tend make perform dierenc among classier look small part reason underli probabl plot rang 0 100 import distinct among real cla sier much smaller exampl dierenc 75 80 accept good case small plot like like practic import despit clear diminish return n increas whether weight unweight logist regress 8000 case produc roc curv essenti overlap logist regress 92000 figur 3 shown roc curv logist regress proprietari score percent good case classi good plot percent bad case classi good exampl point 02 08 describ unreal set 80 good case would accept along 20 bad case solid curv top bottom proprietari score empir likelihood weight logist regress sampl size 92000 8000 4000 2000 1000 dash curv top bottom unweight logist regress 8000 4000 2000 1000 case curv overlap signicantli describ text case empir likelihood weight produc overlap smaller sampl perhap although coecient keep get better perform tend converg limit reason expect better squash techniqu would get logist regress good full data logist regress even smaller sampl size empir likelihood weight logist regress roc curv figur 3 comput n point includ point use train littl risk overt sampl size n either larg compar 39 small compar evid logist regress overt notic logist regress 92000 case produc roc curv much better one 4000 case 5 boost tree logist regress fairli old classic techniqu modern classic method also make use observ weight also consid boost classic tree boost classic tree make predict combin larg number typic small classic tree extrem individu tree one split take weight sum stump produc addit model friedman 1999a friedman 1999b describ multipl addit regress tree mart model construct boost tree classier build earlier work friedman hasti tibshirani 1999 built turn freund schapir 1996 roc curv obtain mart use sampl size 1000 2000 4000 8000 92000 use empir likelihood weight unweight analys plot roc curv tend hard distinguish well logist regress custom method figur 3 curv separ visual interv 01 02 horizont axi rang roughli parallel cross among close curv custom 0217 0479 0651 0792 09448 099217 099761 099895 0999793 mart 0190 0485 0634 0774 09433 099172 099733 099891 0999871 logist 0163 0431 0604 0754 09244 099026 099720 099881 0999858 mart 4 0188 0456 0626 0770 09361 099150 099689 099877 0999832 mart 8 0189 0477 0636 0774 09419 099147 099707 099889 0999871 mart 1w 0143 0430 0585 0745 09238 098980 099656 099844 0999651 mart 2w 0178 0432 0598 0750 09274 098830 099571 099829 0999625 mart 4w 0170 0431 0599 0753 09326 098950 099624 099846 0999754 mart 8w 0183 0477 0633 0775 09435 099163 099720 099885 0999819 tabl 1 roc valu boost tree shown height 11 roc curv correspond 11 method describ text roc curv evalu horizont valu given top row tabl show numer valu roc curv valu smaller 05 given 3 signic place valu close 1 given dierenc 1 may comput 3 signic place region 010 020 weight unweigh mart model tend better larger sampl size use weight sometim help sometim hurt seem make much dierenc mart model respond global local featur data anticip weight might help global portion local one appear weight greatli acceler mart also investig boost tree use evalu copi mineset unabl obtain result better logist regress data appear benet use empir likelihood weight even boost stump global natur 6 discuss result empir likelihood base data squash encourag origin paper dumouchel et al 1999 outlin dierenc describ posit result might expect first base comparison primarili qualiti estim logist regress coecient like get good result coe cient nd diminish return classic perform also compar predict probabl squash model predict probabl full data set probabl determinist function coecient wont show diminish return way mi classic rate second dierenc report result local method addit global one found littl benet area ambiti squash describ dumouchel et al 1999 might abl make big improv thirdli reason expect optimist result entir appropri one data set anoth data set need investig data set 7 predictor use 38 consequ abl look interact consid sampl size larg enough reason match interact moment case data set compar total size 744963 record compar 92000 point origin motiv squash speed although much articl stress accuraci reason essenti speed gain achiev sampl squash repres gain sampl accur n diminish return suggest small n squash could much better sampl larger n practic valu disappear suggest squash use problem even one ll comput memori data one undersampl set maxim promis squash first problem near zero bay error might benet squash secondli classic one need comput score right side threshold problem one must predict numer valu eg prot versu protabl diminish return might set much later third record 7 38 predictor larg n memori record mani thousand million predictor much smaller valu n memori could gain form squash final squash describ dumouchel et al 1999 might serv good data obfusc devic organ could releas squash train data set squash test set research evalu learn method without ever releas singl condenti data record acknowledg thank bruce hoadley valuabl discuss data mine jerom friedman make avail earli version mart code work support nsf grant dms9704495 dms0072445 r scale cluster algorithm larg databas guid simul second edit method numer integr 2nd squash addit logist regress statist view boost stochast simul tr