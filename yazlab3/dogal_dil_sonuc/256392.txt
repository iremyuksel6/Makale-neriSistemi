adapt schedul parallel loop distribut sharedmemori system abstractus runtim inform load distribut processor affin propos adapt schedul algorithm variat differ control mechan propos algorithm appli differ degre aggress adjust loop schedul granular aim improv execut perform parallel loop make schedul decis match real workload distribut runtim experiment compar perform algorithm variat sever exist schedul algorithm two parallel machin ksr1 convex exemplar kernel applic program use perform evalu care select differ class parallel loop result show use runtim inform adapt adjust schedul granular effect way handl loop wide rang load distribut prior knowledg execut use overhead caus collect runtim inform insignific comparison perform improv experi show adapt algorithm five variat outperform exist schedul algorithm b introduct oop richest sourc parallel wide use scientif applic program mani scientif applic set independ task typic exist parallel loop call doall loop process element iter independ other perform loop schedul algorithm mainli affect three overhead sourc synchron loop alloc load imbal data commun although desir effici algorithm minim three sourc overhead usual imposs conflict aris among exploit processor affin processor affin refer certain data access depend task specif processor precis definit given section 31 favor alloc loop iter close data tend caus load imbal load balanc favor fine grain alloc loop iter small number iter alloc order minim effect uneven assign howev fine grain alloc tend increas synchron overhead loop alloc overhead differ applic overhead sourc affect perform differ henc effici loop schedul algorithm optim perform adapt trade synchron overhead loop alloc overhead load imbal overhead data commun overhead moreov dynam schedul algorithm assum prior knowledg execut time loop iter execut loop usual unpredict practic far mani novel dynam schedul algorithm propos eg 2 4 5 6 8 9 11 10 algorithm fall two distinct class central queue base distribut queue base central queue base algorithm 2 8 11 10 iter parallel loop store share central queue processor exclus grab iter central queue exe cute major advantag use central queue possibl evenli balanc workload keep good load balanc central queue base algorithm differ way reduc synchron loop alloc overhead howev three limit associ use central queue iter central queue like dynam alloc execut processor facilit exploit processor alloc processor one remot access central work queue therebi gener heavi network traffic processor contend central queue central queue tend perform bottleneck result longer synchron delay order exploit processor affin inher parallel execut mani loop elimin central bottleneck affin schedul algorithm propos 6 distribut central queue local proc 10459219971000 1997 ieee yan x zhang high perform comput softwar laboratori univers texa san antonio san antonio 782490664 c jin intervoic inc dalla texa email cjinintervoicecom manuscript receiv feb 19 1996 inform obtain reprint articl pleas send email transpdscomputerorg refer ieeec log number d96040 yan et al adapt schedul parallel loop sharedmemori system 71 essor algorithm partit iter parallel loop static local queue processor involv remot access load imbal occur markato leblanc 6 show affin schedul almost achiev best perform test case compar central queue base algorithm enhanc affin schedul algorithm presenc larg correl imbal loop execut time subramaniam eager 9 propos two loop partit method dynam partit wrap partit two partit method howev improv affin schedul specif applic execut specif assumpt distribut loop execut time design distribut queue base algorithm reason prefer kind loop partit method uniform partit due uneven unpredict execut time loop iter henc crucial distribut queue base algorithm abl dynam effici schedul task runtim even load imbal caus static partit exist affin schedul algorithm 6 9 processor schedul loop iter local queue use alloc scheme time 1p remain iter local queue alloc p number processor iter alloc scheme may effici exampl initi loop partit balanc processor complet execut iter local queue time processor grab iter local queue alloc instead 1p remain iter hand initi loop partit balanc lightli load processor finish execut iter local queue soon possibl immedi turn help heavili load processor henc processor abl dynam increas decreas alloc granular base runtim inform reduc synchron loop alloc overhead balanc load evenli motiv us design adapt schedul algorithm improv exist affin schedul algorithm major object paper exploit potenti dynam inform reduc loop execut time propos adapt schedul algorithm five variat algorithm dynam adjust alloc granular accord program execut histori classifi parallel loop execut pattern fairli select set applic experiment verifi effect algorithm comparison propos affin schedul algorithm 6 9 experiment result show use runtim inform adapt adjust schedul granular effect way handl wide rang load distribut prior knowledg use overhead caus collect runtim inform insignific comparison benefit gain method proper algorithm design experi show aggress algorithm use dynam format improv execut perform parallel loop adapt algorithm outperform exist schedul algorithm experiment organ paper follow section 2 describ detail main idea design adapt schedul algorithm present five variat differ degre aggress adjust loop schedul granular order assess precis effect propos algorithm practic analyz classifi program characterist applic section 3 select five repres kernel applic benchmark perform evalu section 4 report experiment result compari son summar paper section 5 similar affin schedul algorithm 6 adapt affin schedul algorithm also construct follow three phase initi partit phase determinist assign polici use partit iter parallel loop local queue processor ensur iter alway assign processor start assign scheme parallel loop execut repeatedli parallel iter access data set differ execut first execut parallel loop bring data local processor subsequ execut parallel loop involv local data access local schedul phase base local schedul polici processor alloc part remain iter local queue execut local queue empti local schedul caus remot access overhead local queue share processor critic section use protect alloc loop iter local queue local schedul overhead mainli come synchron overhead loop alloc overhead execut critic section reduc number alloc crucial improv perform local schedul phase remot schedul phase processor finish execut iter local queue remot alloc portion iter load processor system execut remot schedul phase aim dynam balanc workload iter reassign avoid processor thrash remot schedul caus remot data access overhead well synchron overhead loop alloc overhead instead reli preknowledg loop exe cution adapt affin schedul algorithm exploit potenti use dynam execut histori adapt adjust iter chunk size reduc synchron loop alloc overhead algorithm also maintain better load balanc main idea design minim local schedul overhead phase dynam balanc workload 72 ieee transact parallel distribut system vol 8 1 januari 1997 speed result reduct loop execut time initi phase loop n iter partit chunk uniform size np p processor reason prefer partit method absenc precis predict execut distribut loop iter initi partit ident one 6 local schedul phase process speed variabl term ps variabl set processor keep track number iter processor execut far initi set zero increas one time processor finish execut iter compar local ps variabl ps variabl processor observ load distribut time processor smaller ps variabl valu execut iter heavier workload execut processor larger ps variabl valu appli cation load distribut state certain steadi dura tion feasibl specul load distribut near futur current observ although applic realli surg varianc load distri bution predict differ minim dynam readjust order processor respons spontan dynam chang iter work load necessari differenti workload state processor fair select averag number iter execut processor ie p pivot partit workload state processor follow three type heavili load hlthe processor ps valu smaller p normal load nlthe processor ps valu within rang p p lightli load llthe processor ps valu equal larger p nonneg rang control variabl adjust distribut hl processor nl processor processor variat paramet would affect algorithm perform dynam featur execut real applic loop make impract imposs analyt determin optim valu discuss effect differ valu perform experi give empir method determin performanceeffici order control chunk size alloc loop erat chunksiz control variabl k set processor processor alway remov 1k remain iter local work queue execut begin local schedul phase chunksiz control variabl initi valu p total number processor adapt independ adjust chunksiz control function p function p use load state current valu k processor two input paramet adjust chunksiz control variabl processor heavili load p increas k aim reduc chunk size iter remain heavili load processor execut lightli load processor therefor balanc workload effici processor normal load lightli load p decreas k aim increas chunk size normal load lightli load processor finish iter local work queue soon possibl immedi start help heavili load processor processor complet execut iter local queue turn remot schedul phase affin schedul algorithm 6 processor exhaust local work queue start help heavili load processor remov 1p remain iter heavili load processor alloc method may effici processor turn help processor determin chunk size accord current number lightli load normal load processor abl help heavili load processor near futur processor determin chunk control variabl k follow n total number lightli load processor normal load processor n mean includ heavili load processor processor alloc remain iter p total number processor processor alloc 1k remain iter heavili load processor execut procedur repeat local work queue empti initi k smaller valu p big chunk size use reduc number remot alloc experi next section show select big chunk size increas risk imbalanc load subsequ processor becom lightli load normal load k increas reach maxim valu p follow pseudocod descript adapt affin schedul algorithm given impl mentat code automat insert compil applic program processor dynam schedul execut loop without interfer oper system exist work gener dynam schedul program hand experi order focu algorithm studi 1 initi partit phase initialpartitionn p n iter uniformli partit p processor iter processor yan et al adapt schedul parallel loop sharedmemori system 73 2 local schedul phase processor loop processor get 1k local iter execut adjust k 1k iter rang load state processor adjust chunk granular 3 remot schedul phase processor loop locklocalqueuej iter processor j iter finish adapt chang loop schedul granular major characterist distinguish adapt affin schedul affin schedul algorithm 6 remot read ps variabl processor overhead caus adapt schedul algorithm collect execut histori processor increas overhead nullifi benefit adapt vari loop schedul granular adapt affin schedul algorithm may exhibit perform improv exist affin schedul algorithm differ variat adapt affin schedul algorithm construct design differ chunk size control protocol function p propos four mechan adapt algorithm let k chunk size control variabl processor local schedul phase exponenti adapt ea mechan ea mechan processor increas decreas valu chunksiz control variabl k factor time accord current load state chunksiz control function p formal defin state base base c h base integ constant choos two base initi k set p adapt algorithm linearli adapt la mechan la mechan processor increas decreas chunk size control variabl k constant time interv accord current load state chunksiz control function p formal defin state con con con constant specifi user choos 1 experi la mechan chang chunk size slower pace ea algorithm less risk imbalanc work load larger synchron loop alloc overhead conserv adapt ca mechan care select chunk size loop schedul algorithm crucial find compromis synchron overhead load imbal anc alloc bigger chunk iter loop tend reduc synchron loop alloc overhead increas risk imbalanc load previou work 5 show order reason load imbal synchron head safe chunk size control variabl k choos valu p 2p ca mechan construct restrict vari rang chunk size control variabl la mechan within p2 2p chunk size control function defin follow state min con constant 0 p use one experi greedili adapt ga mechan ga mechan employ twophas consensu method greedili enlarg chunk size non heavili load processor ga mechan record previou load state processor processor find nonheavili load state two consecut alloc greedili reduc chunksiz control variabl 1 ie grab remain iter local work queue exe cute otherwis processor increas decreas chunk size use conserv method ca mechan pre record previou load state processor let c record current load state processor chunk size control function r pre c pre min c h hl hl hl hl keep maintain ps variabl processor allow four adapt mechan know exactli current workload processor therebi ps variabl use adjust speed proc 74 ieee transact parallel distribut system vol 8 1 januari 1997 essor consequ adjust workload among processor also introduc loop alloc head design heurist variat denot still adopt framework adapt schedul algorithm instead use ps variabl determin workload distribut among processor use number iter actual execut processor guid adjust schedul granular initi parallel loop uniformli distribut proce sor processor repeat grab 1k remain iter local queue execut without adjust k processor finish iter local work queue turn get iter heavili load processor j processor said lightli load processor j heavili load processor increas schedul granular processor decreas schedul granular henc lightli load processor turn earli possibl help heavili load processor heavili load processor remain much workload possibl even lightli load processor end execut parallel loop processor check whether execut approxim number iter ie balanc workload processor increas schedul granular speed subsequ execut parallel loop compar four variat adapt algo rithm ea la ca ga ha variat differ sever aspect instead determin load state time local schedul use adapt algo rithm ha variat updat load state processor remot schedul phase end one execut parallel loop caus less schedul overhead adapt algorithm 2 ha variat work requir parallel loop nest sequenti loop execut repeatedli parallel loop execut ha variat becom affin algorithm 6 pseudocod heurist variat adapt affin schedul algorithm ha variat shown follow 1 initi partit phase initialpartitionn p n iter uniformli partit p processor iter processor 2 local schedul phase processor loop locklocalqueuei remain iter 3 remot schedul phase processor loop locklocalqueuej iter processor j increas chunk size processor decreas chunk size processor j 4 program section end parallel loop barrierbarri p tid execut code findmaximumandminimumofchunk kmax kmin p2 workload bal anc increas chunk size processor barrierbarri p markato leblanc 6 show affin schedul algorithm hereaft simplifi ml algorithm outperform algorithm exploit processor affin henc focu compar variat adapt schedul algorithm affin schedul algorithm two variat 9 schedul algorithm evalu compar 1 ml affin schedul algorithm 2 se dynam initi partit affin schedul algorithm adapt affin algorithm exponenti adapt mechan ea adapt affin algorithm linearli adapt affin mechan la 5 adapt affin algorithm conserv adapt mechan ca adapt affin algorithm greedili adapt mechan ga 7 heurist adapt variat ha experi conduct two machin ksr1 hierarchicalringbas cach coher sharedmemori system convex examplar crossbar ringbas cach coher sharedmemori system address method select applic kernel evalu algorithm 31 principl select applic kernel consid effect program featur schedul algorithm character parallel loop three factor affin loop iter processor distribut loop execut time granular loop iter iter parallel loop may exhibit affin processor loop nest sequenti loop execut repeatedli one fact parallel process domin overhead sourc mani applic commun synchron henc first classifi parallel loop two class potenti affin parallel loop nest sequenti loop nonaffin parallel loop execut strong iter potenti affin parallel loop exhibit affin processor significantli affect size data set access iter data local iter better data local iter mean data set access iter chang less significantli differ execut iter data local determin affin iter processor hand size data set access iter determin benefit exploit processor affin parallel loop better data local iter small data set eg one integ exploit processor affin improv execut time parallel loop balanc load reduc synchron overhead let di data set iter ith execut parallel loop let di size byte data set di n fi averag size data set iter n execut parallel loop n f f1 averag size differ two data set two consecut loop execut iter indic approxim much data reload execut iter parallel loop data local iter quantit evalu follow defin local rate local rate valu 0 1 local rate one mean iter alway access set data larger local rate repres better data local strong iter affin processor quantit evalu localityr averag number data set access repeatedli data set may alway store local cach select potenti affin parallel loop use data local data size differenti affin iter processor unpredict varianc execut time parallel loop major obstacl loop schedul algorithm work effici order show much parallel loop schedul algorithm toler differ distribut workload among iter select parallel loop load distribut cover three distinguish type loop balanc loop iter amount comput time predict imbalanc loop comput time iter parallel loop vari predict function loop control variabl load distribut parallel loop fix execut repeatedli unpredict imbalanc loop comput time iter chang randomli depend initi input runtim variabl eg execut time branch statement depend actual execut path ml algorithm handl load imbal remot schedul se algorithm improv ml algorithm perform predict imbalanc parallel loop load distribut parallel loop chang multipl execut parallel loop execut time iter loop increas decreas monoton loop control variabl adapt algorithm variat dynam adjust loop schedul granular speed load balanc procedur base execut histori processor follow experi show adapt algorithm handl load imbal effici wider rang ml se algorithm besid affin load distribut iter granular loop anoth import factor affect perform loop schedul algorithm parallel loop coars granular execut time loop iter significantli larger overhead remot access delay balanc workload crucial reduc synchron loop alloc head parallel loop fine granular execut time loop iter much smaller overhead remot access delay import minim schedul overhead determin iter granular parallel loop depend interact parallel loop underli system difficult tell whether parallel loop coars grain fine grain execut instead classifi parallel loop granular consid effect iter granular experi base analys classifi parallel loop six type affin load distribut loop potenti affin balanc workload ii loop potenti affin predict workload iii loop potenti affin unpredict workload iv loop nonaffin balanc workload v loop nonaffin predict workload vi loop nonaffin unpredict workload order complet understand well schedul algorithm work area realworld applic select one applic type loop nonaffin unpredict workload rare case practic therefor evalu schedul algorithm applic first five type loop 32 applic select applic kernel includ potenti affin loop success overrelax sor type jacobi iter ji type ii transit closur tc type iii matrix multipl mm type iv adjoint convolut type v applic kernel includ non affin loop type balanc affin loop sor 76 ieee transact parallel distribut system vol 8 1 januari 1997 iter sor parallel loop take time execut iter alway access set data exploit processor affin may improv perform better balanc workload applic parallel iter local rate one data set n array element comput granular parallel iter type ii predict affin loop jacobi iter ji iter precis ajk ne 0andj ne ji program top 20 row element nonsingular matrix nonzero element gener random number gener iter parallel loop differ workload determin distribut nonzero element exploit load imbal would improv perform howev workload parallel iter chang execut repeatedli jth iter parallel loop alway access jth row matric bj x0j jth iter fix execut repeatedli processor need reload x0j cach x0j updat execut parallel loop henc applic kernel exhibit good processor affin iter data set size n data local close one averag comput granular iter smaller sor kernel type iii unpredict imbalanc affin loop transit closur tc kernel aji eq true aik eq true may exhibit seriou load imbal ji iter parallel loop execut parallel iter may comput granular o1 depend input matrix iter exhibit weaker affin processor sor ji due random comput fea ture difficult quantifi data local affin parallel iter type iv balanc nonaffin loop matrix multipl mm cijcijaik mm program affin exploit parallel iter comput granular reduc synchron loop alloc overhead way improv perform applic use investig whether adapt algorithm lower schedul overhead ml algorithm type v predict imbalanc nonaffin loop adjoint convolut ac similar matrix multipl applic parallel loop ac kernel execut henc exhibit processor affin howev comput granular ith parallel iter 2 chang specif function control variabl produc signific imbalanc load distribut triangular pat tern kernel use examin effici adapt algorithm handl load imbal caus uniform partit perform metric use evalu algorithm execut time execut time measur differ schedul algorithm work differ type applic given problem size 41 comparison loop schedul algorithm first use np 2 valu four adapt schedul variat ca la ea ga shall discuss effect valu perform later section discuss np 2 costeffect next section fig 1 present execut time second sor run two eight processor ksr1 convex exemplar sinc sor perfectli balanc applic kernel dynam partit se algorithm improv perform ml affin algorithm hand introduc overhead ml algorithm result ml se perform worst among due overhead caus loop alloc synchron step adapt increas chunk size yan et al adapt schedul parallel loop sharedmemori system 77 time processor access local work queue adapt algorithm reduc time processor need access local work queue therefor schedul synchron overhead reduc five adapt algorithm outperform ml se algo rithm ea ga perform best among sinc take three step adjust chunk size finish remain iter la variat need alloc step ea ga need ha ca variat chang chunk size limit rang therefor could get best benefit reduc synchron loop alloc overhead perfectli balanc applic fig 2 plot execut time jacobi iter ji differ schedul algorithm ksr1 convex exemplar ji applic fit se algorithm best sinc workload distribut illustr rectangular shapeth leftmost 20 heavi load remain 80 almost zero workload se algorithm readjust initi partit balanc workload processor improv execut time lower execut time curv se algorithm confirm instead readjust initi partit adapt algorithm reduc execut time adjust chunk size processor lightli load processor took larger number iter execut turn help heavili load processor heavili load processor took small number iter execut might leav iter processor finish solv linear system size ji kernel la ga ea ha variat perform well se ca variat perform slightli wors adapt algorithm use ca variat processor zero workload still take 2p iter execut therefor need time finish lightli load job turn help heavili load processor meantim heavili load processor may alreadi taken larg number job execut leav enough job idl processor b fig 1 perform sor ksr1 exemplar b b fig 2 perform ji ksr1 exemplar b 78 ieee transact parallel distribut system vol 8 1 januari 1997 fig 3 present execut time transit closur kernel random input graph 1024 node 10 edg uniformli present execut parallel loop workload uniformli distribut among iter howev total workload increas next execut parallel loop fig 3a fig 3b show compar perform seven test algorithm respect ksr1 machin exemplar se algorithm ml algorithm perform similarli case se algorithm littl chanc improv ml algorithm readjust load distribut algorithm la ea ga perform best among adjust schedul granular aggress combin result experiment result sor conclud load balanc applic aggress adjust schedul granular effici method reduc schedul synchron head thu improv perform well result also show overhead collect state inform signific compar benefit gain adapt adjust schedul granular test schedul algorithm variat transit closur kernel skew input graph 640 node contain cliqu 320 node edg case load imbal signific comput across iter total load parallel loop increas one execut next execut time schedul algorithm present fig 4a fig 4b although author 9 claim se algorithm assum execut time particular iter vari wide one execut loop anoth result show se algorithm still improv ml algorithm case studi adapt algorithm captur varianc load precis se algorithm la ea ga ha perform better se algorithm variat perform similarli se algorithm b fig 4 perform tc skew input ksr1 exemplar b b fig 3 perform tc random input ksr1 yan et al adapt schedul parallel loop sharedmemori system 79 experiment result show adapt adjust schedul granular effici way handl load imbal unpredict loop applic parallel loop embed sequenti loop call nonaffin loop se algorithm heurist variat ha chanc improv ml affin algorithm adjust initi partit adjust chunk size near end one execut parallel loop hope new partit new chunk size play role next execut parallel loop want see adapt variat perform better ml algorithm nonaffin loop fig 5a fig 5b present perform schedul algorithm matrix multipl mm algorithm ml se ha perform similarli algorithm ea la ga dynam detect workload distribut condit rapidli increas chunk size processor take remain iter execut access local work queue variat also increas chunk size limit 2p remain iter therefor involv less synchron loop alloc overhead ml present overhead ga la ea compar experiment result kernel sor adapt variat improv ml algorithm mm significantli parallel loop execut one time fig 6a fig 6b present perform schedul algorithm kernel adjoint convolut 128 se ha could improv ml algorithm sinc parallel loop embed within sequenti loop load imbal across iter signific sinc first iter took time proport 2 last iter took time proport o1 expect ml se ha perform similarli ea la ga perform best among ca variat perform 42 determin costeffici valu previou section use np 2 valu adapt schedul algorithm variat b fig 6 perform ac ksr1 exemplar b b fig 5 perform mm ksr1 exemplar b n number iter parallel loop p number processor use execut parallel loop test sever valu tri give optim valu evalu adapt schedul algorithm variat differ valu five benchmark applic ksr1 exemplar valu select evalu np np 2 32 4 respect due space limit present part result two adapt schedul variat ea ca respect one kernel applica tion remain result specifi follow also support conclus go present fig 7a present perform sor kernel ksr1 use ea adapt variat differ valu also present perform ml algorithm run sor kernel comparison ea show best perform ea present worst perform sinc sor wellbalanc applic processor normal workload larg valu like np guarante workload state processor alway normal processor increas chunk size reduc execut time although sor wellbalanc sometim event cach miss page fault interprocessor commun delay bring execut time varianc among iter use small valu 4 presenc interfer kind event processor take workload state heavi therefor decreas chunk size factor two sinc give limit chunk size ea variat decreas chunk size exponenti rate may caus processor take small chunk processor may take one iter access local work queue similar selfschedul ea spent much time ml number processor two four number processor increas six eight 4 becom close np 2 reason hold 2 processor determin workload state correctli due system interfer small valu number processor increas get close valu np 2 therefor good perform algorithm number processor four six eight fig 7b present perform sor applic ksr1 use ca adapt variat differ valu also show curv ml algorithm curv ea variat 4 order compar fig 7b show ca np perform best among ca show small valu comparison valu np 2 may caus neg effect perform adapt algorithm due system interf enc ca perform worst among curv also notic curv much lower ea 4 reason limit rang chunk size ca variat within p2 2p guarante processor take least 1 remain iter execut access local work queue 5 conclus adapt adjust loop alloc granular accord workload execut speed proc essor loop schedul algorithm demonstr better perform affin schedul algorithm propos markato leblanc 6 dynam partit affin schedul algorithm propos subramaniam eager 9 author shown two algorithm present best perform among loop schedul algorithm adapt schedul algorithm suitabl wider rang applic program reduc execut time well loadbalanc parallel loop also load unbalanc parallel loop experi show overhead caus collect state inform sig b fig 7 perform sor ksr1 use ea differ valu use ca differ valu b yan et al adapt schedul parallel loop sharedmemori system 81 nific compar benefit gain one import conclus research effici use runtim inform significantli improv effici loop schedul algorithm among variat adapt schedul algo rithm ea la ga variat alway demonstr better perform ca ha variat although ea la ga higher risk ca term caus loadimbal term much sensit system interfer observ worst perform phenomena case studi ping pong effect state processor often switch lightli load heavili load caus overwhelm schedul head addit neg effect ea la ga variat significantli reduc select appropri workload control constant np 2 current develop analyt model determin optim valu machin architectur may anoth import factor affect perform loop schedul algorithm far abl test adapt algorithm variat ksr1 exemplar experiment result indic algorithm perform quit independ sharedmemori architectur ever effect adapt algorithm significantli affect system size system size scale larg cost collect runtim inform increas advantag adapt algorithm nullifi increas overhead adapt algorithm suitabl schedul parallel loop small number processor acknowledg appreci neal wagner samir da care read manuscript construct comment wish thank anonym refere help comment suggest work support part us nation scienc foundat grant ccr 9102854 ccr9400719 us air forc research agreement fd20409264157 air forc offic scientif research grant afosr9510215 r convex comput corp factor practic robust method schedul parallel loop dynam schedul method irregular parallel program safe selfschedul parallel loop schedul scheme sharedmemori multiproc sor use processor affin loop schedul sharedmemori multiprocessor design tradeoff process schedul share memori multiprocessor system guid selfschedul practic selfschedul scheme parallel supercomput affin schedul unbalanc workload processor selfschedul multipl nest parallel loop trapezoid selfschedul practic schedul scheme parallel compil tr ctr tatiana tabirca len freeman sabin tabirca laurenc tianruo yang feedback guid dynam loop schedul converg continu case journal supercomput v30 n2 p151178 novemb 2004 jose l aguilar ernst l leiss data depend loop schedul base genet algorithm distribut share memori system journal parallel distribut comput v64 n5 p578590 may 2004 clemen grelck svenbodo scholz sac offtheshelf support dataparallel multicor proceed 2007 workshop declar aspect multicor program p2533 januari 1616 2007 nice franc yong yan xiaodong zhang zhao zhang cachemin runtim approach exploit cach local smp ieee transact parallel distribut system v11 n4 p357374 april 2000 sotiri ioannidi umit rencuzogullari robert stet sandhya dwarkada craulcolon compil runtim integr adapt load1thi work support part nsf grant cda9401142 ccr9702466 ccr9705594semi extern research grant compaq scientif program v7 n34 p261273 august 1999 clemen grelck share memori multiprocessor support function array process sac journal function program v15 n3 p353401 may 2005