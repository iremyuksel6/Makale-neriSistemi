adapt precondit gmre algorithm restart gmre algorithm propos saad schultz siam j sci statist comput 7 1986 pp 856869 one popular iter method solut larg linear system equat axb nonsymmetr spars matrix algorithm particularli attract good precondition avail present paper describ two new method determin precondition spectral inform gather arnoldi process iter restart gmre algorithm method seek determin invari subspac matrix associ eigenvalu close origin move eigenvalu higher rate converg iter method achiev b introduct mani problem appli mathemat engin give rise larg linear system equat spars nonsymmetr nonsingular matrix often desir sometim necessari solv system iter method let x 0 initi approxim solut 11 let r associ residu vector introduc krylov subspac associ matrix vector r 0 mani popular iter method determin mth iter xm xm gamma x refer method krylov subspac iter method see eg freund et al 12 recent review let iter xm gener krylov subspac iter method residu error r associ xm satisfi residu polynomi pm determin iter method satisfi denot euclidean norm r n well associ induc matrix norm r nthetan restart gener minim residu algorithm saad schultz 22 describ section 3 one popular krylov subspac iter method solut linear system nonsymmetr matrix residu polynomi determin algorithm satisfi depart mathemat comput scienc kent state univers kent oh 44242 email jbaglamamcskentedu research support part nsf grant f377 dmr8920147 alcom depart mathemat scienc steven institut technolog hoboken nj 07030 email nacalvettinanetornlgov research support part nsf grant dms9404692 z comput scienc depart stanford univers stanford ca 94305 x depart mathemat comput scienc kent state univers kent oh 44242 email reichelmcskentedu research support part nsf grant dms9404706 j baglama et al denot set polynomi p degre analysi implement restart gmresm algorithm modif thereof continu receiv consider attent see eg 4 5 7 algorithm particularli attract suitabl precondition nthetan matrix avail see eg 2 15 21 recent discuss precondition matrix gamma1 good precondition applic iter method interest precondit linear system equat give higher rate converg comput iter applic iter method origin linear system 11 moreov would like precondition gamma1 properti w 2 r n vector gamma1 w rapidli evalu matrix gamma1 15 sometim refer left precondition present paper describ two new adapt method determin precondition iter restart gmresm algorithm standard implement restart gmresm algorithm 22 base arnoldi process 1 describ section 2 allow spectral inform gather iter use inform determin approxim invari subspac associ eigenvalu close origin precondition essenti remov influenc eigenvalu rate converg focu effect precondition spectrum howev known rate converg iter comput gmresm algorithm also determin pseudospectra see nachtig et al 19 eas present ignor effect precondition pseudospectra present paper precondition particularli effect cluster eigenvalu larg influenc rate converg illustr found section 4 determin well applic precondition requir evalu matrixvector product matrix addit need arnoldi process evalu certain residu error implement use recurr formula implicitli restart arnoldi ira method describ sorensen 23 recent lehoucq 17 precondition combin precondition also applic known effici precondition avail differ method adapt determin precondition iter restart gmresm algorithm recent describ erhel et al 11 util recurr formula ira method precondit scheme allow flexibl choic precondition requir less comput memori method describ 11 anoth adapt precondit method present kharchenko yeremin 16 method differ scheme approxim invari subspac determin morgan 18 also use approxim invari subspac improv rate converg restart gmresm algorithm instead construct precondition append approxim invari subspac krylov subspac gener arnoldi process feel new algorithm attract simplic ira method algorithm base typic determin adequ approxim invari subspac fairli rapidli adapt precondition 3 let matrix spectral factor 13 14 yield bound denot spectrum note bound 17 would decreas abl replac subset precondition roughli effect definit assum eigenvalu order accord let scale good approxim scale determin iter discuss arnoldi process determin decomposit form vm 2 r nthetam mthetam upper hessenberg matrix refer 110 arnoldi decomposit throughout paper e j denot jth axi vector appropri dimens j denot ident matrix order j vm e column vm span krylov subspac km r 0 defin 12 futur refer defin let matrix v k 2 r nthetak consist first k column vm let column matrix wngammak span r n nspanfv k g spanfv k g denot span column v k assum w ngammak thu column matrix v k wngammak form orthogon basi r n introduc matrix use invers matric form 112 k n left precondi tioner form invers given proposit 11 let q 2 r nthetan orthogon matrix partit accord submatrix v consist k first column q submatrix w consist remain column assum nonsingular matrix nonsingular invers given 4 j baglama et al proof matrix 113 written theta ngammak therefor theta ngammak show 114 column matrix v proposit 11 span invari subspac eigenvalu matrix gamma1 express term eigenvalu corollari 12 let matric v w h proposit 11 assum moreov column matrix v span invari subspac associ eigenvalu eigenvalu 1 multipl least k proof matrix similar theta 12 22 22 ng formula 116 represent 115 yield theta 12 22 thu spectrum gamma1 consist 22 eigenvalu 1 multipl latter eigenvalu least k result analog corollari 12 right precondition shown erhel et al 11 remark applic precondition form 114 simplifi fact thu matrix w comput follow exampl compar bound rate converg iter determin gmresm algorithm appli origin linear system 11 precondit linear system 15 precondition 114 assum condit corollari 12 hold exampl 11 assum spectral factor form 16 eigenvalu real posit let eigenvalu order accord 18 17 yield lim sup min adapt precondition 5 tm z chebyshev polynomi first kind degre interv equal 119 follow wellknown properti chebyshev polynomi see eg 13 section 1015 precondition 114 assum condit corollari 12 hold precondition elimin influenc k smallest eigenvalu rate converg gmresm algorithm specif gmresm algorithm appli precondit linear system 15 yield sequenc residu vector bound lim sup usual r bound 120 shown first note lim sup appli bound 118 righthand side 121 2 actual comput determin precondition krylov subspac spanfv k g close invari subspac comput exampl 11 suggest gmresm algorithm requir fewer iter determin accur approxim solut 11 appli precondit linear system 15 precondition appli origin unprecondit system 11 verifi numer experi present section 4 2 construct precondition section describ determin approxim invari subspac associ eigenvalu use recurs formula ira method sorensen 23 first present arnoldi process 1 algorithm 21 arnoldi process input k upper hessenberg matrix h output upper hessenberg matrix nthetam h j v endfor jwe may assum vector f gener algorithm 21 nonvanish f column matrix v j gener span invari subspac v j use construct precondition describ exampl 11 input algorithm 21 initi vector f 0 6 j baglama et al provid note f 6 0 defin matrix orthogon column sequel use matrix matrix hessenbergtyp whose lead theta princip submatrix hm whose 1st row numer difficulti aris comput vector f j al gorithm comput done modifi gramschmidt process one reorthogon neglect enforc orthogon vector f j vector give rise spuriou eigenvalu matrix hm ie eigenvalu consid approxim eigenvalu given arnoldi decomposit 110 initi vector recurs formula ira method use comput vector monic polynomi degre evalu new matrixvector product matrix coeffici jmgammak scale factor chosen kv mgammak 1 discuss select zero z j recurs formula ira method truncat version recurs formula qr algorithm explicit shift zero z j chosen shift see eg 13 chapter 7 descript qr algorithm therefor sometim refer zero z j shift thu let decomposit 110 given determin qr factor r 1 upper triangular put also hessenberg matrix multipl equat 242 e 1 yield ae 1 equat 25 display relationship initi arnoldi vector v 1 vector v 1 1 appli shift obtain decomposit 2 adapt precondition 7 denot orthogon matrix associ shift z j introduc partit hmgammak equat first k column righthand side lefthand side 26 give v mgammak mgammak follow 28 v mgammak thu 27 arnoldi decomposit construct vector v mgammak written 23 descript ira method base recurs formula qr algorithm explicit shift implement base qr algorithm implicit shift reason numer stabil see 13 chapter 7 descript qr algorithm use implicit shift allow applic complex conjug shift without use complex arithmet first appli arnoldi process comput arnoldi decomposit 110 use recurs formula ira method determin arnoldi decomposit 27 purpos comput determin accur approxim invari subspac associ eigenvalu would like choos zero z z mgammak mgammak first column v mgammak k defin 23 close invari subspac associ eigenvalu let f denot eigenvalu upper hessenberg matrix hm 110 order avm orthogon project consid j approxim eigenvalu order forc vector v mgammak 1 invari subspac associ k eigenvalu smallest magnitud choos zero ie z j chosen avail approxim eigenvalu largest magnitud select zero discuss sorensen 23 calvetti 8 j baglama et al et al 6 lehoucq 17 zero refer exact shift numer experi indic order shift accord 210 adequ sens comput matric h mgammak close k eigenvalu hm smallest magnitud let f k j1 eigenvalueeigenvector pair h mgammak k introduc vector approxim eigenvalueeigenvector pair residu error accept spanfv k g approxim invari subspac kf mgammak ffl subspac 0 paramet purpos matrix h mgammak k 211 make bound invari scale inequ 211 satisfi appli algorithm 21 arnoldi decomposit 27 input order determin new arnoldi decomposit 110 theta upper hessenberg matrix hm appli recurs formula ira method zero chosen hm largest magnitud give arnoldi decomposit form 27 check whether inequ 211 satisfi comput repeat fashion 211 hold obtain way arnoldi decomposit form 27 matric k h k gener spanfv k g accur approxim invari subspac associ k eigenvalu smallest magnitud h k accur approxim set f j g k accuraci approxim depend paramet ffl subspac 211 distribut eigenvalu departur normal matric v k h k obtain use defin first precondition use 117 describ section 3 combin ira process restart gmre algorithm richardson iter improv avail approxim solut 11 determin precondition gamma1 1 comput precondition 1 appli method outlin precondit system 15 order determin approxim invari subspac associ eigenvalu smallest magnitud matrix simultan improv avail approxim solut 11 yield new precondition gamma1 2 system gamma1 equival new precondition 1 system 11 comput continu manner determin precondition form specifi integ ff 0 1 form 213 precondition make natur scale 19 hold approxim scale achiev scale linear system 11 factor 1j eigenvalu adapt precondition 9 largest magnitud one matric hm gener algorithm 21 comput precondition gamma1 1 remark certain matric techniqu achiev scale may avail instanc one may abl use gershgorin disk inequ matrix norm induc vector norm see 24 chapter 6 detail latter topic 3 iter method section describ two algorithm adapt precondit detail one algorithm 35 combin ira process richardson iter gmre algorithm scheme algorithm 36 appli richardson iter first recal restart gmresm algorithm saad schultz 22 solut linear system equat 11 algorithm 31 restart gmresm algorithm input initi approxim solut x output approxim solut xm associ residu vector r krm kkr solut comput algorithm 21 input matric vm1 hm defin 21 22 respect also avail comput solut ym hm yk endwhilew describ improv avail approxim solut richardson iter appli recurs formula ira method arnoldi decomposit iter carri without evalu matrixvector product matrix let x 0 avail approxim solut 11 richardson iter written relax paramet would like paramet ffi j approxim solut x j converg rapidli solut 11 j increas futur refer note residu vector 32 written theorem 32 let x 0 approxim solut 11 let r consid arnoldi decomposit initi vector k appli recurs formula ira method zero z residu vector 32 associ iter 31 comput richardson iter relax paramet j baglama et al given q denot orthogon matrix r upper triangular matrix associ zero z ira recurs formula moreov v proof first show 34 1 substitut v represent 33 show turn case 2 33 35 obtain replac vmq 1 equat 241244 multipli equat 242 obtain e 1 show analog 25 substitut 37 36 show 34 2 continu manner yield case treat separ arnoldi decomposit similarli 3 obtain v 1 choos ae complet proof prior develop gmresm algorithm saad 20 introduc full orthogon algorithm galerkin method solut 11 let x 0 approxim solut 11 let r 0 associ residu vector consid arnoldi decomposit 110 let v theorem 32 fom algorithm determin improv approxim solut xm 11 solv linear system let follow result show approxim solut determin richardson iter theorem 33 let vector x 0 r 0 arnoldi decomposit 110 theorem 32 assum arnoldi decomposit exist adapt precondition 11 kfm k 6 0 matrix hm arnoldi decomposit nonsingular let 34 let relax paramet richardson iter reciproc valu eigenvalu hm exact arithmet approxim solut xm determin richardson iter 3132 equal approxim solut comput fom algorithm proof substitut use fact linear system 38 written hm introduc polynomi f g bilinear form construct g j polynomi degre j particular equat 310 311 yield show pm residu polynomi degre fom algorithm therefor satisfi pm combin formula 110 311 yield ident show eigenvalu f hm zero gm particular therefor pm written pm follow comparison 312 13 33 show step richardson iter relax paramet j applic fom algorithm correspond residu polynomi therefor equival implement iter method base follow observ corollari 34 let x j gamma1 approxim solut 11 let r associ residu vector let arnoldi decomposit initi vector j1 eigenvalu h let x approxim solut j baglama et al obtain one step richardson iter relax paramet q let applic recurs formula ira method 313 shift q yield arnoldi decomposit av 1 triangular matrix qr factor h moreov h 1 proof corollari follow theorem 32 fact use exact shift eigenvalu reduc matrix h 1 eigenvalu origin matrix h except shift latter result shown sorensen 23 lemma 310 corollari show appli shift one time determin requir residu vector first column matric v avail arnoldi decomposit analog result establish complex conjug shift latter case recurs formula ira method implement use qr algorithm implicit doubl shift obviat need use complex arithmet doubl step richardson iter complex conjug relax paramet also carri without use complex arithmet notat simplic algorithm iter method use doubl shift doubl step howev implement algorithm use comput exampl section 4 algorithm 35 adapt precondit gmresm algorithm richardson iter input toler comput approxim solut ffl solut toler approxim invari subspac ffl subspac dimens largest krylov subspac determin dimens k approxim invari subspac comput maximum number ff 0 precondition gamma1 j comput maximum number fi 0 arnoldi decomposit order determin precondition output comput approxim solut x associ residu vector r j precondition comput algorithm 21 initi vector comput eigenvalu f matrix hm arnoldi decomposit order accord 29 scale matrix righthand side linear system factor 1j j equat 19 approxim satisfi appli shift m1gamma arnoldi decomposit comput residu vector gamma1 r j describ corollari 34 give mgamma adapt precondition 13 endfor bound 211 satisfi goto use arnoldi decomposit gamma1 av mgammak k input algorithm 21 appli arnoldi process comput arnoldi decomposit endfor fi 1 improv approxim solut gmresk updat precondition k well matric 22 avail comput solut k 2 r k min 2 gamma1 3 r jk solut done endfor ff kr j kkr solut appli algorithm 21 initi vector matric vm1 hm defin 21 22 respect comput solut ym 4 r jm endwhilein algorithm 35 comput matrixvector product matrix appli arnoldi process evalu residu vector r line label 3 4 examin storag requir algorithm 35 count number nvector store storag necessari repres matrix ignor sinc independ iter method use precondition requir storag n theta k matrix v k limit number precondition ff 0 thu precondition gamma1 defin 213 requir storag ff 0 k nvector particular matrix gamma1 actual form line mark 2 algorithm 35 interpret symbol mean storag matrix gamma1 formula evalu matrixvector product gamma1 updat gmresm algorithm whileloop algorithm 35 requir addit storag vector x j r j matrix vm1 2 r nthetam1 equival storag 3 nvector vector algorithm 35 scale factor store first column matrix vm1 last column vm1 contain vector fm scale factor righthand side vector b also store therefor total storag requir algorithm 35 ff algorithm 36 obtain replac richardson iter algorithm 35 gmre algorithm replac make residu error decreas smoothli iter proceed howev iter precondition gener algorithm 35 36 found 14 j baglama et al former algorithm seldom give faster converg illustr section 4 therefor feel algorithm interest storag requir algorithm 36 essenti algorithm 35 notat simplic iti algorithm 36 use doubl shift howev implement algorithm use comput exampl section 4 algorithm 36 adapt precondit gmresm algorithm input toler comput approxim solut ffl solut toler approxim invari subspac ffl subspac dimens largest krylov subspac determin dimens k approxim invari subspac comput maximum number ff 0 precondition gamma1 j comput maximum number fi 0 arnoldi decomposit order determin precondition output comput approxim solut x associ residu vector r j precondition comput algorithm 21 initi vector appli gmresm determin matric vm1 hm defin 21 22 respect comput solut ym comput eigenvalu f matrix hm arnoldi decomposit order accord 29 scale matrix righthand side linear system factor 1j j equat 19 approxim satisfi appli shift m1gamma arnoldi decomposit use ira formula 2428 give arnoldi decomposit mgamma endfor bound 211 satisfi goto use arnoldi decomposit gamma1 av mgammak k input algorithm 21 appli arnoldi process comput arnoldi decomposit appli gmresm determin matric vm1 hm defin 22 respect comput solut ym endfor fi 1 improv approxim solut gmresk updat precondition k well adapt precondition 15 trice v k1 22 avail comput solut k 2 r k min 2 gamma1 3 r jk solut done endfor ff kr j kkr solut appli algorithm 21 initi vector matric vm1 hm defin 21 22 respect comput solut ym 4 r jm endwhileth comment regard line label 2 3 4 algorithm 35 also appli algorithm 36 4 numer experi numer experi present section carri hp 9000735 comput use matlab exampl chose initi approxim solut x b vector b randomli gener uniformli distribut entri open interv 0 1 purpos experi compar algorithm 35 36 restart paramet 0 chosen latter algorithm allow least much comput storag former two algorithm also compar algorithm 35 36 gmre algorithm without restart refer latter scheme full gmre termin iter iter method soon residu vector r j determin ffl solut algorithm 35 36 chose input paramet valu ffl subspac 20 storag requir algorithm 35 36 choic paramet 54 nvector compar scheme restart gmres60 algorithm requir storag 62 nvector v 61 xm see algorithm 31 storag count assum residu vector r algorithm 31 scale factor store first column matrix v 61 exampl 41 let matrix 2 r 200theta200 partit accord 12 22 11 2 r 30theta30 circul matrix first row gamma32 2 entri diagon matrix 22 2 r 170theta170 uniformli distribut random number interv 1 10 matrix 12 zero matrix appropri order thu j baglama et al matrix 30 eigenvalu circl center gamma32 radiu 2 remain eigenvalu uniformli distribut open interv 1 10 figur 41 show denot last precondition comput algorithm 35 shift 210 eigenvalu shown unscal matrix eigenvalu gamma1 also unscal matrix associ precondition unscal precondition map eigenvalu smallest magnitud approxim signr n j n j illustr figur 41 figur 42 show iter converg rapidli precondition remov mani eigenvalu circl fz 2g remark plot determin algorithm 36 look roughli plot eigenvalu precondition shown figur 41 graph algorithm 35 figur 42 continu curv gener evalu kr j k everi valu j residu vector r j defin ie everi step richardson iter everi minim residu error gmre algorithm graph algorithm 36 figur 42 dash curv gener evalu kr j k everi minim residu error gmre algorithm number matrixvector product matrix report tabl 41 howev number actual requir algorithm 35 36 piecewis linear graph gmres60 figur 42 obtain linear interpol node node mark circl column size krylov subspac tabl 41 display paramet use algorithm 31 35 36 column precondition show number precondition gamma1 use suffici accur solut found number bound ff 0 column vector precondition paramet k algorithm 35 36 column label total vector use count number nvector storag graph figur 42 dashdot curv full gmre obtain appli gmresm solut 11 increas valu order improv initi approxim solut x 0 approxim solut xm suffici small residu error kr k determin figur 42 show 10logarithm rel residu error kr k kkr 0 k exampl 42 consid 200 theta 200 block bidiagon matrix gammay gammay gammay eigenvalu given 2j gamma1 figur 43 44 analog figur 41 42 respect tabl 42 analog tabl 41 distribut eigenvalu gamma1 figur 43 indic toler ffl subspac use comput larg determin accur approxim invari subspac nevertheless adapt precondition 17 eigenvalu closest origin remov algorithm 35 36 yield faster converg restart gmres60 algorithm see figur 44 2 exampl 43 let pores3 matrix harwellbo matrix collect matrix 0 nonsymmetr order 3474 nonzero entri purpos shift obtain matrix posit eigenvalu figur 45 46 analog figur 41 42 respect tabl 43 analog tabl 41 see eigenvalu matrix close origin other larg magnitud figur 45 illustr precondition move eigenvalu away origin approxim signr n j n j neg figur 46 show rate converg 2 exampl 44 let diagon matrix order 200 diagon entri figur 47 49 analog figur 41 42 respect tabl 44 analog tabl 41 figur 48 illustr precondition move smallest eigenvalu except one away origin figur 49 show rate converg 2 exampl 45 exampl chose shift accord 210 ie determin approxim subspac associ eigenvalu smallest magnitud present exampl illustr algorithm 35 36 easili modifi determin approxim invari subspac specif use algorithm 36 solv linear system equat exampl 41 chose shift eigenvalu largest real part matric hm gener iter thu sought determin invari subspac associ eigenvalu smallest real part figur 410 analog figur 41 show dot gamma1 eigenvalu circl remov number matrixvector product requir stop criterion satisfi 311 less number matrixvector product report tabl 41 2 5 conclus paper describ new precondit method well suit use restart gmresm algorithm numer comput exampl indic iter gener method converg significantli faster iter determin restart gmre algorithm requir comput storag algorithm 35 36 describ version precondit method eigenvalu j smallest magnitud matrix map approxim easi modifi precondition eigenvalu map acknowledg work paper carri last three author visit comput scienc depart ip eth would like thank walter gander martin gutknecht make visit possibl would like thank marcu grote discuss code extract matric harwellbo matrix collect richard lehoucq provid us refer 16 j baglama et al r principl minim iter solut matrix eigenvalu problem cambridg univers press iter method comput eigenvalu larg symmetr matrix newton basi gmre implement parallel implement gmre al gorithm implicitli restart lanczo method larg symmetr eigenvalu problem deflat augment krylov subspac techniqu parallel implement restart gmre iter algorithm nonsymmetr system linear equat numer stabil gmre parallel gmre version gener spars matric restart gmre precondit deflat iter solut linear system matrix comput gmrescr arnoldilanczo matrix approxim problem parallel precondit spars approxim invers eigenvalu translat base precondition gmresk method analysi implement implicitli restart arnoldi iter restart gmre method augment eigenvector hybrid gmre algorithm nonsymmetr linear system krylov subspac method solv larg unsymmetr system linear equat precondit krylov subspac method cfd applic gmre gener minimum residu algorithm solv nonsymmetr linear system implicit applic polynomi filter kstep arnoldi method introduct numer analysi superlinear converg behaviour gmre tr ctr loghin ruiz touhami adapt precondition nonlinear system equat journal comput appli mathemat v189 n1 p362374 1 may 2006 ronald b morgan restart blockgmr deflat eigenvalu appli numer mathemat v54 n2 p222236 juli 2005 paul j harri ke chen effici precondition iter solut galerkin boundari element equat threedimension exterior helmholtz problem journal comput appli mathemat v156 n2 p303318 15 juli