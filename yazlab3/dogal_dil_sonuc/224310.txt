distribut chemic process optim applic gigabit network evalu impact gigabit network implement distribut chemic process optim applic optim problem formul stochast linear assign problem solv use think machin cm2 simd cray c90 vector comput psc intel iwarp mimd system cmu connect gigabit nectar testb report experi distribut applic across heterogen set system present measur show commun requir applic depend structur applic use detail trace build applic perform model use estim elaps time applic differ comput system network combin result show applic benefit highspe network need high network throughput increas comput system get faster also observ support high burst rate critic although structur applic commun overlap comput relax bandwidth requir b introduct highperform network made attract distribut computeintens applic across comput system connect localarea widearea network obviou benefit applic combin resourc sever system reduc execut time heterogen comput special case distribut comput ad benefit applic compon map onto appropri architectur thu optim effici comput result heterogen comput result superlinear speed ie use n system applic run n time faster individu system eg 22 import question critic network perform success distribut comput mani coarsegrain applic distribut success across rel slow network highspe network need want appli distribut comput wide class applic includ grand challeng nation challeng applic first indic mani applic comput intens also data intens larg data set exchang distribut task second observ comput system get faster network keep paper evalu impact network bandwidth perform chemic process optim applic applic econom import chemic process industri repres larg class optim problem field use twostep evalu strategi first distribut applic across three system connect gigabit nectar testb intel iwarp system mimd cmu think machin cray c90 vector comput psc implement show feasibl distribut comput class problem allow us identifi problem distribut larg applic across heterogen system evalu howev limit singl set system singl network second step evalu use detail trace inform collect execut build perform model applic model captur commun comput requir applic data depend differ task model use estim execut time differ comput system differ network remaind paper organ follow section 2 give overview applic section 3 discuss map nectar testb section 4 describ experiment set comput result present applic perform model section 5 use model studi impact network node perform applic execut time section 6 summar section 7 2 applic overview model optim applic primari tool decis make throughout chemic process industri typic engin exampl process design materi alloc optim control realtim optim process schedul product capac plan applic uncertainti inher decis model process ie model paramet estim real valu although failur account uncertainti key paramet decis problem lead nonoptim solut 2 determinist optim method still predomin chemic engin today 10 includ explicit treatment uncertainti model increas comput requir beyond capabl today comput optim resourc alloc problem express linear assign problem lap state follow given n resourc eg raw materi n demand eg process unit set cost c ij assign resourc demand j find set one toon resourcedemand assign minim total cost z primal lap defin follow lap subject x term denot sourc termin node set correspond resourc demand respect term denot bipartit graph match edg set 1 connect sourc termin node exclus manner despit combinatori larg solut space varieti polynomi time algorithm develop achiev effici exploit special structur linear assign problem see 20 21 14 17 detail serial parallel algorithm lap problem stochast cost c ij defin probabilist ie repres probabl distribut instead singl valu stochast lap problem solv convert determinist problem use certainti equival transform 8 howev transform increas size lap problem exponenti furthermor transform alter structur problem solut procedur special determinist lap longer appli algorithm appropri stochast lap cost independ normal distribut variabl present 5 6 3 distribut stochast lap solut stochast lap problem combin divers task best suit differ type comput system eg mpp fast scalar processor consequ applic good candid heterogen comput section describ map stochast lap onto set heterogen system connect nectar gigabit testb discuss solut method well mpp comput implement result report 5 6 7 31 applic overview map figur 1 show structur map distribut chemic process optim applic real world model ie product cost data simul iwarp sampl normal distribut mean rang 0100000 standard deviat randomli set cost element product data sent c 90 analyz use comput lap cost matrix mean statist model analysi statist reduct c90 send cost matrix cm2 lap solver initi entir cost matrix receiv cm2 comput reduc cost matrix send indic potenti optim assign c90 maximum cardin match comput c90 base initi zeroel indic reduc cost matrix unweight bipartit match cm2 complet weight match portion lap solut 6 complet implement applic would includ bayesian infer step gener probabl manifold product data would also use mean varianc lap solver simplif fundament alter structur map applic product data process network market influenc process disturb raw materi select stochast linear assign problem optim initi match model analysi bayesian infer real world materi process j pq n q 1 n ts raw materi product pq l pyq pq dq figur 1 map stochast linear assign problem nectar testb map applic shown figur 1 driven perform suitabl task system iwarp mimd system well suit independ complex function evalu requir simul integr problem c90 use highperform vector machin well suit statist reduct comput serial initi match procedur cm2 simd machin well suit row column scan matrix arithmet oper characterist weight match portion lap solver inde task could theoret run system none task well suit machin sinc singlemachin version applic measur speedup expect effici processor util result superlinear speedup 32 implement applic develop ad iwarp sampl gener phase exist highli optim lap solver run c90 cm2 illustr import advantag heterogen comput larg applic built exist separatelydevelop applic compon allow fast applic develop without port effort expect opportun one main motiv heterogen comput highspe network implement program control carri use pvm 32 9 cm2 act master node read key paramet cm2 lap start data gener job iwarp gen analysi job c90 ana simul plant data gener iwarp sent use stream packag 24 11 hippi network read c90 use socket interfac commun c90 cm2 dhsc librari 19 dhsc support distribut comput across cm2 c90 use hippi network interconnect stream packag dhsc use raw hippi actual commun fact varieti tool use ad consider complex distribut applic moreov sinc tool support messag pass hide detail system individu expertis system help program develop program tool hide system detail parallel compil 26 clearli need make distribut comput access user figur show differ comput task applic interact figur scale horizont bar repres comput task execut differ system arrow repres commun applic delin two main phase data gener analysi ii lap solut first phase consist data gener iwarp data analysi c90 lap initi cm2 sinc time requir lap initi cm2 insignific phase end last packet cost matrix data reach cm2 c90 gener analysi pipelin minim execut time commun view separ stage pipelin pipelin comput stage execut concurr execut time determin slowest stage pipelin lap solut phase applic mainli perform cm2 remot procedur call rpc c90 perform unweight initi match phase oper includ commun perform serial execut time sum execut time compon data gener statist analysi lap solver initi convert reduc cost matrix unweight bipartit match weight bipartit match time data gener analysi lap solut figur applic flowchart stochast optim problem 33 commun requir applic commun requir summar tabl 1 tabl give sourc destin data format data size four data stream applic compon item tabl 1 refer applic execut imag resid comput node program gen ana lap initi compris data gener analysi phase applic program lap fem denot lap solver initi match lap solut phase applic data sourc data type destin size plant data gen iwarp float ana c90 n 2 n ts stochast model ana c90 int lap cm2 n 2 cost data lap cm2 int fem c90 n 2 initi match fem c90 int lap cm2 n tabl 1 summari applic commun requir commun requir applic depend size n lap number sampl n ts use simul plant data number grid point n use map probabl manifold number stochast paramet n q stochast lap applic execut n n ts sinc probabl manifold map ie bayesian infer problem omit n q sinc cost assum uncertain use mean varianc lap solut instead mean would doubl commun requir stochast model data stream implement reduct factor invers proport n discuss detail section 52 seen tabl data reduct analysi step ana c 90 first phase applic significantli larger data requir second data format chang sever time comput result present layer overhead gener sampl repres bit ieee float point number iwarp transmit c90 convert 64 bit cray float point format statist analysi c90 sampl mean convert bit integ transmit cm2 data exchang cm2 c90 initi match procedur use integ represent howev result differ data represent c90 cm2 transfer still requir expens transform 16 27 18 structur applic figur 2 four data stream differ characterist first stream sent continu stream 64 kbyte packet sinc iwarp send data gener second stream sent sequenc burst number burst degre pipelin ie number block use comput data transfer c90 exampl degre pipelin 16 problem size 4k stream would consist 16 burst 4 mbyte final last two data stream sent singl burst 4 experiment result distribut optim applic describ execut nectar gigabit testb may 9 1994 section describ execut environ present analyz measur 41 nectar testb nectar testb one five nation gigabit testb 23 fund arpa nsf cnri nectar testb joint effort nectar group cmu bellcor pittsburgh supercomput center psc bell atlant goal testb build gigabit metropolitan area network man demonstr valu applic testb consist twentyf dec alpha workstat iwarp parallel array 3 paragon 12 cmu campu cray c90 cray t3d 1 cm2 alpha cluster pittsburgh supercomput center psc alpha workstat iwarp use network interfac provid architectur support copi avoid optim throughput 24 25 15 paragon alpha frame buffer alpha file server cmu campu pittsburgh supercomput center 26 km atmsonet file server alpha alpha alpha alpha file server parallel data lab vision lab offic figur 3 nectar testb highperform distribut comput system network figur connect system consist two hippi base lan link 24 gb atmsonet link 13 4 repres metropolitan area network man execut run report paper use hippi link run parallel atmsonet link peak throughput link 100 mbsec howev latenc set hippi connect across 26 km link packet maximum achiev throughput 73 mbsec packet size 64 kbyte 42 experiment set solv lap problem instanc size number sampl n ts fix 64 anoth paramet experi degre pipelin gener analysi phase block size use c90 analysi model data similarli size run random number seed use iwarp gener simul plant data ident lead gener ident pseudorandom cost matric done allow repeat ident run help isol element system perform experi cm2 run dedic mode ie 32k processor attach user front end result repeat run lap compon cm2 c90 applic compon run singl node interact mode variat elaps time occur repeat instanc problem iwarp array run dedic mode variat iwarp elaps time occur repeat instanc problem due nonconst load front end 43 measur analysi experiment data problem size 4k plot figur 4 6 problem size 1k 2k give similar result figur 4 show total execut time applic broken gener gen lap initi match c90 fem reduct cost matrix plu lap weight match solut lap iwarp time domin pipelin execut gener analysi phase time gen repres total time phase time c90 cm2 shown time shown function degre pipelin 500 0 750 012500 elaps time sec pipelin c90 npassesnnrow fem gen figur 4 elaps time versu degre pipelin gener analysi phase size 4k 4k problem gener compon account 80 total execut time ie iwarp bottleneck observ first phase take slightli longer highest lowest degre pipelin 8 128 effect small surpris sinc block size rang 500 mbyte 32 mbyte iwarpc90 commun factor 64 smaller c90cm2 commun larg enough allow effici commun number block larg enough pipelin fill drain time signific figur 5 show cpu time model analysi data transfer convers comput c90 4k case data read ana1readdata iwarp convert cray float point format ana1cf132c statist comput apost perform reduc data set cost mean sent ana1dhscwrit cm2 shown figur read write cpu time rel small vector format convers c90 quit fast 10 nsec per float point number nearli costli statist comput indic improv convers routin elimin agre singl represent highli desir sinc cpu time elaps time record program ana c90 data pipelin effect second pipelin c90 npassesnnrow ana1dhscwrit ana1readdata ana1cf132c apost figur 5 c90 cpu time versu degre pipelin analysi step 6 idl 22 0 22 2 22 4 22 6 22 initialmatch sec solut sec figur 6 initi match cm2 idl versu lap solut time size 4k x axi figur 6 show total execut time second phase applic lap solver run cm2 lap c90 7 lap initi match elaps time c90 left black full curv cm2 idl right red dash curv given versu total lap solut time differ run solver sinc cm2 ran fulli dedic mode cm2 time ident run problem size chang lap solut time result load chang c90 graph confirm close correspond increas initi match time wait idl time cm2 increas overal lap solut time implic distribut comput system load imbal one machin affect util comput resourc system run distribut applic effici requir care alloc system resourc reason predict respons time system use applic 5 applic perform model project behavior applic result chang distribut comput system ie number comput node network bandwidth develop model applic compon next section use model examin sensit applic execut time network comput system perform 51 comput model comput model repres execut time task applic function problem size case iwarp cm2 size system paramet summar tabl 2 model deriv use data larg seri parameter run 5 6 7 model present section spars approach discuss tradeoff spars dens approach section 64 function paramet valu problem size n 1k4k number data sampl n tsrang cost matrix valu r 10 5 number iwarp node p iwarp 64 measur number cm2 node p cm2 8k32k measur bandwidth iwarp c90 bw 1 hippi bandwidth c90 cm2 bw 2 hippi tabl model paramet use experi data gener model gen run iwarp time test indic 64 node iwarp array capabl gener per second rate sampl gener correspond directli number iwarp node doubl number node doubl rate result follow elapsedtim perform model gener sampl iwarp ts 1 data analysi model ana run c90 use singl node c90 elaps time close correl data size n 2 model analysi c90 obtain regress experiment data sampl mean comput lap solver model lap run cm2 use data set parametr test statist model fit data give follow perform model lap solver constant 3 c natur scale equat 3 number cost element number cm2 node also time solv weight match problem weakli correl degre precis character rang r lap initi match model fem run c90 use data set parametr test statist model fit data routin fem run c90 give r constant c equat 4 first second order term ie n n 2 respect character lap size ratio nr repres natur indic rel degre precis 6 52 traffic model traffic model shown tabl 3 simpler comput model linear depend data time size data stream tabl 1 transfer time inverselyproport sustain network bandwidth note sustain network bandwidth practic limit send receiv host abil put data remov data network transfer model equat gen output iwarp c90 dt ts ana output c90 cm2 dt lap output cm2 c90 dt 4an 2 fem output c90 cm2 dt fem 4n tabl 3 applic traffic model equat 7 requir explan program lap run cm2 comput reduc cost matrix part initi procedur 5 7 zero element matrix potenti optim assign lap program fem run c90 find optim initi match given zero element indic reduc cost matrix simplest way transmit element cm 2 transmit entir reduc cost matrix c90 select zero element call dens approach howev use effici way call spars approach cm2 first locat indic zero element send vector indic c90 initi match advantag spars approach lower data transfer requir ie number indic sent c90 gener less n 2 howev tradeoff cm 2 less effici c90 construct spars incid matrix paramet equat 7 reduct factor indic densiti incid matrix set 1 give traffic model dens approach scalar applic depend lie gener 1 n 1 depend rel precis problem defin ratio n r use experi invers proport problem size 6 perform analysi equat 18 repres perform model distribut applic section use model studi perform two phase comput individu combin degre freedom model lap problem size number node use iwarp cm2 machin sustain network bandwidth also use model compar dens spars transfer option cm2 c90 look differ structur two applic phase influenc depend execut time network bandwidth 61 data gener analysi perform model result pipelin gener analysi phase throughput system determin slowest compon note iwarp c90 overlap commun comput commun phase independ stage pipelin elaps time gener analysi phase maximum genx dt ana realist paramet iwarp comput iwarp c90 commun limit perform phase figur 7 show estim gener analysi time function two limit paramet iwarp node bandwidth time phase figur 7 estim execut time sec gener analysi phase size 4k function network bandwidth mbsec iwarp system size number node experi use 64 node iwarp system model predict execut time 766 second close match measur time gen figur 4 note point flat part graph respect network bandwidth indic gener phase limit comput iwarp network bandwidth scale iwarp system 256 node equival 66 node paragon system applic 512 node 66 node paragon coprocessor use comput execut time drop almost linearli demonstr sustain applic throughput 40 mbsec iwarp c90 11 network becom bottleneck iwarp grow 460 node note paragon system much larger 66 node built 40100 mbsec network bandwidth mean excess data analysi c90 becom bottleneck system size p iwarp 1540 node iwarp c90 bandwidth 62 lap solut perform model comput commun occur sequenti lap solut phase elaps time sum lapx dt fem figur 8 show execut time lap solver function network bandwidth number cm2 node shape graph differ graph summar gener analysi phase specif flat region impact network bandwidth absolut execut time independ number cm2 node cm2 node bandwidth time phase figur 8 estim execut time sec lap solver phase size 4k function network bandwidth mbsec size cm2 system number node spars incid matrix transfer cm 2 c90 experi use cm2 32k node bandwidth c90 cm2 12 mbsec model predict execut time 200 second close measur time lap plu fem figur 4 note c90cm2 bandwidth would need present layer format convers cm2 18 higher throughput execut time would reduc 10 63 applic perform model combin equat 18 give overal applic perform model account iwarp data gener transfer overlap discuss figur 9 show sensit network bandwidth number iwarp node given 64k cm2 node bw result compar figur 7 sinc data gener analysi phase applic domin execut time strongest sensit network bandwidth limit data flow iwarp c90 adequ number iwarp node avoid gener comput bottleneck rel iwarp node gener comput becom restrict network shown graph observ experi iwarp node bandwidth time figur 9 estim execut time sec combin lap applic size 4k function iwarpc90cm2 network bandwidth mbsec iwarp system size number node spars approach figur 10a show overal applic perform sensit network bandwidth number cm2 node use 256 iwarp node assum bw data gener comput iwarp limit high bandwidth improv occur increas bandwidth data gener rate gain increas number node cm2 base line time remain 200 second due data gener bottleneck figur 10b show compar sensit use 1024 iwarp node increas number iwarp node data gener bottleneck remov overal perform continu improv network bandwidth increas cm2 node bandwidth time 256 iwarp node cm2 node bandwidth time b 1024 iwarp node figur estim execut time sec lap applic size 4k function iwarpc90cm2 network bandwidth mbsec size cm2 number node two iwarp system size 64 tradeoff dens spars reduc matrix transfer two altern exist transfer initi reduc cost matrix zero element indic cm2 c90 initi match comput see section 52 spars approach cm2 locat zeroel indic initi reduc cost matrix pack incid vector send vector c90 initi match subproblem dens approach cm2 send entir initi reduc cost matrix c90 form spars incid matrix advantag spars approach lower data transfer requir sinc densiti term equat 7 bound 1 howev tradeoff cm2 less effici c90 construct spars incid matrix cm2 node bandwidth time phase figur estim execut time sec lap solver phase size 4k function network bandwidth mbsec size cm2 system number node dens incid matrix transfer cm 2 c90 figur 11 time lap solut phase plot function network bandwidth number cm2 node dens matrix transfer method problem size 4k sensit network bandwidth minim spars method figur 8 expect dens transfer method show higher sensit network bandwidth figur 11 sinc time pack incid matric cm2 rel small compar overal lap solut spars method superior perform dens method almost casesth dens method sometim faster small data set howev c90 time dens method could acceler use singl c90 node multipl c90 node use expect dens method would faster spars method network bandwidth suffici high 65 impact network throughput execut time impact network speed overal applic perform view term percent time applic commun bound vs comput bound interconnect comput speed number node network perform requir lap applic shown figur 12 13 applic phase 1 figur 12 commun comput oper overlap henc long network perform adequ applic run complet comput bound increas network bandwidth speed applic decreas network bandwidth immedi slow applic complet stop limit phase 2 figur 13 commun comput oper serial case clearli key accept perform keep commun time significantli comput time increas decreas network perform direct effect elaps time phase applic commun time bind practic insignific due smaller data set transfer statist reduct cost data percent elaps time bound commun phase 1512128iwarp node figur estim percent elaps time applic bound commun versu effect network bandwidth variou iwarp size lap size 4k0 01 percent elaps time bound commun phase 2 cm2 node figur phase 2 estim percent elaps time applic bound commun versu effect network bandwidth variou cm2 size lap size 4k spars transfer 7 conclus paper describ distribut chemic process optim applic across heterogen system consist intel iwarp cray c90 think machin cm2 comput connect nectar gigabit testb implement demonstr sever benefit heterogen comput effici execut abil build applic connect exist separatelydevelop applic compon across network without port code note benefit eg effici system util may realiz differ system simultan dedic applic suffici network bandwidth avail creat organiz problem supercomput center implement applic also demonstr difficulti distribut applic across heterogen comput sinc expertis number differ comput system requir better program tool requir time hide detail system integr system better measur perform model applic show sensit execut time network bandwidth depend strongli structur distribut applic comput commun serial rpcbase solut phase applic network delay includ increas latenc due physic distanc increas execut time abl burst high rate critic averag bandwidth requir applic indic commun requir contrast commun comput overlap pipelin gener analysi phase applic network bandwidth requir relax speed light latenc hidden specif averag bandwidth requir applic repres bandwidth sustain network acknowledg would like thank michael hemi jamshid mahdavi todd mummert help distribut optim applic gregori j mcrae input conceptu applic also grate acknowledg use comput resourc pittsburgh supercomput center especi psc applic support group also grate use comput resourc sandia nation lab final prepar manuscript research support nation scienc foundat defens advanc research project agenc cooper agreement ncr8919038 corpor nation research initi advanc research project agenc dod monitor space naval warfar system command spawar contract n0003987c0251 r cray t3d system architectur overview model model valu stochast program integr solut highspe parallel comput gigabitsec wide area comput network potenti applic technolog challeng schedul presenc uncertainti probabilist solut assign problem schedul presenc uncertainti linear assign problem solut largescal model optim problem use heterogen supercomput system plan uncertainti use parallel comput pvm system supercomput level concurr comput heterogen network workstat recent develop evalu optim flexibl chemic process gigabit io distributedmemori system architectur applic paragon xp product overview 25 gb sonet datalink sts12c input hippi interfac gigabit comput network shortest augment path algorithm dens spars linear assign problem softwar support outboard buffer checksum experi gigabit neurosci applic cm2 combinatori optim network matroid deploy hippibas distribut supercomput environ pittsburgh supercomput center deploy hippibas distribut supercomput environ pittsburgh supercomput center linear assign problem implement test primaldu algorithm assign problem run climat model heterogen gigabit network testb architectur evalu highspe network subsystem distributedmemori system host interfac architectur highspe network program task data parallel multicomput network supercomput experi cray2 cm2 hippi connect tr shortest augment path algorithm dens spars linear assign problem warp integr solut highspe parallel comput gigabit network testb exploit task data parallel multicomput experi gigabit neurosci applic cm2 architectur evalu highspe network subsystem distributedmemori system softwar support outboard buffer checksum gigabit io distributedmemori machin host interfac architectur highspe network ctr michael hemi peter steenkist gigabit io distributedmemori machin architectur applic proceed 1995 acmiee confer supercomput cdrom p58e decemb 0408 1995 san diego california unit state peter steenkist highspe network interfac distributedmemori system architectur applic acm transact comput system toc v15 n1 p75109 feb 1997 peter steenkist networkbas multicomput practic supercomput architectur ieee transact parallel distribut system v7 n8 p861875 august 1996