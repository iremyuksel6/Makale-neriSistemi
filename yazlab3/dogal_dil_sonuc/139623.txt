converg tdmyampersandlambda gener myampersandlambda method tempor differ td one way make consist predict futur paper use analysi watkin 1989 extend converg theorem due sutton 1988 case use inform adjac time step involv inform arbitrari onesit also consid version td behav face linearli depend represent statesdemonstr still converg differ answer least mean squar algorithm final adapt watkin theorem cal qlearn close relat predict action learn method converg probabl one demonstr strong form converg slightli modifi version td b introduct mani system oper tempor extend circumst whole sequenc state rather individu one import system may frequent predict futur outcom base potenti stochast relationship current state furthermor often import abl learn predict base experi consid simpl version problem task predict expect ultim termin valu start state absorb markov process random process gener termin valu absorb state one way make predict learn transit matrix chain expect valu absorb state solv simultan equat one fell swoop simpler altern learn predict directli without first learn transit method tempor differ td first defin sutton 16 17 fall simpler categori given parametr way predict expect valu state alter paramet reduc inconsist estim one state estim next state state learn happen increment system observ state termin valu sutton 17 prove result converg particular case td method mani control problem formalis term control absorb markov pro cess polici ie map state action defin absorb markov chain engin method dynam program dp 4 use predict expect termin valu way judg henc improv polici td method also extend accomplish discuss extens watkin 19 barto sutton watkin 3 td actual close relat dp way significantli illumin work paper use watkin insight extend sutton theorem special case td consid inconsist adjac state gener case arbitrari state import weight exponenti less accord tempor distanc also consid td converg represent adopt state linearli depend prove one version td predict converg probabl one cast form qlearn earliest work tempor differ method due samuel 14 15 checker draught play program tri learn consist function evalu board posit use discrep predict valu state base limit depth gamestre search subsequ predict valu number move elaps mani propos along similar line made sutton acknowledg influenc klopf 9 10 17 discuss holland bucket brigad method classifi system 8 procedur witten 22 hampson 6 7 present empir result quit similar navig task one describ barto sutton watkin 3 barto sutton anderson 2 describ earli td system learn balanc upend pole problem introduc relat paper michi chamber 11 watkin 19 also gave refer next section defin td show use watkin analysi relationship dp extend sutton theorem make comment unhelp state represent section 3 look qlearn use version watkin converg theorem demonstr particular case strongest guarante known behaviour td0 sutton 17 develop rational behind td method predict prove td0 special case time horizon one step converg mean observ absorb markov chain although theorem appli gener illustr case point anexampl simpl random walkshown figur chain alway start state move left right equal probabl state reach left absorb barrier right absorb barrier g problem face td estim probabl absorb right hand barrier rather left hand one given state current locat insert figur 1 raw inform avail system collect sequenc state termin locat gener random walk initi knowledg transit probabl sutton describ supervis least mean squar lm 21 techniqu work make estim probabl place visit sequenc closer 1 sequenc end right hand barrier closer 0 end left hand one show techniqu exactli td1 one special case td contrast td particularli td0 tri make estim probabl one state closer estim next without wait see sequenc might termin discount paramet td determin exponenti weight futur state base tempor distanc smoothli interpol next state relev lm case state equal weight describ introduct obeis tempor order sequenc mark td follow subsect describ sutton result td0 separ algorithm vector represent state show watkin analysi provid wherewith extend tdand final reincorpor origin represent 21 converg theorem follow sutton 17 consid case absorb markov chain defin set valu termin state nontermin state vector repres nontermin state expect termin valu state j probabl start state p payoff structur chain shown figur degener sens valu termin state g determinist 0 1 respect make expect valu state probabl absorb g estim system fed complet sequenc x observ vector togeth scalar termin valu z gener everi nontermin state predict expect valu ezji start state transit matrix markov chain complet known predict could comput follow sutton let ab denot ab th entri matrix u denot th compon vector u q denot squar matrix compon q ab denot vector whose compon h 2 n equat 1 2 sutton show exist limit equat follow fact q transit matrix nontermin state absorb markov chain probabl one ultim termin learn phase linear td gener success vector w chang complet observ sequenc predict subsequ superscript use indic tdbase estim termin valu start state stage n learn one sequenc intermedi predict termin valu abus notat somewhat defin also z observ termin valu note 17 sutton use p n accord ff learn rate sutton show td1 normal lm estim 21 also prove follow theorem theorem absorb markov chain distribut start probabl inaccess state outcom distribut finit expect valu z j linearli independ set observ vector fx ji 2 ng exist ffl 0 posit ff ffl initi weight vector predict linear td weight updat sequenc converg expect valu ideal predict 2 w n denot weight vector n sequenc experienc lim true case 0 paper prove theorem gener 22 localist represent equat 3 conflat two issu underli td algorithm represent predict function v n even though remain tangl ultim proof converg benefici separ sinc make oper algorithm clearer consid repres v n lookup tabl one entri state equival choos set vector x one compon 1 other 0 state two state represent trivial satisfi condit sutton theorem also make wn easi interpret compon predict one state use also prevent generalis represent term rwn v sum reduc count number time chain visit state exponenti weight recenc case full linear case term depend n state chain visit defin characterist function state j predict function v n entri lookup tabl state stage n learn equat 3 reduc element piec valu state updat separ illustr process consid punctat represent state b c e f figur 3 observ sequenc c e f e f g sum step compon sum clearli time 3 state g absorb repres 23 contract map watkin 19 show fruit way look td estim dynam program associ contract map method start current predict function vn 8i 2 n show defin whole collect statist better estim vn1 8i 2 n base observ sequenc use td linear combin estim except explicitli note section follow watkin exactli equat develop exact analogu linear represent seen subsect 25 imagin chain start state 0 run forward state ultim absorb defin rstep estim 0 either estim vn r state r chain absorb r step r 2 n observ termin valu z sequenc chain absorb time formal defin random variabl vn 1 z otherwis vn z otherwis vn r z otherwis 5 first state access markov chain one particular sequenc start second z observ termin valu chain get absorb time step r reach random variabl sinc depend particular sequenc state observ natur also depend valu vn point chain absorb complet step 0 v r r base termin valu provid world rather one deriv bootstrap vn v r therefor averag accur vn use increment improv shown look differ e ezji 0 ideal predict tr2t vn r 6 wherea easili shown tr2t therefor watkin actual treat slightli differ case target valu predictor base discount futur valu whose contribut diminish exponenti time happen case easier see reduct error brought analogu equat discount factor sinc p q matrix markov chain watkin could guarante provid weak guarante error v r n less vn nondiscount case differ initi state nonzero probabl chain absorb finish r step case valu v r z unbias provid error reduct even chain absorb valu inaccur compon vn although error reduct due fl guarante inequ state possibl absorb within r step ensur sinc maximum could achiev patholog state fromwhich imposs absorb r step howev estim state within r step absorpt averag improv averag filter back state watkin demonstr td base weight averag v consid also valid estim termin valu start 0 point choos valu trade bia caus error vn varianc real termin valu z higher signific v r higher valu r effect unbias termin valu lead higher varianc lower bia convers lower less signific contribut higher valu r less effect unbias termin valu lead smaller varianc greater bia remain shown td inde base combin estim expand sum equat 10 vn 0 vn vn 1 vn 2 defin vn whole point defin v use make v accur obviou increment updat rule achiev vn1 0 vn vn 0 equat 11 appar chang vn 0 involv sum futur valu vn t1 vn weight power follow watkin differ calcul activ trace base characterist function defin earlier way count often recent chain enter particular state use index member observ sequenc onlin version td rule problem sutton treat chang vn appli offlin complet sequenc chain therefor state chain pass one sequenc absorb termin valu vn vn1 new estim experienc sequenc vn1 0 vn ff vn t1 vn vn1 1 vn 1 ff vn t1 vn vn1 vn vn sum term note express exactli td weight chang formula equat 4 thu actual td algorithm base exponenti weight sum defin equat 10 outcom v r random variabl themean contract properti variabl therefor determin mean contract properti overal td estim 24 linear represent previou subsect consid td algorithm isol represent sutton use although number differ represent might employ simplest linear one adopt identifi vector x state repres vn wn x wn weight vector stage n learn basic algorithm concern v predictor random variabl rather valu use chang initi predictor vn new represent equat 12 longer make sens sinc state separ appropri manner rather inform error use updat weight depend appropri formula deriv deltarul vn 0 rwn vn 0 weight error due state 0 vector represent 0 equival equat 13 sutton main td equat 3 sophist represent kdtree see 13 review cmac may lead faster learn better generalis requir separ converg proof 5 compar qualiti certain differ represent barto sutton watkin grid task 3 25 proof theorem strategi prove theorem follow sutton 17 consid expect valu new predict weight vector given observ complet sequenc follow watkin split chang compon due equival v r random variabl sum mean error reduct iter assur equival equat 9 linear represent defin v r random variabl equat 5 z otherwis x identifi state observ sequenc w r n current weight vector defin estim termin valu z actual valu observ whole sequenc w r n updat visit vn rwn vn visit exact parallel sutton proof procedur turn appli w r defin j ij number time sstep transit occur intermedi state x kt 2 n sum equat 14 regroup term sourc destin state transit ff z z j indic termin valu gener distribut due state j extra term gener possibl visit x 2 n chain absorb take r step take expect valu sequenc 2 n ik q kj ik q kj expect number time markov chain state one sequenc absorb markov chain known depend probabl start variou state substitut equat 15 take expect side note depend ew r n n linear use w denot expect valu close relat equat 6 emerg linear represent z defin x matrix whose column x x ab x diagon ab ffi ab kroneck delta rememb h convert matrix form sinc x cover possibl option rgammastep move state defin correct predict e also equat 2 e sum converg sinc chain absorb anoth way write equat 7 multipli equat 17 left x subtract e side equat note equat 18 give updat rule equival equat e e e watkin construct td develop equat 10 previou section reveal start w r therefor sinc e io h e e w expect weight td procedur sum converg sinc truth theorem shown demonstr 9ffl 0 e 1 estim tend correct almost sutton proof 17 appli mutati mutandi case 6 0 alway provid crucial condit hold x full rank complet entir proof given appendix overal impli expect valu estim converg desir valu sequenc observ condit state theorem 26 nonindepend x move watkin representationfre proof sutton treatment linear case one assumpt x vector repres state indepen dent matrix x full rank proof break still posit howev x xd longer full set eigenvalu posit real part sinc null subspac empti nonzero member eigenvector eigenvalu 0 say happen expect valu weight turn easier understand choos basi basi proof appendix appli exactli b exist lim also h definit write e e xd e help understand result consid equival lm rule td1 xd e sinc symmetr e e e e equat 21 weight w squar error state expect number visit one sequenc therefor quadrat form e e load squar error predict state desir valu load factor expect frequenc markov chain hit state condit equat 24 impli expect valu weight tend minimis error happen gener 6 1 intuit tradeoff bia varianc return case x full rank sutton show harmless use inaccur estim next state x t1 w criticis estim current state x w x full rank success estim becom bias account might deem share represent amount extra bia relat amount share frequenc transit happen one state next formalis lead second issu interact two statist process calcul mean weight calcul expect number transit compar equat 20 21 one might expect lim e howev key step prove equat 24 transit equat 22 23 reli symmetri sinc q gener symmetr happen defin w e e e actual happen g although behaviour describ equat 25 satisfactori describ equat 26 reveal consid happen one attempt arrang hold achiev complet deriv ie learn rule whose effect e e q term effect arrang backward well forward learn occur would state adjust estim make like state t1 also state would adjust estim make like state werbo 20 sutton person commun discuss point context gradient descent td rather converg nonindepend x werbo present exampl base learn techniqu similar td0 complet deriv manner make rule converg away true solut fault procedur introduc unhelp correl learn rule random move one state next mention point converg term function g equat 26 w 0 weight fix sutton present exampl help explain result first sight augment td seem quit reason could quit easili happen random chanc train sequenc predict one state accur predict next point therefor train second like first would help howev sutton point time choic alway move forward backward imagin case shown figur number arrow repres transit probabl number termin node repres termin absorb valu insert figur 2 valu state reason 12 50 probabl end either z valu state b though 1 chain certain end train forward give train backward make valu b tend 34 werbo term correl weight possibl transit count augment term incident result affect td1 train valu termin valu sequenc bear relat transit number time state visit come back case x full rank td 6 1 still converg away best valu degre determin matrix 3 converg probabl one sutton proof proof previou section accomplish nadir stochast converg viz converg mean rather zenith viz converg probabl one watkin 19 prove converg probabl one form predict action learn call qlearn section show result appli almost directli discount predict version td0 albeit without linear represent provid first strong proof tempor differ method like dynam program dp qlearn combin predict control consid control discount nonabsorb markovprocess ie one state finit set possibl action 2 take one action lead immedi reward random variabl r whose distribut depend stochast transit accord markov matrix p ij j 2 n agent polici 2 determin action would perform state defin valu v satisfi fl discount factor defin q valu state action polici valu take action follow polici thereaft theori dp 4 impli polici least good take action state bg follow state fact lie util q valu discount problem turn least one optim polici defin q qlearn method determin q henc optim polici base explor effect action state consid sequenc observ n process state n probe action take state j n give reward z n defin recurs qn otherwis 27 start valu q 0 un j n bg ff n set learn rate obey standard stochast converg criteriax k th time watkin 19 prove addit reward bound probabl one lim consid degener case control markov process one action possibl everi state case q v similarli defin u valu exactli equal q equat 27 exactli onlin form td0 case nonabsorb chain reward ie termin valu discuss context absorb markov chain arriv everi state rather particular set absorb state therefor condit watkin theorem onlin version td0 converg correct predict probabl one although clearli td procedur variou differ one describ previou section learn onlin v q valu chang everi observ also learn need proceed along observ sequenc requir j uncoupl disembodi move use 4 condit equat 28 consequ everi state must visit infinit often also note sutton proof sinc confin show converg mean work fix learn rate ff wherea watkin common stochast converg proof requir ff n tend 0 also state qlearn theorem appli discount nonabsorb markov chain rather absorb one previou section 4 one watkin main motiv allow system learn effect action believ suboptim import r ole watkin proof bound effect earli qn valu fairli easi modifi proof case absorb markov chain ever increas probabl absorpt achiev effect also condit sutton theorem impli everi nonabsorb state visit infinit often suffic one set ff satisfi condit 28 appli sequenti visit state normal run chain conclus paper use watkin analysi relationship tempor differ td estim dynam program extend sutton theorem td0 predict converg mean case theorem td gener also demonstr vector repres state linearli independ td converg differ solut least mean squar algorithm appli special case watkin theorem qlearn method increment dynam program converg probabl one show td0 use localist state represent also converg probabl one leav open question whether td punctat distribut represent also converg manner appendix exist appropri ff defin necessari show ffl case formula remain correct x full rank sutton prove page 2628 17 show success di gamma q posit full set eigenvalu whose real part posit final ff thu chosen eigenvalu gamma ffx xdi gamma q less 1 modulu proof requir littl alter case 6 0 path follow exactli equival di gamma q posit definit accord lemma varga 18 observ sutton shown strictli diagon domin posit diagon entri part proof differ sutton even structur rather similar sinc q matrix absorb markov chain q r diagon element 1 therefor r posit diagon element also 6 j sinc element q henc also q r posit case r strictli diagon domin p strict inequ equat 29 follow equat 16 equat 30 hold sinc equat 31 hold sinc p 1 chain absorb q also exist least one 0 inequ strict strictli diagon domin r 1 strictli diagon domin therefor posit definit next stage show x xd full set eigenvalu whose real part posit x x non singular ensur set full let u eigenvalueeigenvector pair indic conjug transpos impli xv xv equival b sinc right side posit definit xv xv strictli posit real part must strictli posit furthermor u must also eigenvector sinc therefor eigenvalu gamma ffx xd posit ae take eigenvalu eigenvalu 1 gamma ff iter matrix guarante modulu less one anoth theorem varga 18 lim 0 r new approach manipul control cerebellar model articul control cmac neuronlik element solv difficult learn problem learn sequenti decis make appli dynam program reinforc connection learn statist way neural model adapt behavior connectionist problem solv comput aspect biolog learn escap brittl possibl generalpurpos learn algorithm appli parallel rulebas system brain function adapt system heterostat theori hedonist neuron theori memori box experi adapt control effici memorybas learn robot control effici algorithm neural network behaviour studi machin learn use game checker studi machin learn use game checker ii recent progress tempor credit assign reinforc learn learn predict method tempor differ matrix iter analysi learn delay reward consist hdp appli simpl reinforc learn problem adapt signal process adapt optim control discretetim markov environ tr ctr claudenicola fiechter effici reinforc learn proceed seventh annual confer comput learn theori p8897 juli 1215 1994 new brunswick new jersey unit state fernando j pineda meanfield theori batch td lgr neural comput v9 n7 p14031419 oct 1 1997 vladislav b tadi asymptot analysi temporaldiffer learn algorithm constant stepsiz machin learn v63 n2 p107133 may 2006 satind singh peter dayan analyt mean squar error curv tempor differencelearn machin learn v32 n1 p540 juli 1998 vladislav tadi converg analysi temporaldiffer learn algorithm linear function approxim proceed twelfth annual confer comput learn theori p193202 juli 0709 1999 santa cruz california unit state satind singh tommi jaakkola michael l littman csaba szepesvri converg result singlestep onpolicyreinforcementlearn algorithm machin learn v38 n3 p287308 march 2000 vladislav tadi converg temporaldiffer learn linear function approxim machin learn v42 n3 p241267 march 2001 peter auer philip long structur result onlin learn model without queri machin learn v36 n3 p147181 sept 1999 kazunori iwata kazushi ikeda hideaki sakai asymptot equipartit properti reinforc learn relat return maxim neural network v19 n1 p6275 januari 2006 john w sheppard colearn differenti game machin learn v33 n23 p201233 novdec 1998 david choi benjamin roy gener kalman filter fix point approxim effici temporaldiffer learn discret event dynam system v16 n2 p207239 april 2006 craig boutili plan learn coordin multiag decis process proceed 6th confer theoret aspect ration knowledg march 1720 1996 netherland florentin wrgtter bernd porr tempor sequenc learn predict control review differ model relat biolog mechan neural comput v17 n2 p245319 februari 2005