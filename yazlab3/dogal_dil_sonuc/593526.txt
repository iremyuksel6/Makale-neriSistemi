adapt sampl method scale knowledg discoveri algorithm scalabl key requir kdd data mine algorithm one biggest research challeng develop method allow use larg amount data one possibl approach deal huge amount data take random sampl data mine sinc mani data mine applic approxim answer accept howev argu sever research random sampl difficult use due difficulti determin appropri sampl size paper take sequenti sampl approach solv difficulti propos adapt sampl method solv gener problem cover mani actual problem aris applic discoveri scienc algorithm follow method obtain exampl sequenti onlin fashion determin obtain exampl whether alreadi seen larg enough number exampl thu sampl size fix priorisemi instead iadapt depend situat due adapt worst case situat fortun happen mani practic applic solv problem number exampl much smaller requir worst case prove correct method estim effici theoret illustr use consid one concret task requir sampl provid algorithm base method show effici experiment b introduct scalabl key requir knowledg discoveri data mine algorithm previous observ mani well known machin learn algorithm scale well therefor one biggest research challeng develop new method allow use machin learn techniqu larg amount data face problem huge input data set typic two possibl way address one way could redesign known algorithm almost maintain perform run ecient much larger input data set second possibl approach random sampl data mine applic approxim answer accept thu could take random sampl instanc space data mine howev argu research see instanc 17 approach less recommend due diculti determin appropri sampl size need paper advoc second approach reduc dimension data random sampl propos gener problem cover mani data mine problem gener sampl algorithm solv typic task knowledg discoveri data mine nd rule law explain huge set exampl well often case size possibl candid rule still manag task simpli select rule among candid certain util dataset problem discuss paper call gener rule select specic given input data set x exampl set h rule util function u measur use rule x problem nd nearli best rule h precis h satisfi uh 1 uh h best rule given accuraci paramet though simpl problem cover sever crucial topic knowledg discoveri data mine shown section 4 would like solv gener rule select problem random sampl statist point view problem solv take rst random sampl domain x select h 2 h largest uh choos enough number exampl x randomli guarante select h nearli best within certain condenc level refer simpl method batch sampl approach one import issu random sampl choos proper sampl size ie number exampl sampl method must take account problem paramet accuraci paramet condenc paramet determin appropri sampl size need solv desir problem non theoret sound sampl method like take xed fraction data set wide use empir machin learn research appropri data mine amount data avail huge moreov method take account accuraci condenc consider therefor discuss wide use theoret sound tool determin appropri sampl size given accuraci condenc paramet call concentr bound larg deviat bound like cherno hoed bound commonli use theoret learn research see 7 exampl well mani branch comput scienc 13 exampl sampl size calcul concentr bound data mine problem see eg8 15 18 bound usual allow us calcul sampl size need mani situat usual case result sampl size immens obtain reason good accuraci condenc moreov situat appli bound need assum knowledg certain problem paramet unknown practic applic import notic batch sampl approach sampl size calcul priori thu must big enough work well situat might encount word sampl size provid theoret bound batch sampl approach worst case sampl size thu overestim situat one main reason research found practic bound overestim necessari sampl size mani non worstcas situat see eg discuss toivonen sampl associ rule discoveri 15 overcom problem propos paper sampl onlin sequenti fashion instead batch algorithm obtain exampl sequenti one one determin obtain exampl whether alreadi receiv enough exampl issu current best rule nearli best high condenc thu x sampl size priori instead sampl size depend adapt situat hand due adapt worst case situat fortun happen practic case may abl use signicantli much less exampl worst case follow approach propos gener algorithm adaselect solv gener rule select problem provid us ecient tool mani knowledg discoveri applic gener algorithm evolv preliminari work onlin adapt sampl specic problem relat model select associ rule done 3 4 idea adapt sampl quit natur variou method implement idea propos literatur statist particular method studi depth name sequenti test sequenti analysi 16 howev main goal test statist hypothes thu even though method applic instanc gener rule select problem far author know method reliabl ecient adaselect gener rule select problem use simpl exampl explain next section dierenc advantag adaselect relat algorithm includ one follow batch sampl approach paper organ follow next section explain still intuit level advantag algorithm random sampl method section 3 present problem algorithm prove theorem concern reliabl complex section 4 describ sever applic algorithm particular data mine problem improv might use studi particular situat describ section 5 conclud section 6 highlight futur work relat work idea determin number necessari exampl adapt therebi reduc averag number exampl quit natur method implement idea propos literatur statist method call sequenti test sequenti analysi sinc wald publish pioneer 1 textbook sequenti analysi 16 mani research studi sequenti analysi method depth main goal howev test statist hypothes thu even though method applic purpos evalu andor compar valu given function given huge dataset method far author know reliabl ecient gener algorithm adaselect illustr dierenc adaselect method let us consid follow simpl problem need simpl util function problem test whether probabl p given condit c hold 1 accord wald textbook idea sequenti test procedur goe back hf dodg hg romig 2 databas x 12 c held exactli 12 transact x would check databas notic thu let us suppos intuit condit hold mani transact instanc 90 10 databas sampl small number transact enough gure answer posit neg hand closer 50 transact condit hold dicult test sampl correct answer use adaselect solv problem follow keep two function h 1 h 2 map transact 01 valu given one transact x h 1 x output 1 transact x satis condit c otherwis h 1 x output 0 hand h 2 negat h 1 util function use uh dierenc posit neg half proport transact purpos algorithm need detect whether uh 1 posit case neg thu need x number less 1 run algorithm set would abl determin high condenc whether condit c occur 50 transact x notic applic adaselect alway solv problem matter small far 0 hand sampl complex number necessari exampl depend henc algorithm might requir lot transact small specic number transact need sampl databas o1 ln1 ignor factor depend condenc paramet therefor closer valu 0 thu p 12 larger number exampl need batch sampl approach also applic problem use appropri larg deviat bound eg cherno bound determin number exampl sucient detect high condenc whether condit hold x notic choos appropri sinc high condenc algorithm guarante hand number exampl need o1 therefor use smaller underestim sampl complex becom larg word batch sampl approach alway big enough cover possibl valu bigger thu depend sinc worst case might equal hand adaselect depend case hand thu sampl size depend moreov practic applic might unrealist assum assum knowledg lower bound quantiti want estim clearli see advantag algorithm simpl batch sampl sophist way solv problem could follow instead use cherno bound provid estim within multipl error probabl estim thu adequ purpos use unless lower bound known use hoed bound also usual refer addit version cherno bound sampl size provid bound independ probabl estim thu need assum knowledg lower bound hand estim guarante within addit error valu estim therefor gener imposs use one singl sampl guarante problem solv instead follow suppos run batch sampl calcul appropri size hoed bound obtain estim p 1 p high probabl p 1 satisfi 14 thu p 1 greater 34 determin high condenc p greater 12 hand p 1 less 14 determin p less 12 howev p 1 rang 14 p 1 34 conclud anyth whether p 12 last situat occur choos small enough sampl complex becom larg underestim one way solv problem iter execut algorithm smaller accuraci paramet obtain estim safe rang case exampl run algorithm continu process obtain estim ith iter rang 12 2 i1 122 i1 suppos algorithm alway give close estim p routin calcul show algorithm termin log1 iter approach use o1 2 exampl obtain close estim ignor factor depend condenc paramet everi step henc altogeth need o1 give order adaselect fact roughli speak idea adaselect hand adaselect iter phase natur incorpor thu adaselect better sampl complex furthermor easi gener techniqu estim andor compar gener function valu method sampl describ refer classic statist multipl sampl 1 one earlier work sequenti sampl method 16 recent work adapt sampl come databas commun due lipton etal 9 10 follow problem discuss 2 given databas queri databas instanc select joint want estim queri size number transact associ queri databas certain error condenc level design algorithm task refer algorithm adapt estim specic given databas x condit c accuraci paramet condenc paramet adapt estim estim random sampl probabl p transact multipl error probabl least 1 algorithm yield estim p p 1 p p 1 achiev task adapt estim collect exampl databas sequenti random check whether collect exampl sucient termin execut current estim number exampl use algorithm depend correct algorithm prove use larg deviat tool particular use central limit theorem thu word adapt estim sequenti version multipl cherno bound howev import notic adapt estim work estim total probabl exampl provid us multipl estim p approach quit similar adapt estim algorithm adaselect propos also collect exampl given databas sequenti random check whether collect exampl sucient furthermor also use one larg deviat tool order guarante correct ie reliabl output algorithm thu one may think superci adaselect dier adapt estim point enabl us estim gener valu ie valu user dene util function fact could estim advantag instead p exampl note dierenc essenti exampl problem adapt estim exactli problem batch sampl method hoed bound thu use gener must use iter describ also remark choic util function u import use uh problem execut adaselect becom essenti adapt estim technic due gener stop condit sampl algorithm monoton requir care probabl analysi 2 order keep explan intuit level explain typic algorithm omit detail dierenc algorithm see paper cite detail algorithm adaselect present paper evolv previou work hypothesi select 3 sampl associ rule 4 fact two case treat simpl case gener util function introduc paper algorithm present paper greatli gener adapt algorithm provid use attack sever problem 3 adapt sampl algorithm section formal describ problem would like solv present algorithm investig reliabl complex begin introduc notat let larg set exampl let nite larg set n function thought function evalu exampl x produc real valu result intuit h 2 h correspond rule law explain exampl call rule measur good rule x follow identifi h correspond rule usual call h rule exampl task predict particular boolean featur exampl x term featur could set featur predict correctli h predict incorrectli also assum xed realvalu nonneg util function uh measur global good rule correspond h set x specic x uh dene f function ir 7 ir avg denot take arithmet averag ie i2i jij uh simpli dene uh x section 4 describ sever applic framework u instanti specic function mean becom clear readi state problem gener rule select given x h 0 1 goal find h 2 h uh 1 rule maximum valu uh remark 1 accuraci paramet intuit task nd h 2 h whose util reason high compar maximum uh accuraci uh uh speci paramet certainli closer uh uh better howev depend choic u accuraci essenti case may abl use larg advantag algorithm becom clear case recal exampl discuss section 2 see also discuss end section remark 2 condenc paramet want achiev goal random sampl ie use exampl randomli select x must chanc select bad exampl make algorithm yield unsatisfactori h 2 h thu introduc one paramet specifi condenc requir probabl error bound remark 3 condit h order simplifi discuss assum follow valu hx hx 0 constant 0 denot constant remark 4 condit u goal make sens uh neg thu assum uh posit also order sort random sampl work happen singl exampl chang drastic valu u otherwis would forc look exampl x even approxim valu uh thu requir function f dene u smooth formal f need clipschitz constant c 0 dene c denot lipschitz constant f denit 1 function f ir 7 ir clipschitz x hold jf x f yj c jx yj lipschitz constant f minimum c 0 f clipschitz observ lipschitz function continu dierenti function bound deriv lipschitz fact f dierenti mean valu theorem lipschitz constant f max x jf 0 xj see section 4 natur function use applic describ satisfi condit c also note condit cd uh cd h 2 h remark 5 minim problem situat primari goal might maxim util function data minim penalti function p want nd h p h 1 solv gener hypothesi select problem algorithm analysi similar one present end remark one trivial way solv problem evalu function h h exampl x x henc comput uh h nding h maxim valu obvious x larg method might extrem ineci want solv task much ecient random sampl want look fairli small randomli drawn subset x nd h maxim uh still sure probabl 1 h output satis uh 1 uh one easili think follow simpl batch sampl approach obtain random sampl x priori xed size output function h highest util sever statist bound calcul appropri number exampl paper choos hoed bound wide use comput scienc see eg 7 13 one use reason bound choos one use determin consid reliabl ecienc reason choos hoed bound basic assumpt necessari 3 use bound estim error probabl calcul sampl size hand bound exampl central limit theorem might appropri practic situat sinc behav better although slighlti less reliabl easi modifi algorithm analyz altern bound roughli sampl size error valu hoed bound provid us upper bound probabl estim calcul randomli drawn sampl apart real valu thu use bound determin sampl size guarante batch sampl yield rule satisfi requir problem probabl least 1 batch sampl solv problem ecienc satisfactori choos sampl size worst case overcom ineci take sequenti sampl approach instead static decid sampl size new algorithm obtain exampl sequenti one one stop accord condit base number exampl seen valu function exampl seen far algorithm adapt situat hand thu worst case algorithm would abl realiz stop 3 assumpt obtain sampl independ obtain distribut natur assumpt hold problem consid algorithm repeat x randomli drawn exampl x 1 constant close 1 see proof theorem 3 output h 2 h largest uh figur 1 pseudocod onlin sampl adaselect figur 1 show pseudocod algorithm propos call adaselect solv gener rule select problem provid two theorem discuss reliabl complex algorithm adaselect proof make use follow lemma lemma 2 let x set size obtain independ draw element x random h 2 h 0 proof let g valu avgi hx x 2 x g random variabl avgi observ use fact f clipschitz prf jg egj c g g averag independ random variabl rang bound hoed bound probabl less 2 exp claim end proof rst prove reliabl algorithm adaselect theorem 3 probabl 1 adaselectx h output function h 2 h uh 1 uh proof xed 0 dene h g show function output adaselectx h h bad probabl less want bound follow error probabl p error regard one repeatloop iter basic step algorithm measur algorithm run time term number repeatloop iter use denot number execut repeatloop iter particular let 0 integ follow inequ hold note strictli decreas function henc 0 uniqu determin see algorithm termin 0 th step ie 0 th repeatloop iter high probabl deriv bound consid follow two case case 1 h 2 h bad satis stop condit repeatloop 0 th step case satisfi stop condit rst 0 step clearli whenev algorithm make error one case certainli occur thu bound probabl either case 1 case 2 occur bound error probabl p error algorithm first bound probabl case 1 let h bad rule h bad largest util case 1 hold g prf h satis stop condit adaselect tth step g stop condit adaselect tth step g g 1 0 p 1 bound follow use fact 0 uh 2 uh 1 uh bad lemma 2 thu estim case 1 hold g 2n exp next consid case 2 clearli case 2 impli uh 2 1 thu probabl case 2 bound follow bound p 2 rst estim 0 let b use assumpt 0 1 uh 2 fact uh cd henc may consid b 1 therefor b p 2 bound follow 2nt summari b probabl either case 1 case hold bound end proof next estim run time algorithm regard one repeat loop iter basic step algorithm measur algorithm run time term number repeatloop iter exactli number requir exampl proof alreadi show probabl algorithm termin within 0 step case 2 occur thu follow theorem immedi proof theorem 4 probabl 1 adaselectx h halt within 0 step word adaselectx h need 0 exampl 0 largest integ 0 let us express 0 conveni form recal 1 sinc approxim approxim x ln x x ln cd let us discuss mean formula sinc n within log func tion uenc complex small word handl rel larg number rule requir high condenc without increas much sampl size need main term formula 1 cduh recal uh cd h 2 h henc 1 cduh least 1 depend choic u case may assum cduh larg case may need small thu 1 larg adaselect perform well latter case specic adaselect show advantag u chosen 1 rel larg sucient 2 though cduh bound gener larg lucki case happen often bad case see section 4 clever choic u might allow us choos larg overal number exampl might larg 4 exampl applic section describ two domain instanc algorithm use solv particular problem two domain studi model hypothesi select induct decis tree due space limit describ possibl applic problem like associ rule mine alreadi studi 4 subgroup discoveri batch sampl method base larg deviat method alreadi propos speed comput process see instanc 15and 18 algorithm also appli order instanti framework particular problem need specifi mean function class h util function u condit condit u satis follow problem model hypothesi select typic applic framework class function h seen xed set hypothes model set could obtain instanc dierent run rival learn algorithm learn algorithm dierent input paramet architectur could contain sever dierent memorybas hypothesi xed certain restrict model space consequ design decis notic later case case algorithm tri select hypothesi simpl small class hypothes instanc decis stump amplifi precis use vote method like boost 5 thu rest discuss assum class h xed nite tractabl size util function captur criterion good hypothesi typic one predict error order keep discuss simpl level assum hypothes binari good criteria predict error case one might naiv set util function ident function uh notic howev worst possibl predict error 12 answer ip random coin henc precis speak good hypothesi h measur advantag random guess thu want algorithm output hypothesi whose advantag random guess close best possibl advantag class fact set ts particularli well vote method like adaboost 5 typic one need obtain hypothesi better random guess everi step purpos set uh particular select hypothesi vote method choic may import set constant smaller 1 similar set previous studi maron moor 11 propos algorithm call hoed race acceler model select idea discard hypothes clearli go among best one criteria discard base invert hoed bound refer reader paper detail clearli add featur algorithm without compromis reliabl complex possibl acceler total run time notic combin hoed race algorithm reduc much number exampl need sinc depend logarithm number model n might greatli reduc comput time depend linearli n follow research moor lee 12 develop ecient version hoed race base bayesian approach assumpt model accuraci dataset normal distribut furthermor also introduc modic discard model almost indistinguish other thu allow race output model best class notic also accuraci paramet framework allow one use complic util function could incorpor size smooth consider togeth predict error case realvalu function could also consid instanc mean squar error decis tree induct algorithm decis tree induct typic work choos test root certain node function class subsequ root subtre explor train data choos one best accord certain split criteria like entropi measur gini index larg dataset could possibl reduc train time choos split base subsampl whole data musick catlett russel 14 describ algorithm implement idea choos sampl base dicult decis node typic algorithm use small sampl root node enlarg progress tree grow propos altern way select appropri sampl size need everi node use instanti algorithm describ follow follow notat 6 simplic assum want construct decis tree approxim unknown function use train data set x furthermor assum class node function f xed priori nite small instanc input variabl negat 4 fact class commonli use standard softwar packag c45 cart final denot g 0 0 1 split criteria use topdown decis tree induct algorithm typic exampl function binari entropi let decis tree whose intern node label function f node label valu f0 1g let l leaf want make new intern node substitut leaf l function h f goal choos function h valu g origin tree sum valu g everi leaf weight probabl reach leaf decreas substitut l h 4 assumpt make sens attribut discret discret priori label new label l 0 l 1 accord major class instanc reach l 0 l 1 respect formal let set instanc reach l x h f denot p 1 probabl fx 1 p 1 probabl hx 1 p 11 probabl hx fx 1 p 01 probabl hx 0 fx 1 notic probabl taken distribut induc initi distribut train set typic assum uniform distribut thu given leaf l given goal nd function h maximum valu l h l denot h function mention larg dataset ecient way attack problem follow given tree leaf l take sampl x output function h highest valu l h sampl sampl size chosen appropri valu l h h function output algorithm close l h appli algorithm use appropri amount data follow use f h l h uh x 5 remain determin constant c lipschitz condit u notic u addit three g function dierent input thu g lipschitz certain constant c u state obtain lipschitz constant g leav reader calcul appropri constant whole function u gq gini index deriv g 0 4 thu mean valu theorem lipschitz constant 4 gq binari entropi hq improv split criterion present 6 deriv bound 0 1 rang therefor xed constant work possibl valu howev suppos ignor input valu close 0 1 consid instanc interv 005 095 function lipschitz constant 5 interv notic input function g estim sampl thu assumpt make sens sinc admit certain error valu thu run algorithm input h u discuss desir accuraci condenc level algorithm output probabl larger 1 node function h l h 1 crucial point choic 5 precis speak l h denit uh x easi see algorithm also work situat u moreov accord result 6 h l h suce reduc overal error whole tree ad new intern node thu x 12 inform describ anoth possibl applic algorithm problem decis tree induct problem nding good cut point continu attribut order discret case everi function h repres possibl cut point even though total number cut point innit notic need consid cut point appear dataset set consid thu k k size x although x might big notic bound given theorem 4 depend logarithm size h thu particular applic size x give us upper bound size h furthermor notic run algorithm need function h priori everi time new exampl reveal new possibl cut point add new function class calcul util function exampl seen far util function case split criterion use compar split function describ thu algorithm problem would choos almost optim respect split criterion cut point particular continu attribut done use attribut discret attribut decid attribut use label node build 5 improv section describ improv incorpor main algorithm adaselect complet rigor justic other seem intuit clear harder captur form theorem use multipl cherno bound instead addit hoed bound develop algorithm adaselect use hoed bound deviat averag valu appear addit case also possibl use cherno bound deviat appear multipl proof slightli involv appli cherno seem requir previou knowledg expect valu util function precis tri estim care also adapt applic let us circumv problem util function particular done case f ident function plu minu constant 0 1 problem model hypothesi select case use cherno clear advantag case small probabl precis bound number exampl o1 depend 1uh linear instead quadrat although seem asymptot better hidden constant bigger precis 12 thu happen better uh 16 consid varianc case may true valu hx alway 0 moder larg probabl version hoed call berstein bound instead assumpt incorpor varianc hx bound estim varianc known plug adaselect may give quit advantag use worstcas constant adapt local lipschitz constant bound depend constant c global lipschitz constant f howev mani region much smaller constant may enough bound growth rate f consid exampl entropi style function discuss decisiontre induct saw appropri choic c around 4 5 probabl near 0 1 howev probabl near 12 quit common case function almost ie c much closer 0 suce practic one probabl use step worstcas lipschitz constant within uncertainti interv uh ie uh dicult give rigor analysi new version intuit clear may result signic improv essenti aect reliabl 6 conclud remark present new methodolog sampl keep theoret guarante previou one applic wider set moreov like use practic key point rather decid priori sampl size obtain batch algorithm perform sampl sequenti maintain stop condit depend problem hand futur work verifi advantag approach experiment although theorem provid paper suggest algorithm might ecient applic sever domain still plenti work test whether assert true one hand algorithm take prot non worst case situat therefor like outperform usual batch sampl approach hand asymptot alon guarante practic sinc huge constant might spoil advantag sampl use data even ecient sampl algorithm use test second point preliminari work 3 4 use synthet data could test wide rang valu result promis sampl size use method greatli outperform one use batch approach moreov sampl size mani case reason small suggest reduc data size sampl algorithm might allow us improv overal run time experiment result 10 although dierent context also encourag case remain experi use real world data test real practic algorithm furthermor point sever improv one might perform appli algorithm particular situat due gener approach everi applic deserv individu deeper studi see possibl enhanc one particular set acknowledg would like thank heikki mannila point us work sampl databas queri estim encourag us follow previou research adapt sampl would also like thank chri watkin tell us hoed race pedro domingo point us sever relat machin learn paper r multipl sampl constant probabl method sampl inspect ricard gavald ricard gavald decisiontheoret gener onlin learn applic boost boost abil topdown decis tree learn algorithm introduct comput learn theori power sampl knowledg discoveri je random algorithm decis theoret subsampl induct larg databas sampl larg databas associ rule sequenti analysi bala iyer je algorithm multirel discoveri subgroup tr ctr geoff hulten pedro domingo mine complex model arbitrarili larg databas constant time proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli 2326 2002 edmonton alberta canada szymon jaroszewicz tobia scheffer fast discoveri unexpect pattern data rel bayesian network proceed eleventh acm sigkdd intern confer knowledg discoveri data mine august 2124 2005 chicago illinoi usa osamu watanab sequenti sampl techniqu algorithm learn theori theoret comput scienc v348 n1 p314 2 decemb 2005 huan liu hiroshi motoda issu instanc select data mine knowledg discoveri v6 n2 p115130 april 2002 jaekyung yang sigurdur olafsson optimizationbas featur select adapt instanc sampl comput oper research v33 n11 p30883106 novemb 2006 pierrealain laur richard nock jeanemil symphor pascal poncelet mine evolv data stream frequent pattern pattern recognit v40 n2 p492503 februari 2007