combin static dynam schedul distributedmemori multiprocessor loop larg sourc parallel mani numer applic import issu parallel execut loop schedul workload well balanc among processor exist loop schedul algorithm design sharedmemori multiprocessor uniform memori access cost approach suitabl distributedmemori multiprocessor data local major concern commun cost high paper present new schedul algorithm data local taken account approach combin world static dynam schedul twolevel overlap fashion way data local consid commun cost limit perform new algorithm evalu cm5 messagepass distributedmemori multiprocessor b introduct loop exhibit parallel present numer program therefor distribut workload loop evenli among processor critic factor effici execut kind parallel program loop schedul strategi assign iter processor machin way finish workload less time simpl strategi static schedul determin assign iter processor compiletim mani situat workload iter unpredict compil time dynam schedul strategi develop handl situat solv assign problem runtim consid crossiter data depend classifi loop three major type doseri doall doacross pol88 paper primarili concern doall parallel loop data depend pair iter otherwis publish proc acm intl conf supercomput manchest uk juli 1115 1994 loop taken serial point view schedul loop uniform execut time differ iter eg matrix multipl semiuniform depend index loop eg adjoint convolut nonuniform depend data eg transit closur alway obtain optim near optim static schedul uniform loop parallel machin p processor must simpli partit set iter loop p chunk dpne iter n length loop assign chunk processor still obtain near optim static schedul semiuniform loop exampl consid parallel adjoint convolut algorithm exhibit triangular iter space establish near optim static schedul use kind cyclic loop distribut scheme assign iter rp 1 p processor processor clearli possibl defin optim static schedul nonuniform loop data known runtim loop frequent mani applic imag process spars matrix comput partial differenti equat among other dynam schedul strategi use balanc workload nonuniform parallel loop design sharedmemori machin uniform memori access cost uma therefor data local taken con sider nevertheless distributedmemori machin data local major concern must optim paper concentr nonuniform parallel loop discuss effici solut schedul kind loop distributedmemori parallel machin strategi combin featur static dynam schedul techniqu succe keep cost associ remot memori access low section 2 describ schedul strategi propos literatur special distributedmemori machin approach perform loop schedul explain section 3 section 4 show experiment result obtain cm5 final paper conclud section 5 relat work find static schedul solut propos literatur pkp89 optim compiletim schedul strategi propos perfectlynest parallel loop constant bound sarkar hennessi sh86 propos schedul method base split program sequenti task bb91 schedul solv linear optim problem tawbi feautrier tf92 test heurist solv processor alloc schedul problem applic symbol analysi deriv optim static schedul found hp93 nonuniform problem necessari balanc load dynam runtim selfschedul ss ty86 simplest strategi processor repeatedli select execut one iter iter execut experiment comparison selfschedul static preschedul algorithm found zha91 fixeds chunk schedul kw85 reduc high synchron overhead found ss schedul chunk one iter unit gss pk87 schedul larg chunk begin loop low synchron overhead small one toward end loop tri balanc workload factor schedul hsf92 alloc iter processor proce phase phase part remain iter divid equal among avail processor trapezoid schedul tn93 variat gss size success chunk decreas linearli instead exponenti luc92 taper schedul propos similar gss trapezoid schedul differ function decreas size chunk dynam schedul design sharedmemori parallel machin effici method synchron data share found distributedmemori parallel machin big differ access time local memori remot mem ori synchron overhead datashar cost high comparison access cost local data much better schedul perform obtain local data exploit recent dynam schedul strategi exploit data local appear literatur ml94 affin dynam schedul ad introduc numa machin algorithm gss trapezoid schedul assign larg chunk iter start loop execut use determinist assign polici ensur chunk alway assign processor way data local exploit work case data reus sever time happen exampl parallel loop surround sequenti one chunk execut repeatedli localitybas dynam schedul ld design numa machin describ ltss93 ld consid data space partit throughout processor comput size chunk use gsslike scheme chunk assign processor demand includ iter whose data store local memori processor assign case messagepass machin rudolph polychronopoulo rp89 implement evalu static self chunk guidedself schedul ipsc2 hypercub multicomput first attempt evalu sharedmemori dynam schedul algorithm distributedmemori multiprocessor foreverf execut processor static schedul level dynam schedul levelg figur 1 hybrid schedul hs algorithm distributedmemori machin pure dynam schedul strategi poor perform due rel high synchron overhead hand static schedul scheme suitabl nonuniform prob lem situat hybrid scheme perform bet ter exploit data local exhibit rel low synchron overhead balanc workload dynam time exampl approach present lsl92 twophas safe selfschedul sss describ first phase subset iter loop distribut uniformli among processor second phase sss activ runtim processor becom idl chunk yet execut iter chosen assign dynam request processor strategi consid central queue iter processor access data distribut safe selfschedul dsss adapt sss messagepass machin discuss sll93 data partit small block size distribut partial redund among processor dsss proce sss chunk iter assign processor correspond data dsss gener ls93 dynam phase dsss fire processor becom idl processor charg schedul duti distribut demand rest workload among processor inher dynam redistribut load may impli low perform paper describ new approach hybrid schedul ing propos twolevel scheme phase static dynam overlap ad use similar twolevel scheme exploit dataloc major concern loadbalanc accomplish demand processor becom idl case dataloc consid tri predict advanc workload unbal order obtain better loadbal reduc commun overhead processor execut static distribut workload dynam redistribut rest workload action henc commun overhead associ dynam level schedul hidden local comput experi show twolevel strategi obtain good perform 3 schedul scheme parallel loop consid rest paper follow simpl structur loop bodyi 1 hybrid schedul hs propos accomplish two level shown figur 1 static level first static partit evenli distribut iter space parallel loop among processor machin denot p number processor processor execut total iter parallel loop 1 local loop bodyi note use lowercas indic repres local variabl uppercas global one denot ff numer address processor relat local global indic depend static distribut scheme use exampl case block distribut loop form local loop bodi depend data distribut scheme chosen choos partit data throughout local memori processor local loop bodyi ident loop bodyi prefer replic data local memori local loop bodyi equal loop bodyi combin found partial replic data consid dynam level second level requir split local iter space set chunk size chunk may constant variabl inde may use one dynam schedul algorithm found literatur order accomplish partit local iter space exampl gss algorithm consid set n local iter would partit total iter group chunk e size chunk number therefor local loop transform upperbound lowerbound upperbound localloopbodyi chunk sizec comput size chunk number c action associ dynam level hs carri boundari execut one chunk follow one way establish hybrid degre two extrem static dy namic choos size number chunk certain unbal workload detect dynam level hs becom activ tri reduc unbal given threshold redistribut local comput still go specif execut chunk iter start next one processor carri action order arrang fastest slowest one lightli load heavili load processor point execut redistribut load chunk erat execut necessari redistribut process overlap execut local chunk critic point hs arrang effici classif processor order determin processor send load receiv solv worker local queue empti f send load msg schedul remov chunk local queue execut chunk removedg els firsttim ye f send load need msg schedul schedul local queue empti f increment workload counter remov chunk local queue execut chunk removedg els firsttim ye f select mhlw heavili load worker send load request msg mhlw worker dead local queue empti messag travel exit load msg receiv figur 2 static schedul level problem assign classif work one pro cessor processor worker one addit charg dynam schedul duti therefor worker must send messag period schedul inform need order establish classif right time chunk boundari implement hs messagepass distributedmemori machin use simpl protocol seven differ type messag mean messag describ tabl 1 rest section dedic detail descript level hs 31 static schedul level figur 2 show detail descript static level hs point view worker schedul also worker level worker send one empti load messag schedul execut one local chunk therefor time elaps two consecut load messag equal time elaps begin execut one local chunk next one schedul carri classif worker execut local chunk code workloadredistribut function figur 2 worker becom idl send load need messag schedul request nonexecut chunk worker search worker accomplish schedul dynam level unless request worker schedul note case load request messag sent select worker mhlw minimum number nonexecut chunk parameter constant transferlimit mechan type mean load worker send schedul execut local chunk load need worker send schedul becom idl load migrat worker send request processor next nonexecut local chunk request fail worker send request processor local queue almost empti data return use return remot process data block origin place load request schedul request worker send next nonexecut chunk processor load finish chunk execut remot tabl 1 messag use hs implement schedul read load msg receiv updat workload counter classifi correspond worker accord workload worker classif list f remov mllw lightli load worker classif list choos mhlw heavili load worker classif list send load migrat msg mllw next nonexecut local chunk els send load request msg mhlw mllw request processorg messag sent f mllw sent load need msg f send load finish msg mllw reduc number worker aliv worker dead local queue empti messag travel exit figur 3 workload redistribut migrat remain chunk avoid commun latenc would probabl elimin benefit associ balanc remain load special true use algorithm like gss partit local loop last chunk small 32 workload redistribut period schedul tri evenli redistribut load among worker execut local chunk schedul read load messag receiv count determin rel local speed worker note rather instantan measur schedul count load messag receiv execut last local chunk base inform schedul classifi worker sent load messag order decreas speed classif complet schedul order heavyload processor send chunk lightload one see figur 3 load redistribut accomplish rest worker execut local chunk worker send load messag start execut remot chunk see next subsect way fast worker receiv number success remot chunk frequenc arriv load messag reduc consequ thu schedul eventu classifi worker slow send remot load becom fast later stage hap pen mechan schedul tri period delay fastest processor allevi load slowest one tradeoff accuraci measur rel speed commun cost associ measur accuraci achiev sensit schedul chang local load thu better balanc load respons chang faster precis order obtain high accuraci worker must send load messag high frequenc reduc size chunk increas commun overhead intoler level tradeoff classif accuraci associ commun cost establish choos size chunk iter order prevent thrash remot chunk incorpor two simpl mechan first remot chunk alway execut destin processor redistribut remot chunk sever worker prohibit second workload counter use select slow worker load vector figur 3 modifi load redistribut process chosen mhlw send one nonexecut local chunk workload counter decrement ac cordingli way singl slow heavi load worker prevent send mani chunk risk processor lose local chunk likewis workload counter correspond destin worker increment remot chunk assign tri prevent bulk arriv 33 dynam processor coordin hide overlap commun latenc redistribut load execut local comput time processor continu execut local chunk transfer chunk travel interconnect network local chunk follow one worker check arriv control me sage possibl remot chunk execut arriv worker immedi begin execut follow local chunk otherwis execut remot chunk final return process remot data owner last action necessari want modifi origin static data distribut case modif irrelev exampl worker pend messag f switch type messag receiv f case load finish msg pend messag exit break case load request msg send load migrat msg request processor next nonexecut chunk els send request fail msg request processor break case load migrat msg execut migrat chunk send data return msg migrat data owner necessari load finish msg receiv els messag travel exit break case request fail msg load finish msg receiv els messag travel exit break case data return msg store remot process data block origin locat els messag travel exit breakgg figur 4 dynam schedul level worker want execut parallel loop sever time one anoth case delay reconstruct origin data distribut last time parallel loop execut due commun latenc lose part load balanc decis redistribut load redistribut carri differ time exampl possibl fast processor enter heavili load part local comput receiv previous transfer remot chunk case increas load current slow processor nevertheless increas error balanc load overcom benefit reduc commun overhead net result benefici experi show workload redistribut phase explain section schedul determin set worker must send chunk set must receiv need establish dynam processor coordin order effici transfer chunk among select worker coordin worker check differ kind messag execut action accord control scheme shown figur 4 5 one argu number worker larg schedul becom bottleneck larg number worker schedul would probabl execut first local chunk redistribut rest among worker depend schedul pend messag f switch type messag receiv f case load need msg select mhlw heavili load worker send load migrat msg request processor next nonexecut chunk els send load request msg mhlw send load finish msg request processor reduc number worker aliv worker dead local queue empti messag travel exit break case load migrat msg execut migrat chunk send data return msg migrat data owner necessari break case request fail msg break case data return msg store remot process data block origin locat els messag travel exit breakgg figur 5 dynam schedul level schedul static load initi assign schedul relat load worker inde experi show gener effici parallel loop lower schedul one initi lightli load processor moreov schedul charg period classif worker core workload redistribut process may introduc anoth potenci perform bottleneck paper show result use one schedul possibl sever schedul consid futur 4 experiment evalu implement hs cm5 use cmmd messagepass librari thi91 addit hs order make comparison fulli static fulli dynam schedul implement well measur perform schedul algorithm use two benchmark program 41 benchmark program chosen matrix multipl mm simpli fie transit closur tc benchmark program mm typic exampl regular uniform prob lem tc repres irregular non uniform one workload parallel loop depend heavili data content ffl matrix multipl program three perfectli nest loop innermost one contain reduct oper two loop fulli parallel experi parallel program outermost loop regular program use evalu effect hs compar optim static schedul transit closur tc program 3depth nest loop well outermost loop serial next one parallel reason first loop drop experi one iter outermost loop consid follow sequenti innermost loop may may exe cute henc comput nonuniform depend input data program allow us evalu perform hs fulli dynam environ 42 schedul algorithm implement follow schedul algorithm static schedul static hs data partit throughout local memori hsp hs data replic local memori hsr dynam schedul data partit throughout local memori consid schedul worker dynamicp charg schedul duti dynamicp static schedul consist blockwis static distribut iter parallel loop matric partit block distribut well case mm matric c block partit row partit store respect local matric c matrix b replic local code processor follow tc matrix block partit row well store local matrix first row replic renam a1 local tc due fact execut time loop bodi parallel loop tc small introduc anoth loop surround granular control loop number loopbodys iter loop permit parameter loop bodi size studi effect experi order obtain initi poor workload balanc static schedul tc benchmark taken input matrix 1s first half row 0s rest data static schedul perform around 50 effici way clearli evalu benefit includ dynam action schedul strategi irregular problem consid data distribut scheme static level hsp hsp hsr analyz global impact data migrat perform hs partit scheme may impli great amount data migrat case scheme chosen partit local loop gss0 schedul gss2 rest worker gss2 obtain reason small commun overhead due rel reduc number messag sent schedul worker chunk present bigger size hand use gss0 schedul improv sensi tive dynam workload chang henc obtain reason load balanc select valu 2 1 transferlimit paramet worker sched uler algorithm gss0 chosen fulli dynam schedul case data migrat alway consid return origin owner execut remot chunk 43 result interpret figur 6 display effici versu number processor mm case two differ matrix size compar perform three schedul algorithm static hybrid dynam comput effici execut schedul algorithm one processor see best perform static schedul worst perform dynam one hs perform quit similar static schedul especi case suffici larg matric behavior explain fact worker process almost workload loop evenli distribut across local memori compiletim worker send load messag less time sched uler execut time chunk suffici larg messag arriv schedul differ time due differ commun path taken smaller execut time singl chunk way workload counter contain number differ one unit processor thu schedul never decid migrat local chunk hs work similar static strategi overhead associ control messag possibl load unbal may appear mm 10010009070503 number processor effici number processors09070503 mm 400400 hsr number processor effici b hsr mm 400400 number processors099097095093 effici figur effici matrix multipl last local chunk processor case transferlimit paramet prevent migrat remain chunk besid explain version hsp hsr perform roughli similar way shown figur 6 b tc program hsp perform best larg loop bodi see figur 7 experi two matrix size three valu upper bound granular control loop loopbodys 10 100 1000 dimens input matrix andor size parallel loop bodi suffici larg effici hsp rise around 75 80 instead best pure dynam schedul alway static one result show advantag consid data local static level hs overlap chunk migrat local comput dynam level hs data size loop bodi small chunk migrat cost partial hidden local comput time case perform hs poor becom wors number processor increas note larg input matrix effici hsp remain around 75 number processor consid therefor use one schedul suffici order balanc load among dozen processor input matrix chosen half 1s half 0s split processor two class heavili load lightli load processor initi static loop distribut half processor charg comput half idl experi influenc initi workload assign schedul perform hs result shown figur 8 data partit replic version hs consid one hand import point larg loop bodi effici hs greatli affect data distribut scheme chosen hand effici notic wors lightli load initi idl schedul chosen reason schedul kind goe workload redistribut level frequent thu send mani messag heavili load processor order migrat mani chunk henc total commun cost high behavior prevent schedul heavi workload expens probabl wors workload balanc inde found mani case load balanc wors schedul heavili load worker nevertheless effici former case better due limit commun cost number processors0503012 4 8 effici static number processor effici number processors060402 effici number processor effici number processor effici number processor effici figur 7 effici transit closur conclus studi problem loop schedul distributedmemori multiprocessor loop regular compiletim static schedul near optim solut need migrat load among processor loop irregular execut time loop bodi depend data exampl thu need consid runtim dynam techniqu order manag load imbal well dynam schedul algorithm work well sharedmemori environ memori distribut take data local account want keep commun overhead certain limit believ best solut would combin static dynam strategi loop schedul algorithm want obtain high perform distributedmemori multiprocessor describ algo rithm hybrid schedul hs static dynam natur present two level concept permit overlap local comput migrat part workload way larg part high commun overhead associ migrat contribut complet time order orchestr dynam workload balanc one worker time charg dynam schedul duti evalu perform hs cm5 regular program matrix multipl hs perform near static schedul depend data size case hs carri load migrat overhead associ dynam level low irregular program transit closur hs perform best loop bodi suffici larg mani data size load well balanc commun overhead associ migrat low result indic combin effect gener benefici machin cm5 import result perform hs sensit data distribut scheme chosen benchmark test import mani applic easi find best data di tribut investig includ depth studi influenc data distribut chosen static level perform moreov work multischedul extens hs obtain experiment result differ kind distributedmemori machin acknowledg research benefit significantli discuss suggest constantin polychronop lo materi experiment result obtain research stay center supercomput research develop univers illinoi urbanachaimpaign would like thank david padua compil group support gave us research support part cicyt grant tic920942c0303 xunta de galicia grant xuga20604a90 r schedul algorithm paralleliz depend task symbol analysi basi parallel optim schedul program factor method schedul parallel loop alloc ind pend subtask parallel processor selfschedul distributedmemori machin schedul parallel loop variabl length iter execut time parallel comput er local loop schedul numa multi processor dynam schedul method irregular parallel program use processor affin loop schedul sharedmemori multiprocessor guid selfschedul practic schedul scheme parallel supercomput util multidimension loop parallel largescal parallel processor system parallel program compil effici messagepass schedul base guid selfschedul compiletim partit schedul parallel program schedul ing nonuniform parallel loop distribut memori machin processor alloc loop schedul multiprocessor com puter processor selfschedul multipl nest parallel loop dynam static load schedul perform numa share memori multi processor tr alloc independ subtask parallel processor compiletim partit schedul parallel program guid selfschedul practic schedul scheme parallel supercomput util multidimension loop parallel larg scale parallel processor system dynam static load schedul perform numa share memori multiprocessor factor method schedul parallel loop dynam schedul method irregular parallel program processor alloc loop schedul multiprocessor comput selfschedul distributedmemori machin effici messagepass schedul base guid self schedul parallel program compil trapezoid selfschedul use processor affin loop schedul sharedmemori multiprocessor symbol analysi ctr babak hamidzadeh lau ying kit david j lilja dynam task schedul use onlin optim ieee transact parallel distribut system v11 n11 p11511163 novemb 2000