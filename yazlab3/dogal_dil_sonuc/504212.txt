analysi comparison two gener spars solver distribut memori comput paper provid comprehens studi comparison two stateoftheart direct solver larg spars set linear equat largescal distributedmemori comput one multifront solver call mump supernod solver call superlu describ main algorithm featur two solver compar perform characterist respect uniprocessor speed interprocessor commun memori requir solver preorder numer stabil sparsiti play import role achiev high parallel effici analys result variou order algorithm perform analysi base data obtain run 512processor cray t3e use set matric real applic also use regular 3d grid problem studi scalabl two solver b introduct consid direct solut spars linear equat distribut memori comput commun messag pass normal use mpi studi detail two stateoftheart solver mump amestoy duff lexcel koster 1999 amestoy duff lexcel 2000 superlu li demmel 1999 first use multifront approach dynam pivot stabil second base supernod techniqu static pivot iter refin discuss detail algorithm use two code section 3 two import factor affect perform code use preprocess preorder matrix diagon entri larg rel offdiagon strategi use comput order row column matrix preserv sparsiti discuss aspect detail section 4 compar perform two code section 5 show comparison fraught difficulti even though author code involv studi section 6 regular grid problem use illustr analys differ two approach origin plan comparison spars code given difficulti found assess code know well moment shelv ambiti project howev feel lesson learn present exercis invalu us futur wider studi given us insight behaviour spars direct code feel use share wider audienc stage addit valuabl inform compar merit multifront versu supernod approach examin paramet space comparison exercis identifi sever key paramet influenc differ degre two approach test environ throughout paper use set test problem evalu perform algorithm test matric come forthcom rutherfordbo spars matrix collect duff grime lewi 1997 1 industri partner project 2 tim davi collect 3 sparsekit2 4 eec depart uc berkeley 5 parasol test matric avail parallab bergen norway 6 two smaller matric garon2 lnsp3937 includ set matric use section 41 illustr differ numer behaviour two solver note experi consid symmetr matric test set superlu exploit symmetri unabl produc ldl factor howev sinc test exampl section 6 symmetr web page httpwwwcseclrcacukactivitysparsematric project 20160 3 web page httpwwwciseufledudavisspars 4 web page httpmathnistgovmatrixmarketdatasparskit 5 matrix ecl32 includ rutherfordbo collect 6 web page httpwwwparallabuibnoparasol real unsymmetr assembl rua matrix name order entri bbmat 38744 1771722 054 rutherfordbo cfd depart uc berkeley garon2 13535 390607 100 davi collect cfd lhr71c 70304 1528092 000 davi collect chem eng rutherfordbo cfd mixtank 29957 1995041 100 parasol polyflow sa collect cfd twoton 120750 1224224 028 rutherfordbo circuit sim wang4 26068 177196 100 rutherfordbo semiconductor tabl 21 test matric strsym number nonzero match nonzero symmetr locat divid total number entri structur symmetr matrix valu 10 show result symmetr unsymmetr factor version mump matric mixtank invextr1 modifi outofrang underflow valu matrix file keep sparsiti pattern want replac underflow valu zero instead replac entri expon smaller 300 number mantissa expon 300 linear system righthand side vector gener true solut vector one result present paper obtain cray t3e900 512 dec ev5 processor 256 mbyte memori per processor 900 peak megaflop rate per processor nersc lawrenc berkeley nation laboratori also refer experi 35 processor ibm sp2 665 mhertz processor 128 mbyte physic memori 512 mbyte virtual memori 266 peak megaflop rate per processor gmd bonn germani use parasol project perform characterist two machin list tabl 22 comput cray t3e900 ibm sp2 frequenc processor 450 mhertz 66 mhertz peak uniproc perform 900 mflop 264 mflop effect uniproc perform 340 mflop 150 mflop peak commun bandwidth 300 mbytessec 36 mbytessec latenc bandwidtheffect perform 088 024 tabl 22 characterist cray t3e900 ibm sp2 factor matrix wang4 use mump use estim effect uniprocessor perform comput 3 descript algorithm use section briefli describ main characterist algorithm use solver highlight major differ complet descript algorithm reader consult previou paper author algorithm amestoy et al 1999 amestoy et al 2000 li demmel 1998 li demmel 1999 algorithm describ comput tree whose node repres comput whose edg repres transfer data case multifront method mump step gaussian elimin perform dens frontal matrix node schur complement contribut block remain pass assembl parent node case supernod code superlu distribut memori version use rightlook formul comput factor block column correspond node tree immedi send data updat block column correspond ancestor tree code accept pivot order builtin capabl gener order base analysi pattern summat perform symbol howev present version mump symbol factor markedli less effici input order given sinc differ logic use case default order use mump approxim minimum degre amd amestoy davi duff 1996a default superlu multipl minimum degre mmd liu 1985 howev experi use minimum degre order consid amd order sinc code gener use subroutin mc47 hsl 2000 usual far quicker mmd produc symbol factor close produc mmd also use nest dissect order nd sometim use onmeti order meti karypi kumar 1998 sometim nest dissectionhaloamd order scotch pellegrini roman amestoy 1999 depend perform better particular problem addit sometim benefici preced order perform unsymmetr permut place larg entri diagon scale matrix diagon modulu one offdiagon modulu less equal one use mc64 code hsl perform preorder scale duff koster 1999 indic clearli done effect use preorder matrix discuss detail section 41 final mc64 use matric alway scale approach pivot order defin analysi symbol factor stage mump modulu prospect pivot compar largest modulu entri row accept greater threshold valu typic 0001 01 default valu 001 note although mump choos pivot diagon largest entri column might unavail pivot stage entri row fulli sum threshold pivot strategi common spars gaussian elimin help avoid excess growth size entri matrix factor directli reduc bound backward error prospect pivot fail test happen kept schur complement pass parent node eventu row entri column avail pivot root pivot chosen column thu numer factor respect threshold criterion cost increas size frontal matric caus work fillin forecast superlu approach static pivot strategi use keep pivot sequenc chosen analysi magnitud potenti pivot test threshold ffl 12 jjajj ffl machin precis jjajj norm less valu immedi set valu sign modifi entri use pivot correspond halfprecis perturb origin matrix entri result factor exact iter refin may need note iter refin obtain accur solut case test problem still occur extend precis bla li demmel bailey henri hida iskandar kahan kapur martin tung yoo 2000 could use 31 mump main parallel featur parallel within mump two level first use structur assembl tree exploit fact comput node ancestor descend independ initi parallel sourc tree parallel number leaf node reduc one root second level subdivis elimin oper block frontal matrix block give rise node parallel either row refer 1dnode parallel row column root refer 2dnode parallel node parallel depend size frontal matrix delay pivot known factor time therefor determin dynam tree node assign processor priori subassign block frontal matrix done dynam machin depend paramet mump control effici code design take account uniprocessor multiprocessor characterist comput dynam distribut schedul approach need precis descript perform characterist comput approach base static schedul pastix henon ramet roman 1999 machin depend paramet mump associ block size involv parallel block factor algorithm dens frontal matric main object maintain minimum granular effici exploit potenti processor provid suffici task exploit avail parallel target machin differ sever respect import one illustr tabl 22 found smaller granular task could use cray t3e ibm sp2 rel faster rate commun megaflop rate cray t3e ibm sp2 see tabl 22 say commun rel effici cray t3e dynam schedul major origin featur approach use mump critic part algorithm process associ tree node decid reassign work correspond partit row set socal worker process call node onedimension parallel node earlier version mump fix block size use partit row work distribut process start least load process load process determin amount work number oper alloc yet process determin cheapli sinc block size fix possibl process charg onedimension parallel node give addit work process alreadi load happen near leaf node tree sparsiti provid enough parallel keep process busi hand insuffici task might creat provid work idl process situat like occur close root tree new algorithm avail sinc version 41 mump block size onedimension partit dynam adjust process charg node earli process tree near leav give rel bigger block size reduc number worker process wherea close root tree block size automat reduc compens lack parallel assembl tree bound block size partit onedimension parallel node interv lower bound need maintain minimum task granular control volum messag upper bound interv less critic default chosen eight time lower bound use estim maximum size commun buffer factor larg dynam strategi partit distribut work onto processor could caus troubl larg number processor 128 case quit benefici take account global inform help local decis exampl one could restrict choic worker process set candid processor determin static analysi phase notion commonli use design static schedul algorithm henon et al 1999 could reduc overhead dynam schedul algorithm reduc increas commun volum increas number processor improv local decis tune paramet control block size 1d partit would easier estim memori requir factor would accur larg number processor perform softwar improv could thu expect featur avail current version 41 mump implement futur releas see ad featur one could address current limit mump approach see section 52 solut phase also perform parallel use asynchron commun forward elimin back substitut case forward elimin tree process leav root similar way factor back substitut requir differ algorithm process tree root leav pool readytobeactiv task use chang distribut factor gener factor phase henc type 2 3 node parallel also use solut phase 32 superlu main parallel featur superlu also use two level parallel although advantag taken node parallel block supernod pivot order fulli determin analysi phase assign block processor done static priori factor commenc 2d blockcycl layout use execut pipelin sinc sequenc predetermin matrix partit base notion unsymmetr supernod introduc demmel eisenstat gilbert li liu 1999 supernod defin matrix factor l supernod rang column l triangular block diagon full nonzero structur elsewher either full zero supernod partit use block partit row column dimens diagon block squar n supernod nbyn matrix n 2 block nonuniform size figur 31 illustr block partit offdiagon block may rectangular need full furthermor column block u necessarili row structur call dens subvector block u segment p process also arrang 2d mesh dimens blockcycl layout mean block j l u map onto process coordin process mesh factor block li j need process process row similarli block ui j need process process column partit map control user first user set maximum block size paramet symbol factor algorithm identifi supernod chop larg supernod smaller one size exceed paramet supernod may smaller paramet due sparsiti block defin supernod boundari supernod smaller maximum block size never larger experi shown good valu paramet ibm sp2 around 40 cray t3e around 24 second user set shape process grid 2 theta 3 3 theta 2 squar grid better perform expect rule thumb use cray t3e defin grid shapes4301204441 00130143 1global matrix5process mesh5 figur 31 2d blockcycl layout use superlu 2d map block column l resid one process name column process exampl figur 31 second block column l resid column process f1 4g process 1 own two nonzero block contigu global matrix main numer kernel involv numer factor block updat correspond rankk updat schur complement see figur 32 earlier version superlu comput base level 25 bla call level 2 bla routin gemv matrixvector product multipl vector segment matrix li k kept cach across multipl call extent mimic level 3 bla gemm matrixmatrix product perform howev differ level 25 level 3 still quit larg mani machin eg ibm sp2 motiv us modifi kernel follow way order use level 3 bla best perform distinguish two case correspond two shape ukj block ffl segment ukj height shown figur 32 sinc nonzero segment store contigu memori call gemm directli without perform oper zero ffl segment ukj differ height shown figur 32 b case first copi segment temporari work array lead zero pad necessari call gemm use li k instead ukj perform extra floatingpoint oper pad zero copi incur run time cost data must load cach anyway work storag bound maximum block size tunabl paramet exampl usual use theta 40 ibm sp2 24 theta 24 cray t3e depend matrix level 3 bla kernel improv uniprocessor factor time 20 40 ibm sp2 perform gain also observ cray t3e clear extra oper well offset benefit effici level 3 bla routin b uk ai j li k uk j uk figur 32 illustr numer kernel use superlu current factor algorithm two limit parallel explain exampl problem specul algorithm may improv futur follow matrix notat zero block left blank nonzero block mark box process own block ffl parallel sparsiti consid matrix 4by4 block map onto 2by2 process mesh660 1 although node 2 parent node 1 elimin tree associ process column 2 depend column 1 process 1 depend l block process 0 process 3 could start factor column 2 time process 0 factor column 1 process 1 start factor column 2 current algorithm requir column process factor column synchron therebi introduc idl time process 3 relax constraint allow diagon process 3 case factor diagon block send factor block offdiagon process use mpi isend even offdiagon process readi column would elimin artifici interprocess depend potenti reduc length critic path note kind independ come sparsiti also 2d processtomatrix map even interest studi would formal 2d task depend task graph perform optim schedul ffl parallel direct acycl elimin graph gilbert liu 1993 often refer elimin dag edag consid anoth matrix 6by6 block map onto 2by3 process mesh66664 column 1 3 independ elimin dag column process set f0 3g f2 5g could start factor column 1 3 simultan howev sinc process 2 also involv updat task block 5 associ step 1 algorithm give preced task step 1 task step 3 process 2 factor column 3 immedi may chang task preced give factor task later step higher prioriti updat task previou step former like critic path would exploit better task independ come elimin dag expect improv larg impact spars andor unsymmetr matric order give wide bushi elimin tree nest dissect triangular solut algorithm also design around distribut 2d data structur forward substitut proce bottom elimin tree root wherea back substitut proce root bottom algorithm base sequenti variant call inner product formul execut program complet messagedriven process selfschedul loop perform appropri local comput depend type messag receiv entir asynchron approach enabl larg overlap commun comput help overcom much higher commun comput ratio phase 33 first comment algorithm differ approach use level 3 bla perform elimin oper howev mump frontal matric alway squar possibl zero frontal matrix especi delay pivot matrix structur markedli asymmetr present implement take advantag sparsiti count measur assum frontal matrix dens shown amestoy puglisi 2000 one detect exploit structur asymmetri frontal matric new algorithm signific gain memori time perform factor obtain exampl use mump new algorithm number oper factor matric lhr71c twoton would reduc 30 37 respect approach test share memori multifront code amestoy duff 1993 hsl 2000 howev yet avail current version mump superlu advantag taken sparsiti block usual dens matrix block smaller use mump addit superlu use sophist data structur keep track irregular sparsiti thu uniprocessor megaflop rate superlu much wors mump perform penalti extent allevi reduct floatingpoint oper better exploit sparsiti rule thumb mump tend perform particularli well matrix structur close symmetr superlu better exploit asymmetri note even order input two code comput tree gener case differ case mump assembl tree gener mc47 use drive mump factor phase superlu direct acycl comput graph dag built implicitli figur 33 34 use vampir trace nagel arnold weber hopp solchenbach 1996 illustr typic parallel behaviour approach trace correspond zoom middl factor phase matrix bbmat 8 processor cray t3e black area correspond time spent commun relat mpi call line two process correspond one messag transfer plot see superlu distinct phase local comput interprocess commun wherea mump hard distinguish process perform comput transfer messag due asynchron schedul algorithm use mump may better chanc overlap commun comput 4 impact preprocess numer issu section first studi impact solver preprocess matrix preprocess first use row column permut permut larg entri onto diagon section 41 report compar structur numer impact preprocess phase perform accuraci solver phase symmetr order minimum degre nest dissect use studi rel influenc order perform solver section 42 also comment rel cost analysi phase two solver 41 use preorder place larg entri onto diagon cost analysi phase duff koster 1999 develop algorithm permut spars matrix diagon entri larg rel offdiagon entri also written comput code mc64 avail hsl 2000 implement algorithm use option 5 mc64 maxim product modulu diagon entri scale permut matrix diagon entri modulu one offdiagon modulu less equal one import preorder scale clear mump limit amount numer pivot factor increas overal cost factor superlu expect permut even crucial reduc amount small pivot modifi set 12 jjajj mc64 code duff koster 1999 quit effici normal requir littl time rel matrix factor even latter execut mani processor mc64 run one processor result section show alway case moreov matric unsymmetr symmetr nearli symmetr structur common problem class problem mc64 perform unsymmetr permut tend destroy symmetri pattern sinc code use symmetr pattern sparsiti order see section 42 mump use one also symbol numer factor overhead markedli unsymmetr pattern high convers initi matrix unsymmetr exampl lhr71c unsymmetr permut may actual help increas structur symmetri thu give second benefit subsequ matrix factor show effect use mc64 exampl tabl 41 tabl 44 illustr rel cost main step analysi phase mc64 use preprocess matrix see tabl 41 unsymmetr matric lhr71c twoton mc64 realli need mump superlu factor matric effici matric zero diagon static pivot approach use superlu unless zero made nonzero fillin larg enough perturb process process process process process process process 6 108 108 5 process 7 108 mpi applic 905 90 895 89 figur 33 illustr asynchron behaviour mump factor phase process 0 process 1 process process 3 process 4 process 5 process 6 process 7 mpi vtapi comm 932 93 928 figur 34 illustr rel synchron behaviour superlu factor phase matrix solver order strsym nonzero flop factor bbmat mump amd 054 461 415 fidapm11 mump amd 100 161 97 garon2 mump amd 100 24 03 mixtank mump amd 100 391 644 twoton mump amd 028 2350 12211 wang4 mump amd 100 116 105 tabl 41 impact permut larg entri onto diagon use mc64 size factor number oper estim given analysi enough memori perform factor strsym denot structur symmetri order factor factor nearbi matrix obtain case mump dramat higher fillin obtain without mc64 make also necessari use mc64 mump main benefit use mc64 structur numer permut matrix fact larger structur symmetri see column 4 tabl 41 symmetr permut obtain permut matrix effici preserv sparsiti superlu benefit similar way symmetr comput symmetr permut base assumpt even superlu preserv better asymmetr structur factor perform symbol analysi direct acycl graph exploit asymmetri factor phase compar exampl result mump superlu matric lhr71c mixtank twoton matrix iter bbmat tabl 42 illustr converg iter refin use mc64 also improv qualiti factor numer behaviour factor phase reduc number step iter refin requir reduc backward error machin precis illustr tabl 42 show number step iter refin requir reduc componentwis rel backward error arioli demmel duff 1989 machin precis 22 theta 10 gamma16 cray t3e iter refin stop either requir accuraci reach converg rate slow berr decreas least factor two true error report jjx true jj tabl illustr impact use mc64 qualiti matrix solver without iter ref iter refin berr bbmat mump 74e11 13e06 2 32e16 30e09 lhr71c mump enough memori superlu enough memori mixtank mump 19e12 48e09 2 59e16 14e11 twoton mump 50e07 13e05 3 13e15 21e11 matrix solver without iter ref iter refin berr bbmat mump 12e11 65e08 2 27e16 35e09 lhr71c mump 11e05 99e00 3 32e13 10e00 mixtank mump 48e12 23e08 2 42e16 40e11 twoton mump 32e13 16e10 2 16e15 23e11 tabl 43 comparison numer behaviour backward error berr forward error err solver nb indic number step iter refin initi solut obtain solver prior iter refin addit show thank numer partial pivot initi solut almost alway accur mump superlu usual markedli observ confirm larger number test matric tabl 43 stop criterion appli run run tabl 42 case mump mc64 also result reduct number offdiagon pivot number delay pivot exampl matrix invextr1 number offdiagon pivot drop 1520 109 number delay pivot drop 2555 42 one also see tabl 42 eg bbmat mc64 alway improv numer accuraci solut obtain superlu expect see matric fairli symmetr pattern eg matrix fidapm11 tabl 41 use mc64 lead signific decreas symmetri solver result signific increas number oper factor addit recollect time spent mc64 domin analysi time either solver see tabl 44 even matric fidapm11 invextr1 provid gain subsequ step thu solver default use mc64 fairli symmetr matric practic default option mump packag mc64 automat invok structur symmetri found less 05 superlu zero diagon numer issu must also consid automat decis analysi phase difficult final compar figur 41 time spent two solver analysi phase reorder base amd mc64 invok sinc time spent bbmat ecl32 invextr1 fidapm11 mixtank rma10 wang42610second mump figur 41 time comparison analysi phase mump superlu mc64 preprocess use amd order use amd similar case give good estim cost differ matrix solver preprocess total mc64 amd bbmat mump amd 47 30 mc64amd 72 21 31 mixtank mump amd 32 08 twoton mump amd 127 87 tabl 44 influenc permut larg entri onto diagon use mc64 time second analysi phase mump superlu analysi phase two solver note superlu current tie specif order code take advantag inform avail order algorithm tighter coupl order case mump amd reduc analysi time superlu howev analysi phase superlu asymmetr structur need factor comput direct acycl graph gilbert liu 1993 unsymmetr matrix must built map onto processor mump main data structur handl analysi assembl tree produc directli byproduct order phase data structur introduc phase dynam schedul use factor simpl massag tree partial map comput task onto processor perform analysi 42 use order preserv sparsiti matric mc64 use show tabl 45 impact choic symmetr permut fillin floatingpoint oper factor observ amestoy et al 1999 use nest dissect significantli improv perform mump see superlu also although lesser extent benefit use nest dissect order examin influenc order perform section 5 also notic order superlu exploit asymmetri matrix somewhat better mump see bbmat structur symmetri 053 expect asymmetri problem better exploit mump approach describ amestoy puglisi 2000 implement matrix order solver nz lu flop bbmat amd mump 461 415 412 340 nd mump 358 257 nd mump 248 209 nd mump 162 81 mixtank amd mump 391 644 nd mump 196 132 tabl 45 influenc symmetr sparsiti order fillin floatingpoint oper factor unsymmetr matric mc64 use 5 perform analysi gener matric 51 perform numer phase section compar perform studi behaviour numer phase factor solv two solver sake clariti report result best term factor time sparsiti order approach best order mump differ superlu result order provid mean result nest dissect minimum degre order given illustr differ sensit code choic order note even order given solver usual perform number oper gener superlu perform fewer oper mump exploit better asymmetri matrix although execut time less mump level 3 bla effect although result often matrix depend tri much possibl identifi gener properti two solver point maximum dimens unsymmetr test matric 120750 see tabl 21 511 studi factor phase show tabl 51 factor time solver smaller matric report tabl 52 result 64 processor observ mump usual faster superlu significantli small number processor believ two reason first mump handl symmetr regular data structur better superlu mump use level 3 bla kernel bigger block use within superlu result megaflop rate mump one processor averag twice superlu factor also evid result smaller test problem tabl 52 result 3d grid problem section 6 note even matrix twoton perform three time fewer oper mump mump 25 time faster superlu four processor small number processor also notic superlu alway fulli benefit reduct number oper due use nest dissect order see bbmat superlu use 4 processor furthermor one notic matric structur asymmetr superlu much less scalabl mump exampl matrix lhr71c tabl 52 speedup 25 83 obtain superlu mump respect due two parallel limit current superlu algorithm describ section 32 first superlu fulli exploit parallel elimin dag second pipelin mechan fulli benefit sparsiti factor block column factor implement also explain superlu fulli benefit case mump better balanc tree gener nest dissect order see order significantli influenc perform code see result matric bbmat ecl32 particular mump gener outperform superlu even larg number processor nest dissect order use hand use minimum degre order superlu faster mump larg number processor also see unsymmetr problem neither solver provid enough parallel benefit use 128 processor except matrix ecl32 use amd order requir flop factor superlu continu decreas factor time 512 processor lack larg unsymmetr system give us data point regim one might expect independ order 2d distribut use superlu provid better scalabl henc eventu better perform larg number processor mix 1d 2d distribut use mump analys scalabl solver consid three dimension regular grid problem section 6 matrix ord solver number processor bbmat amd mump 457 240 165 137 119 112 91 126 superlu 682 231 133 91 67 57 47 61 58 mixtank nd mump 408 130 78 56 44 39 42 42 54 twoton mc64 mump 403 226 186 147 144 143 140 143 tabl 51 factor time second larg test matric cray t3e indic enough memori matrix order solver number processor fidapm11 amd mump 316 117 84 65 57 57 lhr71c mc64amd mump 133 43 29 17 15 16 rma10 amd mump 81 31 22 21 20 21 wang4 amd mump 306 111 70 52 43 39 563 194 139 79 58 56 tabl 52 factor time second small test matric cray t3e indic enough memori better understand perform differ observ tabl 51 52 identifi main characterist solver show tabl 53 averag commun volum speed commun depend much number size messag also indic maximum size messag averag number messag overlap commun comput mump use fulli asynchron commun send receiv use nonblock send synchron schedul approach use superlu also enabl overlap commun comput matrix ord solver number processor max vol mess max vol mess max vol mess bbmat amd mump 49 44 3240 33 63 1700 29 20 2257 nd mump 22 7 2214 28 43 1441 15 48 3228 fidapm11 amd mump 25 28 3000 24 22 1471 24 6 1323 mixtank nd mump 35 twoton mc64 mump 88 61 5076 29 139 4144 21 tabl 53 maximum size messag max mbyte averag volum commun vol mbyte number messag per processor mess larg matric factor result tabl 53 difficult make definit comment averag volum commun overal broadli compar sometim mump sometim superlu lower volum occasion signific amount howev although averag volum messag 64 processor compar solver one two order magnitud differ averag number messag therefor averag size messag due much larger number messag involv fanout approach superlu compar multifront approach mump note mump number messag includ messag one integ requir dynam schedul algorithm updat load process averag volum commun per processor solver depend much number processor superlu increas number processor gener decreas commun volum per processor alway case mump note ad global inform local dynam schedul algorithm mump help increas granular level 2 node subtask without lose parallel see section 31 thu result decreas averag volum commun larg number processor 512 studi solv phase alreadi discuss section 41 differ numer behaviour two solver show gener superlu involv step iter refin mump obtain accuraci solut section focu time spent obtain solut appli enough step iter refin ensur componentwis rel backward error berr less p gamma8 step iter refin involv forward backward solv also matrixvector product origin matrix mump user provid input matrix gener distribut format amestoy et al 1999 function use parallel matrixvector product superlu parallel matrixvector product easier input matrix duplic processor tabl 54 report time perform one solut step use factor matrix solv necessari berr greater p time improv solut use iter refin line ir superlu except ecl32 mixtank requir iter refin one step iter refin requir alway enough reduc backward error mump iter refin requir matrix invextr1 backward error alreadi close one processor 4 8 processor step iter refin requir berr initi solut alreadi equal case time report row ir correspond time perform comput backward error first observ compar exampl tabl 51 54 small number processor less 8 solv phase almost two order magnitud less costli factor larg number processor solv phase rel less scalabl factor phase differ drop one order magnitud applic larg number solv might requir per factor could becom critic perform might address futur show solut time smaller matric tabl 55 run iter refin perform report tabl 54 55 would appear suggest regular structur matrix factor gener factor phase mump respons faster solv phase superlu 256 processor 512 processor solv phase superlu sometim faster mump although case fastest solv time record mump usual fewer number processor cost iter refin significantli increas cost obtain solut superlu static pivot like iter refin requir obtain accur solut numer difficult matric see bbmat twoton mump use partial pivot factor reduc number matric iter refin requir set invextr1 requir iter refin solver use mc64 preprocess matrix also consid reduc number step iter refin even avoid need use case see section 41 matrix order solver number processor bbmat amd mump 053 038 031 032 032 036 040 056 twoton mc64 mump 103 092 097 098 098 103 113 141 tabl 54 solv time second larg matric cray t3e show time spent improv initi solut use iter refin indic enough memori matrix ord solver number processor tabl 55 solv time second small matric cray t3e 52 memori usag section studi memori use factor function solver use number processor see tabl 56 want first point dynam schedul approach threshold pivot use mump analysi phase fulli predict space requir processor upper bound therefor use memori alloc static task map approach use superlu memori use predict analysi phase section compar memori actual use solver factor phase includ real integ commun buffer storag initi matrix howev includ seen amestoy et al 1999 input matrix also provid gener distribut format handl effici solver option avail mump superlu initi matrix current duplic processor 7 matrix order solver number processor avg max avg max avg max bbmat amd mump 147 176 52 nd mump 114 118 44 53 28 35 43 44 nd mump 132 139 39 44 25 28 28 17 22 mixtank nd mump 84 87 29 31 19 21 twoton mc64 mump 167 180 57 67 42 tabl memori use factor megabyt per processor notic tabl 56 signific reduct memori requir increas number processor also see gener superlu usual requir less memori mump although less appar mani processor use show better memori scalabl mump one observ littl differ 7 mump note storag report still includ anoth intern copi initi matrix distribut arrowhead form necessari assembl oper multifront algorithm averag maximum memori usag show algorithm well balanc superlu better two note memori scalabl critic global address platform parallel increas total memori use pure distribut machin t3e main factor remain memori use per processor allow larg problem solv enough processor avail 6 perform analysi 3d grid problem analys understand scalabl solver report section result obtain 11point discret laplacian oper threedimension nx ny nz grid problem consid set 3d cubic nxnynz rectangular nx nx4 nx8 grid nest dissect order use size grid use number oper time report tabl 61 increas number processor tri much possibl maintain constant number oper per processor keep much possibl shape grid possibl satisfi constraint thu number oper per processor complet constant nproc grid size ldl factor lu factor flop time flop time flop time cubic grid nest dissect 4 36 134 199 268 281 268 533 rectangular grid nest dissect 128 208 52 26 2431 274 4858 536 4856 607 tabl 61 factor time second cray t3e lu factor perform mumpsun superlu ldl mumpssym sinc test matric symmetr use mump comput either ldl factor refer mumpssym lu factor refer mumpsun comput lu factor note given matrix unsymmetr solver superlu mumpsun perform roughli twice mani oper mumpssym overcom problem number oper per processor nonconst first report figur 61 62 megaflop rate per processor three approach cubic rectangular grid respect context megaflop rate meaning grid problem number oper almost ident mumpsun superlu see tabl 61 thu correspond absolut perform approach use given problem first notic 8 processor independ grid shape mumpsun twice fast superlu also much higher megaflop rate mumpssym 128 processor rectangular cubic grid three solver similar megaflop rate per processor figur 63 64 show parallel effici cubic rectangular grid respect effici solver p processor comput ratio megaflop rate per processor p processor megaflop rate 1 processor term effici superlu gener effici cubic grid mumpsun even rel small number processor mumpssym rel effici mumpsun mumpssym effici compar superlu larg number processor superlu significantli effici mumpsun peak ratio method reach cubic grid 128 processor superlu three two time effici mumpsun mumpssym respect final report tabl 62 quantit evalu overhead due parallel cubic grid use analysi tool vampir nagel et al 1996 row comput report percentag time spent numer factor mpi call idl time due commun synchron report row overhead tabl nproc grid size mumpssym mumpsun superlunx36 comput 69 76 87 overhead 31 24 13nx46 comput 67 69 75 overhead 33 31 25nx57 comput 50 36 56 overhead 50 64 44 tabl 62 percentag factor time cubic grid spent comput overhead due commun synchron tabl 62 show superlu less overhead either version mump also observ better parallel behaviour mumpssym respect mumpsun analys processor rate mumpssym mumpsun figur 61 megaflop rate per processor cubic grid nest dissect processor rate mumpssym mumpsun figur 62 megaflop rate per processor rectangular grid nest dissect 040812 processor effici mumpssym mumpsun figur 63 parallel effici cubic grid nest dissect 12802061processor effici mumpssym mumpsun figur 64 parallel effici rectangular grid nest dissect amestoy et al 2000 mainli due fact node level parallel provid rel parallel symmetr context 7 conclud remark paper present detail analysi comparison two stateofth art parallel spars direct solversa multifront solver mump supernod solver superlu analysi base experi use massiv parallel distributedmemori machineth cray t3e dozen matric differ applic analysi address effici solver mani respect includ role preorder step cost accuraci solut sparsiti preserv total memori requir amount interprocessor commun time factor triangular solv scalabl found solver strength weak summar observ follow ffl solver benefit numer preorder scheme implement mc64 although superlu benefit greater extent mump mump help reduc number offdiagon pivot number delay pivot superlu may reduc need small diagon perturb number iter refin howev sinc permut asymmetr may destroy structur symmetri origin matrix caus fillin oper tend introduc greater perform penalti mump superlu although recent work amestoy puglisi 2000 might affect conclus default mump use mc64 fairli symmetr matric ffl mump usual provid better initi solut due effect dynam versu static pivot one step iter refin superlu usual obtain solut level accuraci ffl solver accept input fillin reduc order appli symmetr row column mump perform better nest dissect minimum degre exploit better tree parallel provid nest dissect order wherea superlu exploit level parallel parallel effici less sensit differ order ffl given order superlu preserv sparsiti asymmetri l u factor better superlu usual requir less memori mump smaller number processor 64 processor mump requir 2530 memori averag ffl although total volum commun compar solver mump requir mani fewer messag especi larg number processor differ two order magnitud partli intrins algorithm multifront versu fanout partli due 1d mump versu 2d superlu matrix partit ffl mump usual faster factor solv phase speed penalti partli come code complex order preserv irregular sparsiti pattern partli due commun messag processor superlu show better scalabl 2d partit scheme better job keep processor busi despit fact introduc messag said introduct start exercis intent compar wider rang spars code howev demonstr preced section task conduct comparison complex feel though experi gain task use extend comparison futur follow tabl summar major characterist parallel spars direct code awar clear descript term use tabl given heath ng peyton 1991 code techniqu scope avail refer capss multifront spd wwwnetliborgscalapack heath raghavan 1997 mump multifront symun wwwenseeihtfrapomump amestoy et al 1999 pastix fanin spd see caption x henon et al 1999 pspase multifront spd wwwcsumnedumjoshipspas gupta karypi kumar 1997 spool fanin symun wwwnetliborglinalgspool ashcraft grime 1999 superlu fanout un wwwnerscgovxiaoyesuperlu li demmel 1999 fanout un wwwcsucsbeduresearch fu jiao yang 1998 wsmp z multifront sym ibm product gupta 2000 tabl 71 distribut memori code x wwwdeptinfolabriubordeauxfrrametpastix use qr storag static accommod lu fillin z object code ibm avail numer pivot perform code techniqu scope avail refer gspar interpret un grund borchardt grund horn 1997 multifront un wwwcseclrcacukactivityhsl amestoy duff 1993 multifront qr rect wwwcseclrcacukactivityhsl amestoy duff puglisi 1996b panelllt leftlook spd ng ng peyton 1993 pardiso leftright look un schenk schenk gartner fichtner 2000 psldlt leftlook spd sgi product rothberg 1994 psldu leftlook un sgi product rothberg 1994 leftlook un wwwnerscgovxiaoyesuperlu demmel et al 1999 tabl 72 share memori code object code sgi avail acknowledg want thank jame demmel jacko koster rich vuduc help discuss grate chiara puglisi comment earli version articl help present also want thank john reid comment first version paper r unsymmetr multifront lu factor fulli asynchron multifront solver use distribut dynam schedul spool objectori spars matrix librari parallel numer method larg system differentialalgebra equat industri applic algorithm permut larg entri diagon spars matrix appear siam journal matrix analysi applic wsmp watson spars matrix packag part direct solut symmetr spars system version 10 httpwww map schedul algorithm parallel spars fanin numer factor httpwww make spars gaussian elimin scalabl static pivot scalabl spars direct solver use static pivot hybrid nest dissect halo approxim minimum degre effici spars matrix order effici spars choleski factor distributedmemori multiprocessor tr parallel algorithm spars linear system elimin structur unsymmetr spars italicluital factor supernod choleski factor algorithm sharedmemori multiprocessor modif minimumdegre algorithm multipl elimin approxim minimum degre order algorithm highli scalabl parallel algorithm spars matrix factor effici spars lu factor partial pivot distribut memori architectur supernod approach spars partial pivot design use algorithm permut larg entri diagon spars matric asynchron parallel supernod algorithm spars gaussian elimin make spars gaussian elimin scalabl static pivot precondit highli indefinit nonsymmetr matric algorithm permut larg entri diagon spars matrix fulli asynchron multifront solver use distribut dynam schedul map schedul algorithm parallel spars fanin numer factor ctr laura grigori xiaoy li new schedul algorithm parallel spars lu factor static pivot proceed 2002 acmiee confer supercomput p118 novemb 16 2002 baltimor maryland mark baertschi xiaoy li solut threebodi problem quantum mechan use spars linear algebra parallel comput proceed 2001 acmiee confer supercomput cdrom p4747 novemb 1016 2001 denver colorado olaf schenk klau grtner solv unsymmetr spars system linear equat pardiso futur gener comput system v20 n3 p475487 april 2004 patrick r amestoy iain duff jeanyv lexcel xiaoy li impact implement mpi pointtopoint commun perform two gener spars solver parallel comput v29 n7 p833849 juli xiaoy li jame w demmel superludist scalabl distributedmemori spars direct solver unsymmetr linear system acm transact mathemat softwar tom v29 n2 p110140 june anshul gupta recent advanc direct method solv unsymmetr spars system linear equat acm transact mathemat softwar tom v28 n3 p301324 septemb 2002 timothi davi column preorder strategi unsymmetricpattern multifront method acm transact mathemat softwar tom v30 n2 p165195 june 2004 patrick r amestoy iain duff stphane pralet christof vmel adapt parallel spars direct solver architectur cluster smp parallel comput v29 n1112 p16451668 novemberdecemb