data mine spars grid use simplici basi function recent present new approach 18 classif problem aris data mine base regular network approach contrast method employ ansatz function associ data point use grid usual highdimension featur space minim process cope curs dimension employ spars grid 49 thu ohn1nd1 instead ohnd grid point unknown involv denot dimens featur space give mesh size use spars grid combin techniqu 28 classif problem discret solv sequenc convent grid uniform mesh size dimens spars grid solut obtain linear combin contrast former work dlinear function use appli linear basi function base simplici discret allow handl dimens algorithm need less oper per data pointw describ spars grid combin techniqu classif problem give implement detail discuss complex algorithm turn method scale linearli number given data point final report qualiti classifi built new method data set 10 dimens turn new method achiev correct rate competit best exist method b introduct data mine process nding pattern relat trend larg data set exampl rang scien tic applic like postprocess data medicin evalu satellit pictur nancial commerci applic eg assess credit risk select custom advertis campaign letter overview data mine variou task approach see 5 12 paper consid classic problem aris data mine given set data point ddimension featur space togeth class label data classier must construct allow predict class newli given data point futur decis make wide use approach besid other decis tree induct rule learn adapt multivari regress spline neural network support vector machin interestingli techniqu interpret framework regular network 21 approach allow direct descript import neural network also allow equival descript support vector machin nterm approxim scheme 20 classic data interpret scatter data approxim problem certain addit regular term highdimension space 18 present new approach classic problem also base regular network approach contrast method employ mostli global ansatz function associ data point use independ grid associ local ansatz function minim process similar numer treatment partial dierenti equat uniform grid would result oh denot dimens featur space give mesh size therefor complex problem would grow exponenti encount curs dimension probabl reason convent gridbas techniqu use data mine howev socal spars grid approach allow cope complex problem extent method origin develop solut partial dierenti equat 2 8 28 49 use success also integr equat 14 27 interpol approxim 3 26 39 42 eigenvalu problem 16 integr problem 19 inform base complex commun also known hyper bolic cross point idea even trace back 41 ddimension problem spars grid approach employ oh 1 point di cretiz accuraci approxim howev nearli good convent full grid method provid certain addit smooth requir fulll thu spars grid discret method employ also higherdimension problem curs dimension convent full grid method affect spars grid much less paper appli spars grid combin techniqu 28 classic problem regular network problem discret solv certain sequenc convent grid uniform mesh size coordin direct contrast 18 dlinear function stem tensorproduct approach use appli linear basi function base simplici discret comparison approach allow process dimens need less oper per data point spars grid solut obtain solut dierent grid linear combin thu classier build spars grid point data point discuss complex method give method scale linearli number instanc ie amount data classi therefor method well suit realist data mine applic dimens featur space moder high eg preprocess step amount data larg furthermor qualiti classier build new method seem good consid standard test problem uci repositori problem huge synthet data set 10 dimens turn new method achiev correct rate competit best exist method note combin method simpl use parallel natur straightforward way remaind paper organ follow section 2 describ classic problem framework regular network minim qua dratic function discret featur space deriv associ linear problem focu gridbas discret techniqu introduc spars grid combin techniqu classic problem discuss properti furthermor present new variant base discret simplic discuss complex aspect section 3 present result numer experi conduct spars grid combin method demonstr qualiti classier build new method compar result one 18 one obtain dierent form svm 33 nal remark conclud paper 2 problem classic data interpret tradit scatter data approxim problem certain addit regular term contrast convent scatter data approxim applic encount quit highdimension space end approach regular network 21 give good framework approach allow direct descript import neural network also allow equival descript support vector machin nterm approxim scheme 20 consid given set alreadi classi data train rg assum data obtain sampl unknown function f belong function space v dene r sampl process disturb nois aim recov function f given data good possibl clearli illpos problem sinc innit mani solut possibl get wellpos uniqu solvabl problem assum knowledg f end regular theori 43 47 impos addit smooth constraint solut approxim problem regular network approach consid variat problem min f2v c denot error cost function measur interpol error f smooth function must well dene rst term enforc close f data second term enforc smooth f regular paramet balanc two term typic exampl 2 r denot gradient laplac oper valu chosen accord crossvalid techniqu 13 22 37 44 principl structur risk minim 45 note nd exactli type formul case scatter data approxim method see 1 31 regular term usual physic motiv 21 discret restrict problem nite dimension subspac function f replac ansatz function f j g n span vn prefer form basi vn coecient f j g n j1 denot degre freedom note restrict suitabl chosen nitedimension subspac involv addit regular regular discret depend choic vn remaind paper restrict choic given linear oper p way obtain minim problem feasibl linear system thu minim fn nite dimension space vn plug 2 4 obtain dierenti respect k k k equival matrix notat end linear system c squar n n matrix entri c rectangular n matrix entri b vector contain data label length unknown vector contain degre freedom j length n depend regular oper obtain differ minim problem vn exampl use gradient fn regular express 1 obtain poisson problem addit term resembl interpol problem natur boundari condit partial dierenti equat neumann condit discret 2 give us linear system 7 c correspond discret laplacian obtain classier fn solv system 22 grid base discret approxim yet specic nite dimension subspac vn type basi function want use contrast convent data mine approach work ansatz function associ data point use certain grid attribut space determin classier help grid point similar numer treatment partial dierenti equat reason simplic remaind paper restrict ourself case x 0 1 situat alway reach proper rescal data space convent nite element discret would employ equidist grid n mesh size coordin direct n renement level follow alway use gradient regular express 3 let j denot nite element method piecewis dlinear ie linear dimens test trialfunct nj x grid would give nj nj x variat procedur 4 6 would result discret linear system size matrix entri correspond 7 note fn live space vn spanf nj discret problem 8 might principl treat appropri solver like conjug gradient method multigrid method suitabl ecient iter method howev direct applic nite element discret solut result linear system appropri solver clearli possibl ddimension problem larger four number grid point order oh best case number oper order encount socal curs dimension complex problem grow exponenti least 4 reason valu n aris system store solv even largest parallel comput today 23 spars grid combin techniqu therefor proceed follow discret solv problem certain sequenc grid l l 1 l uniform mesh size h tth coordin direct grid may possess dierent mesh size dierent coordin direct end consid grid l twodimension case grid need combin formula level 4 shown figur 1 nite element approach piecewis dlinear test trial function lj x grid l would give f l l lj lj x variat procedur 4 6 would result discret system l matric unknown vector solv c figur 1 combin techniqu level two dimens problem feasibl method end use diagon precondit conjug gradient algorithm also appropri multigrid method partial semi coarsen appli discret solut f l contain space piecewis dlinear function grid l note problem substanti reduc size comparison 8 instead one problem size nd deal problem size dimv l moreov problem solv independ allow straightforward parallel coars grain level see 23 also simpl eectiv static load balanc strategi avail 25 final linearli combin result f l lj lj x dierent grid l follow f c result function f c n live spars grid space space dimv span piecewis dlinear hierarch tensor product basi see 8 note summat discret function dierent space v l 13 involv dlinear interpol resembl transform represent hierarch basi detail see 24 28 29 howev never explicitli assembl function f c keep instead solut f l dierent grid l aris combin formula linear oper f f c easili express mean combin figur 2 twodimension spars grid left threedimension spars grid act directli function f l ie ff c l 1 l nd 1 q ff l therefor want evalu newli given set data point f test evalu set form combin associ valu f l accord 13 evalu dierent f l test point done complet parallel summat need basic allreducegath oper second order ellipt pde model problem proven combin solut f c n almost accur full grid solut fn ie discret error jje c provid slightli stronger smooth requir f full grid approach hold need seminorm 1 bound furthermor seri expans error necessari combin techniqu exist shown pde model problem 10 combin techniqu one variou method solv problem spars grid note exist also nite dierenc 24 38 galerkin nite element approach 2 8 9 work directli hierarch product basi spars grid combin techniqu conceptu much simpler easier implement moreov allow reus standard solver dierent subproblem straightforwardli paralleliz 24 simplici basi function far mention dlinear basi function base tensorproduct approach case present detail 18 grid combin techniqu linear basi function base simplici discret also possibl use socal kuhn triangul 15 32 rectangular block see figur 3 summat discret function dierent space l 13 involv linear interpol tabl 1 complex storag assembl matrixvector multipl dierent matric aris combin method one grid l discret approach c l g l store togeth one matrix structur dlinear basi function linear basi function l b l storag o3 n o3 n o2 o2 assembl o3 n od 2 2d od 2 o2 mvmultipl o3 n o3 n o2 o2 figur 3 kuhn triangul threedimension unit cube theroet properti variant spars grid techniqu still investig detail howev result present section 3 warrant use see slightli wors result linear basi function dlinear basi function believ new approach result approxim order sinc new variant combin techniqu overlap support ie region two basi function nonzero greatli reduc due use simplici discret complex scale signicantli better concern cost assembl storag nonzero entri spars popul matric 8 see tabl 1 note gener oper p complex c l scale o2 n choic zeroentri aris need consid reduc complex iti see tabl 1 right column c l actual iter solut process diagon precondit conjug gradient method scale independ number data point approach note howev storag run time complex still depend exponenti dimens present due limit memori modern workstat 512 mbyte 2 gbyte therefor deal case 8 dlinear basi function 11 linear basi function decomposit matrix entri sever comput parallel environ would permit dimens 3 numer result appli approach dierent test data set use synthet data real data practic data mine applic data set rescal 0 1 evalu method give correct rate test data set avail tenfold crossvalid result otherwis detail criti figur 4 spiral data set spars grid level 5 top left 8 bottom right cal discuss evalu qualiti classica tion algorithm see 13 37 31 twodimension problem rst consid synthet twodimension problem small set data correspond certain structur 311 spiral rst exampl spiral data set propos alexi wieland mitr corp 48 194 data point describ two intertwin spiral see figur 4 sure artici problem appear practic ap plicat howev serv hard test case new data mine algorithm known neural network sever problem data set neural network separ two spiral 40 tabl 2 give correct rate achiev leaveoneout crossvalid method ie 194fold cross valid best test correct achiev level 8 8918 comparison 7720 40 figur 4 show correspond result obtain spars grid combin method level 5 8 level 7 two spiral clearli detect resolv note 1281 grid point contain spars grid level 8 2817 spars grid point shape two reconstruct spiral get smoother tabl 3 result ripley data set linear basi dlinear basi best possibl level tenfold test test data test data linear dlinear 9 877 00015 901 909 911 910 level train correct test correct 9 00006 10000 8814 tabl 2 leaveoneout crossvalid result spiral data set reconstruct get precis 312 ripley data set taken 36 consist 250 train data 1000 test point data set gener synthet known exhibit 8 error thu better test correct 92 expect sinc train test data proceed follow first use train set determin best regular paramet per tenfold crossvalid best test correct rate correspond given dierent level n rst two column tabl 3 comput spars grid classier 250 train data column three tabl 3 give result classier previous unknown test data set see method work well alreadi level 4 sucient obtain result 914 reason sure rel simplic data see figur 5 hyperplan enough separ class quit properli also see much need use higher level contrari even overt eect visibl figur 5 column 4 show result 18 achiev almost result dlinear function see kind result could possibl sophist strategi determ give last two column tabl 3 test correct achiev best possibl end comput discret valu spars grid classier 250 data point evalu test set pick best result clearli see much dierenc indic approach determin valu train set crossvalid work well almost result linear dlinear basi function note test correct figur 5 ripley data set combin techniqu linear basi function left level 4 right level 8 906 911 achiev 36 35 respect data set 32 6dimension problem 321 bupa liver bupa liver disord data set irvin machin learn databas repositori 6 consist 345 data point 6 featur selector eld use split data 2 set 145 instanc 200 instanc respect test data therefor report tenfold crossvalid result compar dlinear result 18 two best result 33 therein introduc smooth support vector machin ssvm classic support vector machin svm jjjj 2 11 46 result given tabl 4 expect spars grid combin approach linear basi function perform slightli wors linear approach best test result 6960 level 4 new variant spars grid combin techniqu perform slightli wors ssvm wherea dlinear variant perform slighli better support vector machin note result svm approach like support vector machin use 1norm approach svm jjjj 1 report somewhat wors 33 tabl 4 result bupa liver disord data set linear dlinear comparison method level 1 10fold train correct 0012 7600 0020 7600 svm 33 10fold test correct 6900 6787 ssvm svm jjjj 2level 2 10fold train correct 0040 7613 010 7749 7037 7057 10fold test correct 6601 6784 7033 6986 level 3 10fold train correct 0165 7871 0007 8428 10fold test correct 6641 7034 level 4 10fold train correct 0075 9201 00004 9027 10fold test correct 6960 7092 322 synthet massiv data set 6d measur perform massiv data set produc datgen 34 6dimension test case 5 million train point 20 000 point test use call datgen r1 x0100ro0100ro0100ro o5020000 p e015 result given tabl 5 note alreadi level 1 test correct 90 achiev 001 main observ test case concern execut time measur pentium iii 700 mhz machin besid total run time also give cpu time need comput matric l see linear basi function realli huge data set 5 million point process reason time note 50 comput time spent data matrix assembl importantli execut time scale linearli number data point latter also case dlinear func tion mention approach need oper per data point result much longer execut time compar also tabl 5 especi assembl data matrix need 96 total run time variant present exampl linear basi approach 40 time faster dlinear approach renement level eg level 2 need 17 minut linear case 11 hour dlinear case higher dimens factor even larger 33 10dimension problem 331 forest cover type forest cover type dataset come uci kdd archiv 4 also use 30 approach similar follow consist cartograph variabl meter cell forest cover type pre dict 12 origin measur attribut result 54 attribut data set besid 10 quantit variabl 4 binari wilder area 40 binari soil type variabl use quantit variabl class label 7 valu sprucefir lodgepol pine ponderosa pine cottonwoodwillow aspen douglasr krummholz like 30 report result classi cation ponderosa pine 35754 instanc total 581012 sinc far less 10 instanc belong ponderosa pine weigh class factor 5 ie ponderosa pine class valu 5 other 1 treshold valu separ class 0 data set randomli separ train set test set evalu set similar size 30 result 6 dimens could report tabl 6 present result 6 dimens chosen ie dimens 14567 10 10 dimens well give overview behavior sever present level n overal correct result correct result ponderosa pine correct result class three valu give result evalu set chosen see tabl 6 alreadi level 1 test correct 9395 ponderosa pine 6 dimension version higher renement level give better result result 9352 evalu set almost correspond test correct note 30 correct rate 8697 achiev evalu set usag 10 dimens improv result slightli get 9381 evalu result level 1 higher renement level improv result data set note forest cover exampl sound enough exampl classic might strike forest scientist amusingli superci known year dynam forest growth domin eect speci present given locat 7 yet dynam variabl classier one see warn never assum avail data contain relev inform 332 synthet massiv data set 10d measur perform still higher dimension massiv data set produc datgen 34 10dimen sional test case 5 million train point 50 000 point test use call datgen r1 x0200ro like synthet 6dimension exampl main observ concern run time measur pentium iii 700 mhz machin besid total run time also give cpu time need comput matric g l note highest amount memori need level 2 case 5 million data point 500 mbyte 250 mbyte matrix 250 mbyte keep data point memori 50 run time spent assembl tabl 5 result 6d synthet massiv data set train test total data matrix point correct correct time sec time sec iter linear basi function level 1 500 000 905 905 25 8 25 5 million 905 906 242 77 28 level 2 500 000 912 911 110 55 204 5 million 911 912 1086 546 223 50 000 922 914 48 23 869 level 3 500 000 917 917 417 226 966 5 million 916 917 4087 2239 1057 dlinear basi function level 1 500 000 907 908 597 572 91 5 million 907 907 5897 5658 102 level 2 500 000 915 916 4285 4168 656 5 million 914 915 42690 41596 742 data matrix time need data matrix scale linearli number data point see tabl 7 total run time seem scale even better linear 4 conclus present spars grid combin techniqu linear basi function base simplic classic data moderatedimension space new method gave good result wide rang problem capabl handl huge data set 5 million point run time scale linearli number data import properti mani practic applic often dimens problem substanti reduc certain preprocess step number data extrem huge believ spars grid combin method possess great potenti practic applic problem demonstr ripley data set best valu regular paramet determin also practic relev parallel version spars grid combin techniqu reduc run time signicantli see 17 note method easili paralleliz alreadi coars grain level second level parallel possibl grid combin techniqu standard techniqu known numer treatment partial differenti equat sinc necessarili dimens need maximum renement level modic combin techniqu regard dierent renement level dimens along line 19 seem promis note furthermor approach deliv continu classier function approxim data therefor use without modic regress problem well contrast mani method like eg decis tree also two class handl use isolin dierent valu final reason simplic use oper r dierenti eg oper employ associ regular nite element ansatz function 5 acknowledg part work support german bundesministerium fur bildung und forschung bmbf within project 03grm6bn work carri cooper prudenti system softwar gmbh chemnitz author thank one refere remark forest cover data set 6 r adapt verfahren f uci kdd archiv uci repositori machin learn databas ecolog consequ comput model forest growth tensor product approxim space e learn data concept data mine method knowledg discoveri approxim statist test compar supervis classi inform complex multivari fredholm integr equat sobolev class simplizialzerlegungen von beschr comput eigenproblem hydrogen helium strong magnet electr parallel spars grid approach data mine data mine spars grid numer integr use spars grid equival spars approxim support vector machin regular theori neural network architectur gener cross valid method choos good ridg paramet combin techniqu spars grid solut pde multiprocessor machin adapt spars grid multilevel method ellipt pde base optim tensorproduct approxim space spars grid boundari integr equat combin techniqu solut spars grid problem high dimension smooth base multilevel analysi grundlagen der goemetrischen datenverarbeitung combinatori lemma topolog ssvm smooth support vector machin classi program creat structur data bayesian neural network classi neural network relat method classi compar classi die method der finiten di interpol spars grid nikolskijbesov space domin mix smooth 2d spiral pattern recognit possibilist measur quadratur interpol formula tensor product certain class function approxim function bound mix deriv solutio illpos problem estim depend base empir data natur statist learn theori spline model observ data spiral data set spars grid tr regular theori neural network architectur approxim scatter data use smooth grid function natur statist learn theori inform complex multivari fredholm integr equat sobolev class 2d spiral pattern recognit possibilist measur equival spars approxim support vector machin data mine method knowledg discoveri adapt spars grid multilevel method ellipt pde base finit differ approxim statist test compar supervis classif learn algorithm bayesian neural network classif comput eigenproblem hydrogen helium strong magnet electr field spars grid combin techniqu learn data compar classifi parallel solut 3d pde network workstat vector comput ctr jochen garck regress optimis combin techniqu proceed 23rd intern confer machin learn p321328 june 2529 2006 pittsburgh pennsylvania deepak k agarw shrinkag estim gener proxim support vector machin proceed eighth acm sigkdd intern confer knowledg discoveri data mine juli 2326 2002 edmonton alberta canada j garck griebel thess data mine spars grid comput v67 n3 p225253 novemb 2001