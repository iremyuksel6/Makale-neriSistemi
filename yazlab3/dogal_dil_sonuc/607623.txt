hidden markov model text categor multipag document tradit set text categor formul concept learn problem instanc singl isol document howev perspect appropri case mani digit librari offer content scan optic read book magazin paper propos gener formul text categor allow document organ sequenc page introduc novel hybrid system specif design multipag text document architectur reli hidden markov model whose emiss bagofword result multinomi word event model gener portion naiv bay classifi rational behind propos take account contextu inform provid whole page sequenc help disambigu improv singl page classif accuraci result two dataset scan journal make america collect confirm import use whole page sequenc empir evalu indic error rate obtain run naiv bay classifi isol page significantli reduc contextu inform incorpor b figur 1 bayesian network naiv bay classifi 22 hidden markov model hmm introduc sever year ago tool probabilist sequenc model interest area develop particularli seventi within speech recognit research commun rabin 1989 last year larg number variant improv standard hmm propos appli undoubt edli markovian model regard one signific stateoftheart approach sequenc learn besid sever applic pattern recognit molecular biolog hmm also appli text relat task includ natur languag model charniak 1993 recent inform retriev extract freitag mccallum 2000 mccallum et al 2000 recent view hmm particular case bayesian network bengio frasconi 1995 luck 1995 smyth et al 1997 help theoret understand abil conceiv extens standard model sound formal eleg framework hmm describ two relat discretetim stochast process first process pertain hidden discret state variabl denot xt form firstord markov chain take realiz finit set x1xn second process pertain observ variabl emiss denot dt start given state time 0 given initi state distribut px0 model probabilist transit new state x1 correspondingli emit observ d1 process repeat recurs end state reach note form comput may suggest hmm close relat stochast regular grammar charniak 1993 markov properti prescrib xt1 condit independ x1xt1 given xt furthermor assum dt independ rest given xt two condit independ assumpt graphic depict use bayesian network figur 2 result hmm fulli specifi follow condit probabl pxt xt1 transit distribut 2 pdt xt emiss distribut sinc process stationari transit distribut repres squar stochast matrix whose entri transit probabl abbrevi pxi x j follow classic literatur emiss restrict hidden markov model 199 figur 2 bayesian network standard hmm symbol finit alphabet multivari continu variabl rabin 1989 explain next section model allow emiss bagofword 3 multipag classifi turn descript classifi multipag document case categor task consist learn exampl function map whole document sequenc d1dt correspond sequenc page categori c1ct section present architectur asoci algorithm grammar extract train classif 31 architectur system base hmm whose emiss associ entir page document thu realiz observ dt bagofword repres text tth page document hmm state relat page categori determinist function map state realiz page categori assum surject biject ie state realiz categori enrich express power model allow differ transit behavior page class depend page actual encount within sequenc howev page content depend categori context categori within sequence5 multipl state may introduc mani paramet may conveni assum pdt xi constrain emiss paramet given page categori form paramet share may help reduc overfit emiss distribut model assum condit word independ given class like eq 1 dt pdt ck 4 therefor architectur graphic describ merg bayesian network hmm naiv bay shown figur 3 remark state 200 frasconi et al figur 3 bayesian network describ architectur sequenti classifi henc categori page depend content page also content page document summar hmm state probabilist depend implement mechan take contextu inform account algorithm use paper deriv literatur markov model rabin 1989 infer learn bayesian network pearl 1988 heckerman 1997 jensen 1996 classif naiv bay lewi gale 1994 kalt 1996 follow give detail integr method 32 induct hmm topolog structur topolog hmm represent allow transit hidden state precis topolog describ direct graph whose vertic state realiz x1xn whose edg pair hmm said ergod transit graph fullyconnect howev almost interest applic domain less connect structur better suit captur observ properti sequenc model sinc convey domain prior knowledg thu start right structur import problem practic hidden markov model exampl consid figur 4 show simplifi graph describ transit part hypothet set book possibl state realiz start titl dedic prefac toc regular index end note simplifi exampl onetoon map figur 4 exampl hmm transit graph hidden markov model 201 structur kind could handcraft domain expert may advantag learn automat data briefli describ solut adopt automat infer hmm transit graph sampl multipag document let us assum page avail train document label class belong one imagin take advantag observ label search effect structur space hmm topolog approach base applic algorithm datadriven model induct adapt previou work construct hmm text phrase inform extract mccallum et al 2000 algorithm start build structur explain avail train sequenc maxim specif model initi structur mani path initi final state train sequenc everi path associ one sequenc page ie distinct state creat everi page train set state x label x categori correspond page document note unlik exampl shown figur 4 sever state gener categori algorithm iter appli merg heurist collaps state augment gener capabl unseen sequenc first heurist call neighbormerg collaps two state x x neighbor graph x second heurist call vmerg collaps two state x x share transit common state thu reduc branch factor structur 33 infer learn given hmm topolog extract algorithm describ learn problem consist determin transit emiss paramet one import distinct need made train bayesian network whether variabl observ assum complet data variabl observ maximum likelihood estim paramet could solv use onestep algorithm collect suffici statist paramet heckerman 1997 case data complet follow two condit met 1 onetoon map hmm state page categori ie 2 categori known page train document ie dataset consist sequenc pair d1 c1dt ct ct known categori page number page document assumpt estim transit paramet straightforward accomplish follow nci cj number time page class ci follow page class cj trainingsetsimilarlyestimationofemissionparametersinthiscasewouldbeaccomplish exactli like case naiv bay classifi see eg mitchel 1997 pw nw ck number occurr word w page class ck v vocabulari size 1v correspond dirichlet prior paramet heckerman 1997 play regular role whose word rare within class condit 1 2 howev normal satisfi first order model accur differ context categori may occur may conveni multipl distinct hmm state page categori impli page label determin uniqu state path second label page train set time consum process need perform hand may import use also unlabel document train joachim 1999 nigam et al 2000 mean label c may avail assumpt 2 satisfi assumpt 1 deriv follow approxim estim formula transit paramet nxi x j count mani time state xi follow x j state merg procedur describ section 32 howev gener presenc hidden variabl requir iter maximum likelihood estim algorithm gradient ascent expectationmaxim em implement use em algorithm origin formul dempster et al 1977 usabl bayesian network local condit probabl distribut belong exponenti famili heckerman 1997 em algorithm essenti reduc baumwelch form rabin 1989 modif evid enter state variabl sinc multipl state associ categori even label document page categori known state evid take form find jensen 1996 state evid taken account estep chang forward propag follow ct forward variabl baumwelch algorithm emiss probabl pdt obtain eq 4 use ck themstepisperformedinthestandardwayfortransitionparametersbyreplacingcount eq 5 expect given observ variabl emiss probabl hidden markov model 203 also estim use expect word count paramet share indic eq 3 count sum state label thu case incomplet data eq 6 replac pw ck number train sequenc nw ck number occurr word w page class ck pxt xi d1dt probabl state xi page given observ sequenc page d1 dt reader familiar hmm recogn latter quantiti comput baumwelch procedur estep sum p extend train sequenc sum extend page pth document train set e mstep iter local maximum incomplet data likelihood reach note page categori observ conveni use estim comput eq 7 start point rather use random initi paramet similarli initi estim emiss paramet obtain eq 6 interest point relat applic em algorithm learn label unlabel document nigam et al 2000 paper concern allow learner take advantag unlabel document train set major differ method nigam et al 2000 assum flat singlepag document appli multipag document would equival zeroord markov model take contextu inform account 34 page classif given document page classif perform first comput sequenc state x1xt like gener observ sequenc page map state correspond categori xt like state sequenc obtain run adapt version viterbi algorithm whose gener form maxpropag algorithm bayesian network describ jensen 1996 briefli follow quantiti comput use follow recurs 204 frasconi et al optim state sequenc retriev backtrack final categori obtain ct xt contrast note naiv bay cla sifier would comput like categori ct compar eq 1115 eq 16 see classifi reli emiss model pdt cj naiv bay employ prior class probabl comput final predict hmm classifi take advantag dynam term squar bracket eq 12 incorpor grammat constraint 4 experiment result section describ set experi give empir evid effect propos model main purpos experi make comparison multipag classif approach tradit isol page classif system like well known naiv bay text classifi evalu conduct realworld document natur organ form page sequenc use two differ dataset associ two journal make america moa collect moa join project univers michigan cornel univers see httpmoaumdlumicheduabouthtml shaw blumson 1997 collect make avail digit inform histori evolut process american societi xix xx centuri 41 dataset first dataset subset journal american missionari sociolog magazin strong christian guidelin task consist correctli classifi page previous unseen document one ten categori describ tabl 1 categori relat topic articl relat part journal ie content receipt advertis dataset select contain 95 issu 1884 1893 total 3222 ocr text page special issu final report issu typic novemb decemb issu remov dataset contain categori found rest ten categori tempor stabl second dataset subset scribner monthli recreat cultur magazin print second half xix centuri tabl 2 describ categori select classif task filter dataset contain total 6035 ocr text page organ issu rang year 1870 1875 although span shorter tempor interv number page second dataset larger first one issu 34 time longer hidden markov model 205 tabl 1 categori american missionari domain name descript cover index survey editori articl afroamerican survey american indian survey report china mission articl femal condit educ childhood magazin inform list founder content mostli graphic littl text descript tabl 2 categori scribner monthli domain name descript 1 articl 2 book author home abroad gener articl book review broad cultur news poem tale articl home live scientif articl articl fine art news report categori label two dataset obtain semiautomat start moaxmlfilessuppliedwiththedocumentscollectionstheassignedcategorieswerethen manual check case page contain end begin two articl belong differ categori page assign categori end articl page within document repres bagofword count number word occurr within page worth remark dataset instanc text document output ocr system imperfect recognit algorithm presenc imag page yield noisi text contain misspel nonexist word trash charact see bicknes 1998 report ocr accuraci moa digit librari although error may neg affect learn process subsequ result evalu phase made attempt correct filter misspelledwordsexceptforthefeatureselectionprocessdescribedinsection43howev sinc ocr extract document preserv text layout found origin imag necessari rejoin word fragment hyphen due line break 206 frasconi et al 42 grammar induct case complet label document possibl run structur learn algorithm present section 32 figur 5 show exampl induc hmm topolog journal american missionari structur extract use 10 issu year 1884 train set vertex transit graph associ one hmm state label correspond categori index see tabl 1 edg label transit probabl sourc target state estim case count state transit state merg procedur see eq 7 valu also use initi estim pxi x j subsequ refin em algorithm associ stochast grammar impli valid sequenc must start index page class 1 follow page gener commun class 8 next state associ page editori articl 2 self transit valu 091 mean high probabl next page belong editori lower probabl 007 next page one south survey 3 probabl 0008 indian 4 bureau women work 6 figur 6 show one exampl induc hmm topolog journal scribner monthlyobtainedfrom12trainingissuesyear1871althoughissuesofscribnersmonthli longer number categori compar american missionari extract transit diagram figur 6 simpler one figur 5 reflect less variabl sequenti organ articl scribner monthli note categori 7 home societi rare never occur 1871 43 featur select text page first preprocess common filter algorithm includ stem stop word remov still bagofword represent page lead highdimension featur space respons overfit conjunct algorithm base gener probabilist model featur select techniqu limit overfit remov noninform word document experi ment perform featur select use inform gain yang pedersen 1997 criterion often employ differ machin learn context measur averag number bit inform categori gain includ word document dictionari term w gain defin k k pck wlog pck w w denot absenc word w featur select perform retain word highest averag mutual inform class variabl ocr error howev produc noisi featur may respons poor perform hidden markov model 207 figur 5 data induc hmm topolog american missionari year 1884 number node correspond 208 frasconi et al figur 6 data induc hmm topolog scribner monthli year 1871 number node correspond hidden markov model 209 even featur select perform reason may conveni prune dictionari appli inform gain criterion word occur less given threshold h train set preliminari experi show best perform achiev prune word less occurr 44 accuraci comparison follow compar isol page classif use standard naiv bay sequenti classif use propos hmm architectur although classif accuraci could estim fix split avail data train test set suggest method attempt incorpor peculiar digit librari domain particular handlabel document purpos train expens activ work larg train set like unrealist practic applic reason experi deliber use small fraction avail data train moreov problem tempor stabil journal organ may chang time test attempt address aspect assum train data avail given year decid test gener journal issu publish differ year split accord public year advantag train algorithm sinc increas likelihood differ issu organ repres train set result method relat kfold crossvalid common approach accuraci estim partit dataset k subset iter use one subset test k 1 train experi revers proport data train test set use journal issu one year train remain issu test believ set realist case digit librari follow experi hmm classifi train first extract transit structur initi paramet use eq 6 7 final tune paramet use em algorithm found initi paramet estim close final solut found em algorithm typic 2 3 iter suffici em converg 441 american missionari dataset result ten result experi shown figur 7 hybrid hmm classifi perform sequenti classif consist outperform plain naiv bay classifi work isol page graph top summar result obtain without featur select averag result ten experi nb achiev 619 accuraci hmm achiev 804 correspond 484 error rate reduct graph bottom refer result obtain select best 300 word accord inform gain criterion averag accuraci case 698 nb 806 hmm 357 error rate reduct case word occur less 10 time train set prune use featur select nb improv hmm perform essenti moreov standard deviat accuraci smaller nb 28 compar 42 hmm larger variabl case hmm due figur 7 isol vs sequenti page classif american missionari dataset column classifi train document correspond year test remain issu structur induct algorithm fact sequenti organ journal issu tempor less stabl articl content 442 scribner monthli dataset similar experi carri scrib ner monthli journal result use featur select shown top figur 8 averag accuraci 810 isol page classif 896 sequenti classi ficat error reduct 425 featur select averag accuraci drop 753 isol page classifi remain similar sequenti classifi hidden markov model 211 figur 8 isol vs sequenti page classif scribner monthli dataset notic featur select differ effect two dataset coupl naiv bay classifi tend improv accuraci american missionari tend worsen scribner monthli hand hmm almost insensit featur select dataset appar counterintuit sinc emiss model almost two classifi except em tune emiss paramet case hmm howev remark naiv bay final predict bias class prior eq 16 hmm predict bias extract grammar eq 1115 latter provid robust inform effect compens crude approxim emiss model prescrib 212 frasconi et al condit word independ robust also affect posit perform suboptim set featur select repres document page 45 learn use ergod hmm follow experi provid basi evalu effect structur learn algorithm present section 32 present set train ergod hmm ten state state map exactli one class emiss paramet initi use eq 6 transit probabl initi random valu case em algorithm take full respons extract sequenti structur data train arc associ probabl less 0001 prune away evalu perform use american missionari dataset train singl year previou set experi expect see figur 9 result wors obtain conjunct grammar extract algorithm howev train hmm outperform naiv bay classifi also case 46 effect train set size investig effect size train set propos set experi altern report section 44 experi select variabl number sequenc journal issu n train randomli chosen dataset test gener remain sequenc accuraci report function n averag 20 trial trial proport train test sequenc experi perform american missionari dataset shown figur 10 gener isol sequenti classifi tend satur 15 sequenc train set slightli figur 9 comparison ergod hmm hmm base extract grammar hidden markov model 213 figur 10 learn curv sequenti isol classifi averag number issu singl year sequenti classifi consist outperform isol page classifi 47 learn partial label document sinc label expens human activ evalu system also fraction train document page label particular interest measur loss accuraci due miss page label sinc structur learn feasibl partial label document use case ergod fulli connect hmm ten state one per class perform six differ experi american missionari dataset use differ percentag label page experi issu year 1884 form train set remain issu form test set tabl 3 show detail result experi classif accuraci report singl class entir test set use 30 label page hmm fail learn reliabl transit structur naiv bay classifi train em nigam et al 2000 obtain higher accuraci tabl 4 howev higher percentag known page label comparison favor sequenti classifi use 50 label page hmm outperform isol page classifi train complet label data greater percentag label document perform begin satur reach maximum 8024 label known correspond result obtain section 45 5 conclus present text categor system multipag document capabl effect take account contextu inform improv accuraci respect tradit isol page classifi method smoothli deal unlabel page within document although found learn hmm structur 214 frasconi et al tabl 3 result achiev model train expectationmaxim vari percentag label document percentag label document categori anoth aspect granular document structur exploit work level page straightforward sinc page boundari readili avail howev actual categori boundari may coincid page boundari page may contain portion text belong differ articl case page would belong multipl categori although critic singlecolumn journal american missionari case document typeset two three column certainli deservesattentionafurtherdirectionofinvestigationisthereforerelatedtothedevelop algorithm capabl perform automat segment continu stream text without necessarili reli page boundari final text categor method take document structur account may extrem use type document nativ avail electron form includ web page document produc typeset system particular hypertext like document internet organ direct graph structur seen gener sequenc howev devis classifi captur context inhypertextsbyextendingthearchitecturedescribedinthispaperisstillanopenproblem though extens hmm sequenc tree straightforward see eg diligenti etal2001thegeneralcaseofdirectedgraphsisdifficultbecauseofthepresenceofcycl preliminari research direct base simplifi model incorpor graphic transit structur present diligenti et al 2000 passerini et al 2001 acknowledg thank cornel univers librari provid us data collect within make america project research partial support ec grant ist199920021 meta project note 1 relat formul would consist assign global categori whole multipag document formul consid paper 2 observ text 3 bayesian network annot graph node repres random variabl miss edg encod condit independ statement amongst variabl given particular state knowledg semant belief network determin whether collect evid set variabl modifi one belief set variabl jensen 1996 pearl 1988 4 adopt standard convent denot variabl uppercas letter realiz correspond lowercas letter moreov use tabl notat probabl jensen 1996 exampl px shorthand tabl denot twodimension tabl entri 5 cours mean categori independ context r input output hmm architectur bayesian network dor data mine introduct bayesian network text categor support vector machin learn mani relev fea ture transduct infer text classif use support vector machin experiment evalu ocr text represent learn document classifi new probabilist model text classif retriev hierarch classifi document use word sequenti algorithm train text classifi comparison two learn algorithm text categor bayesian belief network tool stochast pars autom construct internet portal machin learn machin learn featur select text classif label unlabel document use em evalu method focus crawl probabilist reason intellig system network plausibl infer tutori hidden markov model select applic speech recognit onlin search page present univers michigan probabilist independ network hidden markov probabl model hidden markov model induct bayesian model merg examplebas map method text classif retriev compar studi featur select text categor tr probabilist reason intellig system network plausibl infer examplebas map method text categor retriev sequenti algorithm train text classifi bayesian belief network tool stochast pars probabilist independ network hidden markov probabl model featur select percept learn usabl case studi text categor text classif label unlabel document use em statist languag learn machin learn introduct bayesian network bayesian network data mine autom construct internet portal machin learn text categor suport vector machin hierarch classifi document use word compar studi featur select text categor transduct infer text classif use support vector machin hidden markov model induct bayesian model merg focus crawl use context graph imag document categor use hidden tree markov model structur represent inform extract hmm structur learn stochast optim evalu method focus crawl new probabilist model text classif retriev title2 ctr fabrizio sebastiani machin learn autom text categor acm comput survey csur v34 n1 p147 march 2002