track best disjunct littleston develop simpl determinist onlin learn algorithm learn kliter disjunct algorithm call sc winnow keep one weight variabl multipl updat weight develop random version sc winnow prove bound adapt algorithm case disjunct may chang time case possibl target disjunct schedul tgr sequenc disjunct one per trial shift size total number liter addedremov disjunct one progress sequencew develop algorithm predict nearli well best disjunct schedul arbitrari sequenc exampl algorithm allow us track predict best disjunct hardli complex origin version howev amort analysi need obtain worstcas mistak bound requir new techniqu case lower bound show upper bound algorithm right constant front lead term mistak bound almost right constant front second lead term comput experi support theoret find b introduct one signific success comput learn theori commun littleston formal onlin model learn develop algorithm winnow learn disjunct littleston 1989 1988 key featur winnow learn disjunct constant size number mistak algorithm grow logarithm input dimens mani standard algorithm perceptron algorithm rosenblatt 1958 number mistak grow linearli dimens kivinen warmuth auer 1997 meantim number algorithm similar winnow develop also show logarithm growth loss bound dimens littleston warmuth 1994 vovk 1990 cesabianchi et al 1997 haussler kivinen warmuth 1994 extend abstract appear auer warmuth 1995 k warmuth acknowledg support nsf grant ccr 9700201 paper give refin analysi winnow develop random version algorithm give lower bound show determinist random version close optim adapt version use track predict best disjunct consid follow standard onlin learn model littleston 1989 1988 vovk 1990 cesabianchi et al 1997 learn proce trial trial algorithm present instanc x case ndimension binari vector use produc binari predict algorithm receiv binari classif instanc incur mistak goal minim number mistak algorithm arbitrari sequenc exampl hx cours hopeless scenario determinist algorithm adversari alway choos sequenc algorithm make mistak trial reason goal minim number mistak algorithm compar minimum number mistak made concept comparison class 11 nonshift basic setup paper use monoton 1 kliter disjunct comparison class dimens number boolean attributesliter n disjunct boolean formula form x distinct indic j lie ng number classif error disjunct respect sequenc exampl simpli total number misclassif disjunct produc sequenc goal develop algorithm whose number mistak much larger number classif error best disjunct sequenc exampl paper consid case mistak best target disjunct caus attribut error number attribut error exampl respect target disjunct u minimum number attributesbit x chang result x 0 number attribut error sequenc exampl respect target concept simpli total number error exampl sequenc note target u kliter monoton disjunct number attribut error k time number classif error respect u ie k time number exampl x sequenc ux 6 winnow tune function k make oak lnnk mistak sequenc exampl best disjunct incur attribut error littleston 1988 give random version winnow give improv tune origin algorithm new algorithm tune base k expect mistak bound sequenc exampl monoton kliter disjunct attribut error also show origin determinist algorithm tune number mistak 2a set sequenc lower bound show bound close optim show algorithm expect number mistak must least upper bound correct constant lead term almost optim constant second term determinist algorithm lower bound show constant lead term optim lower bound determinist random case improv significantli essenti match upper bound achiev noneffici algorithm correct factor first second term algorithm use expert cesabianchi et al 1997 expert simpli comput valu particular kliter disjunct one weight kept per expert amount expand ndimension boolean input boolean input use singl liter expert littleston warmuth 1994 vovk 1990 cesabianchi et al 1997 comparison class instead k liter disjunct expect number mistak random algorithm q bound number classif error best kliter disjunct mistak bound determinist algorithm exactli twice high observ algorithm use n k weight need much time trial calcul predict updat weight thu run time exponenti k contrast algorithm use n weight hand nois upper bound effici algorithm measur attribut error rather classif error aris sinc use one weight per attribut recal classif error respect kliter disjunct equat k attribut error captur error affect k attribut effici expans expert seem unavoid nevertheless surpris version winnow abl get right factor number attribut error random version almost right factor squar root term sens winnow compress delta weight n weight point dont combinatori interpret weight interpret found singl liter expert case cesabianchi freund helmbold warmuth 1996 littleston littleston 1991 use amort analysi entrop potenti function obtain worstcas loss bound howev besid care tune bound take amort analysi method signific step prove mistak bound algorithm compar best shift disjunct 12 shift disjunct assum disjunct u specifi ndimension binari vector compon valu 1 correspond monoton liter disjunct two disjunct u u 0 ham distanc measur mani liter shift obtain u 0 u disjunct schedul sequenc exampl length simpli sequenc disjunct u shift size schedul zero vector origin nonshift case u equal kliter disjunct u accordingli definit shift size k trial schedul predict disjunct u defin number attribut error exampl sequenc hx respect schedul total number attribut chang sequenc exampl make consist schedul ie chang instanc x 0 note loss bound nonshift case written cao delta number bit take describ disjunct k liter random determinist algorithm surprisingli abl prove bound form shift disjunct case b number bit take describ best schedul number attribut error schedul z shift size schedul take log 2 z bit describ schedul respect given sequenc exampl 2 worstcas mistak bound similar bound obtain competit algorithm compar number mistak algorithm number attribut error best offlin algorithm given whole sequenc ahead time offlin algorithm still incur attribut error bound addit loss onlin algorithm number attribut error best schedul oppos coarser method bound ratio onlin offlin winnow multipl updat weight whenev algorithm make mistak weight liter correspond bit current input instanc one multipli factor case winnow2 version winnow paper base littleston 1988 factor either ff 1ff ff 1 paramet algorithm multipl weight updat might caus weight algorithm decay rather rapidli sinc liter might becom part disjunct schedul even mislead earli part sequenc exampl algorithm predict well compar best disjunct schedul must abl recov weight quickli extens winnow2 simpli add step origin algorithm reset weight fin whenev drop boundari similar method lower bound weight use algorithm wml littleston warmuth 1994 design predict well best shift singl liter call expert cesabianchi et al 1997 addit gener work littleston warmuth 1994 arbitrari size disjunct abl optim constant lead term mistak bound winnow develop random version algorithm herbster warmuth 1998 work littleston warmuth 1994 gener differ direct focu predict well best shift expert well measur term loss function discret loss count mistak loss function use paper basic build block simpl onlin algorithm use multipl weight updat vovk 1990 haussler et al 1994 predict feedback trial realvalu lie interv 0 1 class loss function includ natur loss function log loss squar loss helling loss loss occur larg discret unit instead loss trial arbitrarili small thu sophist method need recov small weight quickli herbster warmuth 1998 simpli lower bound weight disjunct import whenev richer class built small union larg number simpl basic concept method appli simpli expand origin input mani input basic concept sinc mistak bound depend logarithm number basic con cept even allow exponenti mani basic concept still polynomi mistak bound method previous use develop nois robust algorithm predict nearli well best discret ddimension axisparallel box maass warmuth 1998 auer 1993 well best prune decis tree helmbold schapir 1997 case multipl algorithm maintain one weight exponenti mani basic concept howev exampl multipl algorithm exponenti mani weight still simul effici exampl method paper immedi lead effici algorithm predict well best shift ddimension box thu combin method exist al gorithm design effici learn algorithm provabl good worstcas loss bound gener shift concept disjunct besid experi practic data exemplifi merit worstcas mistak bound research also leav number theoret open prob lem winnow algorithm learn arbitrari linear threshold function method track best disjunct still need gener learn gener class concept believ techniqu develop learn predict well best shift disjunct use set develop algorithm predict nearli well best shift linear combin discret loss replac continu loss function squar loss make problem challeng 13 relat work natur competitor winnow well known perceptron algorithm rosenblatt 1958 learn linear threshold function algorithm addit instead multipl updat classic perceptron converg theorem give mistak bound algorithm duda hart 1973 haykin 1994 bound linear number attribut kivinen et al 1997 wherea bound winnowlik algorithm logarithm number attribut proof perceptron converg theorem also seen amort analysi howev potenti function need perceptron algorithm quit differ potenti function use analysi winnow w weight vector algorithm trial u target weight vector perceptron algorithm 2 potenti function jjjj 2 euclidean length vector contrast potenti function use analysi winnow littleston 1988 1989 also use paper follow gener 3 rel entropi cover case linear regress framework develop kivinen warmuth 1997 deriv updat potenti function use amort anal ysi framework adapt deriv perceptron algorithm winnow differ potenti function algorithm lead addit multipl algorithm respect perceptron algorithm seek weight vector consist exampl otherwis minim euclidean length winnow instead minim rel entropi thu root minimum rel entropi principl kullback kapur kesavan 1992 jumari 1990 14 organ paper next section formal defin notat use throughout paper alreadi discuss introduct section 3 present algorithm section 4 give theoret result algorithm section 5 consid practic aspect name paramet algorithm tune achiev good perform section 6 report experiment result analysi algorithm proof section 4 given section 7 lower bound number mistak made algorithm shown section 8 conclud section 9 2 notat target schedul sequenc disjunct repres nari bit vector u size shift disjunct u disjunct u z j total shift size schedul z assum u get precis bound case shift target schedul distinguish shift liter ad disjunct shift liter remov disjunct thu defin z number time liter switch number time liter switch sequenc exampl consist attribut vector classif 2 f0 1g predict disjunct u attribut vector x u number attribut error trial respect target schedul minim number attribut chang result x 0 u g total number attribut error sequenc respect schedul denot sz n class exampl sequenc n attribut consist target schedul shift size z attribut error wish distinguish posit neg shift denot correspond class sz number liter ad remov respect target schedul 0 k n denot class exampl sequenc n attribut consist nonshift target schedul ie attribut error case upper bound z z known denot correspond class z zz k loss learn algorithm l exampl sequenc number misclassif binari predict learn algorithm l trial 3 algorithm present algorithm swin shift winnow see tabl 1 extens littleston winnow2 algorithm littleston 1991 extens incorpor random algorithm guarante lower bound weight use algorithm algorithm maintain vector n weight n attribut w denot weight end trial tabl 1 algorithm swin paramet algorithm use paramet ff initi set weight initi valu trial 1 set r predict ae receiv binari classif updat 6 pr 1 w 0 2 w w 0 denot initi valu weight vector trial algorithm predict use weight vector w predict algorithm depend r 1 algorithm predict 1 probabl pr predict 0 probabl obtain determinist algorithm one choos function p predict algorithm receiv classif ie weight vector modifi sinc 2 f0 1g pr 2 0 1 occur predict determinist ie pr correct updat occur case predict wrong pr updat weight perform two step first step origin winnow updat second step guarante weight smaller fi paramet fi similar approach taken littleston warmuth 1994 observ weight chang probabl make mistak nonzero determinist algorithm mean weight chang algorithm made mistak furthermor ith weight modifi x 1 weight increas multipli ff decreas divid ff paramet ff fi w 0 function pdelta set appropri good choic function pdelta follow random predict let rand determinist version algorithm let det random version one choos fi ln ff observ det obtain rand choos threshold rand correspond straightforward convers random predict algorithm determinist predict algorithm theoret good choic paramet ff fi w 0 given next section practic issu tune paramet discuss section 5 4 result section give rigor bound expect number mistak swin first gener specif choic ff fi w 0 pdelta chosen rand det bound shown close optim adversari exampl sequenc detail see section 8 theorem 1 random version let ff 1 n pdelta rand fi n e bound hold theorem 2 determinist version let ff 1 n pdelta det fi n e bound hold theorem 3 nonshift case let ff 1 swin use function pdelta given rand swin use function pdelta given det e bound hold 2 remark usual convers bound random algorithm bound determinist algorithm would give 2m determinist bound 4 observ determinist bound 1 time random bound sinc time disjunct contain n liter z give follow corollari w pdelta rand 2 z n j j pdelta det 2 z n ffn j j first give result number mistak swin inform besid n total number attribut given theorem 4 let n pdelta rand 2 z n n pdelta det 2 n pdelta rand 2 bound hold 2 n n 2 pdelta det 2 0 k n bound hold 2 n n 2 section 8 show bound optim constant z known advanc paramet algorithm tune obtain even better result exampl nonshift case number k attribut target concept known get theorem 5 let n pdelta rand e bound hold 2 n k n e set e get emswin 144 e 2 pdelta det 2 0 k n e bound hold 2 n k n e set e get mswin 275 e 2 particular interest case domin term ie ae k ln n theorem 6 let k ln n n pdelta rand 2 0 k n r e bound hold 2 n k n e n e e emswin e 2k pdelta det 2 0 k n r e bound hold 2 n k n e e e mswin 2a e shift case get domin ae z ln n theorem 7 let zminfnzg z zsuch ffl 1 n pdelta rand 2 z n r z zminfnzg z n pdelta det 2 z n r z section 8 show theorem 6 7 constant optim furthermor show random algorithm also magnitud second order term theorem 6 optim 5 practic tune algorithm section give thought paramet ff fi w 0 swin chosen particular target schedul sequenc exampl recommend base mistak bound hold target schedul sequenc exampl appropri bound number shift attribut error thu mention sinc mani target schedul mani exampl sequenc worst case bound usual overestim number mistak made swin therefor paramet set differ recommend might result smaller number error specif target schedul exampl sequenc hand swin quit insensit small chang paramet see section 6 effect chang benign littl known target schedul exampl sequenc paramet set theorem 4 5 advis sinc balanc well effect target shift attribut error good estim number target shift number attribut error known good paramet calcul numer minim bound theorem 1 2 3 corollari 1 respect averag rate target shift attribut error known z r z r r z 0 r 0 larg error rate r mswinst corollari 1 approxim upper bound r random predict r ffn determinist predict optim choic ff fi obtain numer minim 6 experiment result experi report section meant give rigor empir evalu algorithm swin instead intend illustr typic behavior swin compar theoret bound also version winnow modifi adapt shift target schedul experi use attribut target schedul length start 4 activ liter 1000 trial one liter switch anoth 1000 trial anoth liter switch switch switch liter continu depict figur 1 thu initi 4 activ liter exampl sequenc hx chosen half exampl half valu attribut appear target schedul chosen random x probabl 12 exampl exactli one activ attribut chosen random set number trial number activ liter figur 1 shift target schedul use experi 1 exampl attribut error relev attribut either set 1 case set 0 case attribut error occur trial 1 trial figur 2 show perform swin compar theoret bound paramet set numer minim bound corollari 1 describ previou section yield theoret bound trial calcul actual number shift attribut error trial thu increas bound due shift target schedul attribut error trial figur 2 reason increas indic z liter switch z gamma liter switch attribut error figur 2 show theoret bound accur depict behavior swin although overestim actual number mistak amount seen switch liter caus far less mistak switch liter predict bound also relat attribut error mistak seen perform swin whole sequenc exampl shown figur 3 compar perform version winnow modifi target shift seen swin adapt quickli shift target schedul hand unmodifi version winnow make mistak shift unmodifi version winnow use swin thu weight lower bound becom arbitrarili small caus larg number mistak correspond liter becom activ use z a4 z number trial number mistak theoret bound perform swin figur 2 comparison swin theoret bound particular target schedul sequenc exampl shift attribut error indic z number trial number mistak theoret bound perform swin perform winnow figur 3 version winnow lower bound weight make mani mistak swin ff unmodifi version set w optim initi part target schedul therefor unmodifi winnow adapt quickli initi part make increas number mistak shift target schedul shift number mistak made approxim doubl last plot figur 4 compar perform swin tune paramet perform swin gener paramet set given theorem 4 although tune paramet perform better differ number trial number mistak theoret bound perform swin figur 4 tune paramet swin versu gener paramet rel small overal conclus experi first theoret bound captur actual perform algorithm quit well second mechan lower bound weight winnow necessari make algorithm adapt target shift third moder chang paramet chang qualit behavior algorithm 7 amort analysi section first prove gener bound given theorem 1 2 random determinist version swin bound calcul bound given theorem 47 specif choic paramet analysi algorithm proce show distanc weight vector algorithm w vector u repres disjunct trial decreas algorithm make mistak potentialdist function use previou analysi winnow littleston 1988 1989 1991 follow gener rel entropi arbitrari nonneg weight vector distanc function also use analysi egu regress algorithm kivinen warmuth 1997 show winnow relat algorithm take deriv easi see distanc minim equal 0 w convent 0 assumpt u 2 f0 1g n distanc function simplifi start analysi random algorithm shift target di junction case deriv easili analysi first calcul much distanc du w chang trial observ term 1 might nonzero trial term 2 3 nonzero weight updat trial fl ffi lower bound term 1 weight updat trial term 2 bound third equal hold sinc x ti 2 f0 1g rememb x 0 obtain x remov attribut error x last inequ follow fact last observ w ti 6 w 0 case w 0 ffn get term 3 sum trial consid trial weight updat distinguish trial denot trial bound term 1 2 3 theta r want lower bound sum 0 1 expect total number mistak algorithm choos appropri function pdelta w denot p probabl algorithm make mistak trial expect number mistak observ sinc case thu suffici find function pdelta constant c function pdelta satisfi 4 5 get assum 2 sz upper bound expect number mistak henc want choos pdelta c c big possibl fix pdelta let r valu pr becom 1 5 sinc left hand side equat 4 5 continu get r combin two ff achiev choos pdelta rand satisfi 4 5 cours choos fi ln ff put everyth togeth follow lemma assum weight use algorithm swin swin use function pdelta given rand determinist variant algorithm function pdelta take valu f0 1g thu get 4 5 rgammafi1gamma1ff c r1gammaffln ff c yield get choos pdelta det satisfi 4 5 assum weight use algorithm swin swin use function pdelta given det go calcul bound fl ffi 1 get bound lower upper bound w ti obvious w ti fi upper bound w ti deriv observ w ti w tgamma1i pdelta rand det r w tgamma1i x ti find w ti ff thu ln efi lemma 3 fi weight w ti algorithm swin function pdelta rand det satisfi proof theorem 1 2 lemma 1 2 3 2 proof theorem 3 nonshift case u number attribut target disjunct u thu nonshift case term upper bound lemma 1 2 replac k give theorem 2 71 proof specif choic paramet proof theorem 4 5 theorem 3 corollari 1 simpl calcu lation 2 proof theorem 6 get theorem 3 2 second inequ use ffl 1 substitut valu c ffl give statement theorem 2 proof theorem 7 get corollari 1 j j j j 2 ffl 110 j j c c r z give bound theorem 2 8 lower bound start prove lower bound shift case show learn algorithm l exampl sequenc learn algorithm make mani mistak although express explicitli follow theorem show sequenc gener target schedul disjunct u consist exactli one liter ie jth unit vector first lower bound show determinist algorithm adversari exampl sequenc sz n make least 2a mani mistak relat upper bound given theorem 4 7 theorem 8 determinist learn algorithm l n 2 z 1 0 exampl sequenc 2 sz n proof notat conveni assum r 1 construct exampl sequenc depend predict learn algorithm learn algorithm make mistak trial partit trial r round first r gamma 1 round length last round length error occur within last trial choos target schedul round target disjunct chang equal e j begin round disjunct consist exampl round l trial round still 2 gammal consist disjunct construct attribut vector set half attribut correspond consist disjunct 1 attribut 0 furthermor set predict algorithm attribut vector obvious half disjunct consist exampl thu number consist disjunct divid 2 trial thu first r gamma 1 round disjunct consist exampl round last round two disjunct consist exampl round remain 2a1 trial fix attribut vector two disjunct predict differ set thu one disjunct disagre time classif disagr seen caus attribut error disjunct consist exampl last round attribut error 2 remark observ lower bound determinist algorithm like impli follow lower bound random algorithm follow fact random learn algorithm turn determinist learn algorithm make twice mani mistak random algorithm make averag mean theorem 8 impli random algorithm l sequenc 2 sz n remark open problem remain show lower bound form upper bound theorem 7 squar root term turn nonshift case alreadi lower bound known lemma 4 littleston warmuth 1994 determinist learn algorithm l n 2 0 exampl sequenc 2 0 1 n slight modif result cesabianchi et al 1997 give lemma 5 cesabianchi et al 1997 function nj j j 0 random learn algorithm l n nj j exampl sequenc 2 0 1 n ln n extend result obtain follow theorem correspond upper bound given theorem 5 6 theorem 9 determinist learn algorithm l k 1 n 2k 0 exampl sequenc 2 0 k n theorem 10 function nj j j 0 random learn algorithm l k 1 n knj kan j exampl sequenc 2 0 k n r proof theorem 9 10 proof reduct case 1 n attribut divid k group g group consist attribut furthermor choos number xi group g choos sequenc accordingli lemma 4 5 respect learn algorithm sequenc extend sequenc 0 n attribut set attribut group 0 concaten expand sequenc 0 get sequenc easi see 2 sk n hand learn algorithm sequenc n attribut transform learn algorithm sequenc smaller number attribut set miss attribut 0 thu subsequ 0 learn algorithm l make least mani mistak given 6 7 respect henc r r function j chosen appropri 2 last theorem show random algorithm constant 1 theorem 6 optim best constant squar root term 1 2 9 conclus develop algorithm swin variant winnow onlin learn disjunct subject target shift prove worst case mistak bound swin hold sequenc exampl kind target drift amount error exampl amount shift bound determinist random version swin analysi random version involv interest right lower bound show worst case mistak bound close optim case comput experi highlight explicit mechan necessari make algorithm adapt target shift acknowledg would like thank mark herbster nick littleston valuabl discuss also thank anonym refere help comment note 1 expand dimens 2n learn nonmonoton disjunct reduc monoton case 2 essenti one describ shift occur liter shift obvious necess shift current disjunct correct current exampl thu trial current disjunct would make mistak disjunct shift sinc target schedul might make mistak due attribut error z shift get z trial candid shift choos z choos one liter shift give z possibl 3 potenti function weight must posit neg weight handl via reduct littleston 1988 1989 haussler et al 1994 4 worst case random algorithm make mistak probabl 12 trial determinist algorithm alway break tie wrong way make mistak trial thu number mistak determinist algorithm twice expect number mistak random algorithm 5 formal let r sequenc hr j exist pdelta equal 1 everywher valu r 1 function pdelta satisfi condit algorithm swin forc make unbound number mistak even absenc attribut error r track best disjunct use expert advic pattern classif scene analysi tight worstcas loss bound predict expert advic tech predict nearli well best prune decis tree track best expert entropi optim principl applic addit versu exponenti gradient updat linear predict perceptron algorithm vs linear vs logarithm mistak bound input variabl relev mistak bound logarithm linearthreshold learn algorithm redund noisi attribut learn theori pp weight major algorithm inform comput effici learn virtual threshold gate learn theori pp tr ctr mark herbster manfr k warmuth track best expert machin learn v32 n2 p151178 aug 1998 p helmbold panizza k warmuth direct indirect algorithm onlin learn disjunct theoret comput scienc v284 n1 p109142 6 juli 2002 chri mesterharm track linearthreshold concept winnow journal machin learn research 4 1212003 mark herbster manfr k warmuth track best regressor proceed eleventh annual confer comput learn theori p2431 juli 2426 1998 madison wisconsin unit state manfr k warmuth winnow subspac proceed 24th intern confer machin learn p9991006 june 2024 2007 corvali oregon gentil nick littleston robust olivi bousquet manfr k warmuth track small set expert mix past posterior journal machin learn research 3 312003 claudio gentil robust pnorm algorithm machin learn v53 n3 p265299 decemb giovanni cavallanti nicol cesabianchi claudio gentil track best hyperplan simpl budget perceptron machin learn v69 n23 p143167 decemb 2007 mark herbster manfr k warmuth track best linear predictor journal machin learn research 1 p281309 912001 b kotsianti zaharaki p e pintela machin learn review classif combin techniqu artifici intellig review v26 n3 p159190 novemb 2006 peter auer use confid bound exploitationexplor tradeoff journal machin learn research 3 312003