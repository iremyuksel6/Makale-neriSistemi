scalabl featur mine sequenti data classif algorithm difficult appli sequenti exampl text dna sequenc vast number featur potenti use describ exampl past work featur select focus search space subset avail featur intract larg featur set author adapt data mine techniqu act preprocessor select featur standard classif algorithm naiv bay winnow appli algorithm number data set experiment show featur produc algorithm improv classif accuraci 20 b introduct mani real world dataset contain irrelev redund attribut may data collect without data mine mind attribut depend known priori data collect well known mani data mine method like classif cluster etc degrad predict accuraci train dataset contain redund irrelev attribut featur select right featur set improv accuraci also reduc run time predict algorithm lead simpler understand model good featur select thu one fundament data preprocess step data mine research featur select todat focus nonsequenti domain problem may defin select optim featur subset size full ddimension featur space ideal select subset maxim optim criterion classif accuraci faith captur origin data distribut subset search space exponenti larg number featur contrast tradit nonsequenti data focu sequenc data exampl repres sequenc event event might describ set predic ie deal categor sequenti domain exampl sequenc data includ text dna sequenc web usag data multiplay game plan execut trace sequenti domain featur order set partial event descript exampl sequenti featur describ chess game black move knight white move bishop squar d6 featur hold chess game other thu might use classifi chess game exampl one play expert vs one play novic select right featur sequenti tempor domain even challeng nonsequ data origin featur set undefin potenti infinit number sequenc arbitrari length categor attribut dimens even restrict maximum sequenc length k potenti od k subsequ dimens complex consid maximum subsequ length oppos 2 nonsequenti case goal featur select sequenti domain select best subset sequenti featur k possibl sequenti featur ie subsequ compos attribut describ individu event motiv use data mine techniqu set possibl featur exponenti larg altern concept problem construct new featur primit describ event new featur augment dimension origin space effect pull apart exampl class make easili distinguish classif algorithm cours process construct featur primit equival process select featur space combin primit input system set label train sequenc output function map new sequenc label word interest select construct featur sequenc classif order gener function algorithm first use sequenc mine portion train data discov frequent distinct sequenc use sequenc featur feed classif algorithm winnow naiv bay gener classifi remaind data past work rule produc data mine algorithm use construct classifi primarili order rule decis list eg 1 2 merg gener rule occur train data eg 3 paper convert pattern discov mine algorithm set boolean featur feed standard classif algorithm classif algorithm turn assign weight featur allow evid differ featur combin order classifi new exampl two main contribut paper first combin two power data mine paradigm sequenc mine effici search pattern correl target class classif algorithm learn weigh evid differ featur classifi new exampl second present scalabl featur mine algorithm handl larg dataset thousand item million record addit present criteria select featur present prune rule allow effici mine featur present featuremin scalabl algorithm capabl handl larg diskresid dataset mine good sequenti featur integr prune constraint algorithm instead postprocess enabl effici search larg pattern space 11 exampl poker let first preview main idea paper simpl illustr exampl suppos observ three peopl play poker bet sequenc outcom exampl p1 bet 3 p2 call p3 rais 2 p1 rais 1 p2 fold p3 call p1 win exampl p2 pass p3 bet 1 p1 fold p2 rais 2 p3 rais 2 p2 call p3 win object learn function predict like win given bet sequenc task resembl standard classif given label train exampl must produc function classifi new unlabel exampl mani classifi requir howev exampl repres vector featurevalu pair paper address problem select featur repres bet sequenc first consid obviou poor featur set let n length longest bet sequenc repres bet sequenc 3n featur gener distinct featur everi 0 n person made ith bet type ith bet amount ith bet section 3 show experiment featur set lead poor classif one problem featur individu featur express particular complet bid sequenc took place interest subsequ occur featur featur dollar first featur would import p 1 tend win whenev rais twice classifi could construct boolean express featur describ captur notion p 1 rais twice express would disjunct sinc need disjunct p 1 rais ith bet jth believ import consid partial specif difficult know advanc whether p 1 rais twice p 1 rais 2 rais 3 use featur altern use much larger featur set 3 player 4 bid 5 differ amount 4 5 specif bet someon bet 3 chain partial specif togeth relat p 1 rais someon bet 3 number featur length k 120 k problem featur set larg set 10000 featur consid larg classif algorithm furthermor irrelev redund featur reduc classif accuraci 4 adopt middl ground two extrem use data mine techniqu search second huge featur set select subset show criteria similar use gener knowledg discoveri task work well decid featur use 2 data mine featur formul present algorithm featur mine formul involv specifi languag featur express sequenc partial descript event gap p 1 rais later bid fold present criteria select subset featur use classif entir set express languag final describ featuremin algorithm effici mine featur select criteria begin adopt follow terminolog close resembl use sequenc mine eg 5 let f set distinct featur finit set possibl valu let contain uniqu element everi possibl featurevalu pair sequenc order list subset exampl fa b cg exampl sequenc would ab bc sequenc denot sequenc element subset length sequenc width maximum size 1 n say subsequ denot exist integ j exampl ab c subsequ ab bc let h set class label exampl pair h ci sequenc c 2 h label exampl uniqu identifi eid timestamp occur exampl h ci said contain sequenc input databas consist set exampl mean data look multipl sequenc compos set item frequenc sequenc denot fr fraction exampl contain let sequenc c class label confid rule c denot conf c condit probabl c label exampl given contain sequenc conf c c subset exampl class label c sequenc said frequent frequenc userspecifi min freq threshold rule said strong confid userspecifi min conf threshold goal mine frequent strong pattern figur 1 show databas exampl 7 exampl 4 belong class c 1 3 belong class c 2 gener two class look differ min freq sequenc class exampl c frequent class c 2 frequent class c 1 rule c c 2 confid rule confid sequenc classifi function sequenc class label h classifi evalu use standard ba aa 100 75 75 75 75 100 100 100 eid c time c ac 67 67 100 class 6 c2 exampl new boolean featur class eid figur 1 exampl b new databas boolean featur metric accuraci coverag final describ frequent sequenc 1 n use featur classif recal input standard classifi exampl repres vector featurevalu pair repres exampl sequenc vector featurevalu pair treat sequenc boolean featur true iff exampl suppos featur f sequenc ab bd bc would repres hf 1 truei hf falsei sequenc abcd would repres truei note featur skip step featur bc hold ab bd bc figur 1b show new dataset creat frequent sequenc exampl databas figur 1 use frequent sequenc featur exampl gener use good subset frequent sequenc featur describ 21 select criteria mine specifi select criteria select featur use classif object find sequenc repres exampl sequenc yield highli accur sequenc classifi howev want search space subset featur 4 instead want evalu new sequenti featur isol pairwis comparison candid featur certainli criteria select featur might depend domain classifi use believ howev follow domainandclassifi independ heurist use select sequenc serv featur featur frequent featur distinct least one class featur set contain redund featur intuit behind first heurist simpli rare featur definit rare use classifi exampl problem formul heurist translat requir featur minimum frequenc train set note sinc use differ min freq class pattern rare entir databas still frequent specif class ignor pattern rare class intuit second heurist featur equal like class help determin class exampl belong cours conjunct multipl nondistinct featur distinct case algorithm prefer use distinct conjunct featur rather non distinct conjunct encod heurist requir select featur significantli correl least one class frequent motiv third heurist two featur close correl either use classif show reduc number featur time need mine featur prune redund rule addit want prune featur provid inform also want prune featur anoth featur avail provid strictli inform let mfd set exampl contain featur f say featur f 1 subsum featur respect predict class c data set iff mf intuit f 1 subsum f 2 class c f 1 superior f 2 predict c f 1 cover everi exampl c train data f 2 cover f 1 cover subset nonc exampl f 2 cover note featur f 2 better predictor class c f 1 even f 1 cover exampl c f 2 exampl everi exampl f 2 cover c half exampl f 1 cover c case neither featur subsum third heurist lead two prune rule first prune rule extend ie special featur 100 accuraci let f 1 featur contain exampl one class special f 1 may pass frequenc confid test definit featur mine subsum f 1 follow lemma follow definit subsum justifi prune rule respect class c next prune rule concern correl individu item recal exampl repres sequenc set say exampl b occur everi set everi sequenc occur follow lemma state b featur contain set b subsum one gener lemma 2 let subsum precomput set b relat immedi prune featur search contain set b section 3 discuss b relat aris show crucial success approach problem defin featur mine task input featuremin algorithm set exampl paramet min freq maxw max l output nonredund set frequent distinct featur width maxw length max l formal featur mine given exampl paramet min freq maxw max l return featur set f everi featur f everi class c significantli greater jd c jjdj f contain f contain featur subsum f respect class c j data set use chisquar test determin signific 22 effici mine featur present featuremin algorithm leverag exist data mine techniqu effici mine featur set train exampl sequenc mine algorithm design discov highli frequent confid pattern sequenti data set well suit task featuremin base recent propos spade algorithm 5 fast discoveri sequenti pattern spade scalabl diskbas algorithm handl million exampl sequenc thousand item consequ featuremin share properti well construct featuremin adapt spade algorithm search databas label exampl featuremin mine pattern predict class databas simultan oppos previou approach first mine million pattern appli prune postprocess step featuremin integr prune techniqu mine algorithm enabl search larg space previou method would fail featuremin use observ subsequ relat defin partial order sequenc say gener specif relat monoton special relat respect frequenc fr ie frequent sequenc subsequ also frequent algorithm systemat search sequenc lattic span subsequ relat gener specif sequenc depthfirst manner figur 2 show frequent sequenc exampl databas eid suffixjoin idlist time time time time aa ba bb ac intersect ab bb intersect b figur 2 frequent sequenc lattic frequenc comput frequenc comput featuremin use vertic databas layout associ item x sequenc lattic idlist denot lx list exampl id eid event time time pair contain item figur 2 show idlist item b given sequenc idlist determin support ksequenc simpli intersect idlist two k 1 length subsequ check cardin result idlist tell us whether new sequenc frequent two kind intersect tempor equal exampl figur 2 show idlist b obtain perform tempor intersect idlist b ie lb done look within eid occur b list occurr hand idlist obtain equal intersect ie lab b check see two subsequ occur within eid time addit detail found 5 also maintain class index tabl indic class exampl use tabl abl determin frequenc sequenc class time exampl occur eid f1 2 3 4 5 6g howev eid f1 2 3 4g label c 1 f5 6g label c 2 thu frequenc 4 c 1 2 c 2 class frequenc pattern shown frequenc tabl use limit amount mainmemori featuremin break sequenc search space small independ manag chunk process memori accomplish via suffixbas partit ing say two k length sequenc equival class partit share common k 1 length suffix partit fa b cg base length 1 suffix call parent partit parent partit independ sens complet inform gener frequent sequenc share suffix exampl class x element possibl frequent sequenc next step obviou item q lead frequent sequenc suffix x unless qx q x also x parent partit p enumeratefeaturesp element element ruleprun maxw accuracyr 100 return true return fals figur 3 featuremin algorithm featur enumer featuremin process parent partit depthfirst manner shown pseudocod figur 3 input procedur partit along idlist element frequent sequenc gener intersect idlist distinct pair sequenc partit check cardin result idlist min supc sequenc found frequent class c current level form partit next level process repeat frequent sequenc enumer integr constraint featuremin integr prune constraint mine algorithm instead appli prune postprocess step shall show allow featuremin search larg space effici would infeas otherwis ruleprun procedur elimin featur base two prune rule also base length width constraint first prune rule test time extend sequenc new item exist effici onetim method appli b rule idea first comput frequenc 2 length sequenc b remov ab suffix partit b guarante point futur ab appear togeth set sequenc 3 empir evalu describ experi test whether featur produc system improv perform winnow 6 naiv bay 7 classif algorithm winnow multipl weightupd algorithm use variant winnow maintain weight w ij featur f class c j given exampl activ level class c j x 1 featur f true exampl 0 otherwis given exampl winnow output class highest activ level train winnow iter train exampl winnow classif train exampl agre label winnow updat weight featur f true exampl multipli weight correct class constant 1 multipl weight incorrect class constant 1 experi learn often sensit valu use chose valu base common literatur small amount experiment winnow actual use prune irrelev featur exampl run winnow larg featur set say 10000 throw away featur assign weight 0 near 0 howev practic sequenc classif sinc space potenti featur exponenti naivebay classifi featur f class c j naiv bay comput pf jc j fraction train exampl class c j contain f given new exampl featur f 1 f n true naiv bay return class maxim p though naiv bay algorithm appear make unjustifi assumpt featur independ shown perform surprisingli well often well better c45 8 describ domain test approach discuss result experi 301 random pariti problem first describ nonsequenti problem standard classif algorithm perform poorli problem everi featur true exactli half exampl class way solv problem discov combin featur correl differ class intuit construct problem gener n randomlyweight meta featur compos set actual observ featur pariti observ featur determin whether correspond meta featur true fals class label instanc function sum weight meta featur true thu order solv problem featuremin must determin observ featur correspond meta featur import discov meta featur higher weight one lower weight addit increas difficulti problem add irrelev featur bear class instanc formal problem consist n pariti problem size l distract irrelev featur everi boolean featur f ij addit 0 k l irrelev boolean featur k gener instanc randomli assign relev irrelev boolean true fals 5050 probabl exampl instanc nml featur 2 nml distinct instanc possibl instanc equal like also choos n weight w 1 wn uniform distribut 0 1 use assign instanc one two class label follow instanc credit weight w iff ith set featur even pariti score instanc sum weight w number true featur f i1 f im even instanc score greater half sum weight instanc assign class label otherwis assign note 1 featur indic class label pariti problem hard classifi job featuremin essenti figur featur group togeth exampl featur produc featuremin result shown tabl 1 includ f 11 true f 12 true f 41 true f 42 fals use min freq 02 05 302 forest fire plan featuremin algorithm origin motiv task plan monitor stochast domain probabilist planner construct plan high probabl achiev goal task monitor watch plan execut predict advanc whether plan like succeed fail facilit replan order build monitor given plan goal first simul plan repeatedli gener execut trace label execut trace success failur depend whether goal hold final state simul use execut trace input featuremin plan monitor monitor probabilist process simul attract area machin learn essenti unlimit suppli train data although consid possibl execut path number path exponenti length plan process gener arbitrari number new exampl mont carlo simul problem overfit reduc test hypothes fresh data set exampl domain construct simpl forestfir domain base loos phoenix fire simul 9 execut trace avail email contact leshmerlcom use grid represent terrain grid cell contain veget water base exampl terrain shown figur 4 begin bbbb dd dd dd bbdbbd dbbd dbbd dbd bbbbwwwwww dbbd dbbd dd wwwwwwwwwwww wwwwww wwwwww wwwwww wwwwwwwwwwww wwwwww wwwwww wwwwww wwwwww www www www time figur 4 ascii represent sever time slice exampl simul fire world domaina indic fire b indic base b indic bulldoz indic place bulldoz dug fire line w indic water unburn terrain simul fire start random locat iter simul fire spread stochast probabl cell ignit time calcul base cell veget wind direct mani cell neighbor burn time 1 addit bulldoz use contain fire exampl terrain handdesign plan bulldoz dig fire line stop fire bulldoz speed vari simul simul exampl simul look like time0 ignit x3 y7 time0 moveto bd1 x3 y4 time0 moveto bd2 x7 y4 time0 digat bd2 x7 y4 time6 ignit x4 y8 time6 ignit x3 y8 time8 digat bd2 x7 y3 time8 ignit x3 y9 time8 digat bd1 x2 y3 time8 ignit x5 y8 time32 ignit x6 y1 time32 ignit x6 y0 tag plan success none locat base burn final state failur otherwis train plan monitor predict time k whether base ultim burn includ event occur time k train exampl exampl featur produc featuremin domain first sequenc hold bulldoz bd1 move second column time 6 second hold fire ignit anywher second column bulldoz move third row time 8 mani correl use second prune rule describ section 22 aris data set exampl aris one test plan bulldoz never move eighth column fire data 38 boolean featur describ event thu number composit featur search 38 l experi report use min experi winnow winnowtf winnowfm bay bayestf bayesfm pariti pariti pariti spell vs 70 na 94 75 na 78 spell vs 86 na 94 66 na 90 spell vs 83 na 92 79 na 81 spell your vs 77 na 86 77 na 86 tabl 1 classif result averag classif accuraci use differ featur set repres exampl legend tf use featur obtain time featur approach fm use featur produc featurem ine highest accuraci obtain featur produc featuremin algorithm standard deviat shown parenthes follow averag except spell problem one test train set use 303 contextsensit spell correct also test algorithm task correct spell error result valid word substitut 10 test chose two commonli confus word search sentenc 1 millionword brown corpu 11 contain either word remov target word repres word word partofspeech tag brown corpu posit rel target word exampl sentenc polit translat wordand tagcc pos2 wordthen tagrb pos1 wordi tagbez pos1 wordpolit tagnn pos2 exampl featur produc featuremin includ pos3 wordth indic word occur least 3 word target word indic noun occur within three word target word featur reason obviou us significantli correl either train set vs dataset 3802 train exampl 944 test exampl 4692 featurevalu pair vs dataset 2917 train exampl 755 test exampl 5663 featurevalu pair vs dataset 2019 train exampl 494 test exampl 4331 featurevalu pair final your vs dataset 647 train exampl 173 test exampl 1646 featurevalu pair n number featurevalu pair search n maxw experi report use min 2 31 result test pariti fire domain gener 7000 random train exampl mine featur 1000 exampl prune featur pass chisquar signific test correl class featur frequent 2000 exampl train classifi remain 5000 exampl test 1000 addit exampl result tabl 1 2 averag 2550 test spell correct experi evalu select featur featur fire world time 10 64766 553 spell vs 782264 318 tabl 2 mine result number featur consid return featuremin experi cpu second cpu second cpu second featur featur examin featur prune examin examin prune prune prune b prune prune random 320 337 337 1547122 1547122 1547122 fire world 58 hour 560 559 25336097 511215 511215 spell 490 407 410 1126114 999327 971085 tabl 3 impact prune rule run time node visit featuremin without b prune result taken one data set exampl use exampl brown corpu roughli 10004000 exampl per word set split 8020 sentenc train test set mine featur 500 sentenc train classifi entir train set tabl 1 show featur produc featuremin improv classif perform compar use featur set produc featuremin use primit featur ie featur length 1 fire domain also evalu featur set contain featur primit featur time step featur set size 3n describ section 11 winnow naiv bay perform much better featur produc featuremin pariti experi mine featur dramat improv perform classifi experi mine featur improv accuraci classifi signific amount often 20 tabl 2 show number featur evalu number return sever problem largest random pariti problem featuremin evalu 7 million featur select 200 fact 100 million possibl featur 50 boolean featur give rise 100 featurevalu pair search depth 4 sinc reject implicitli prune rule tabl 3 show impact b prune rule describ section 22 mine time result one data set domain slightli higher valu max l maxw experi prune rule improv mine time case made tremend differ fire world prob lem event descriptor often appear togeth without b prune fire world problem essenti unsolv featuremin find 20 million frequent sequenc 4 relat work great deal work done featuresubset select motiv observ classifi perform wors featur set f f 0 f eg 4 algorithm explor exponenti larg space subset given featur set contrast explor exponenti larg set potenti featur evalu featur independ featuresubset approach seem infeas problem consid contain hundr thousand million potenti featur 10 appli winnowbas algorithm contextsensit spell correct use set 10000 40000 featur either use featur prune base classif accuraci individu featur obtain higher accuraci approach howev involv ensembl winnow combin major weight took care choos good paramet specif task goal demonstr featur produc featuremin improv classif perform data mine algorithm often appli task classif 2 build decis list pattern found associ mine nonsequenti version sequenc mine addit previou work explor new method combin associ rule build classifi thrust work leverag augment standard classif algorithm prune rule resembl one use 1 also employ data mine techniqu construct decis list previou work use data mine classif focus combin highli accur rule togeth contrast classif algorithm weigh evid mani featur low accuraci order classifi new exampl work close spirit 12 also construct set sequenti boolean featur use classif algorithm employ heurist search algorithm call fgen increment gener featur cover train exampl base classif perform holdout set train data wherea perform exhaust search depth accept featur meet select crite ria addit use differ featur languag test approach differ classifi conclus shown data mine techniqu use effici select construct featur sequenti domain dna text web usag data plan execut trace domain challeng exponenti number potenti subsequ featur form primit describ item sequenc data number featur larg practic handl today classif algorithm furthermor featur set contain mani irrelev redund featur reduc classif accuraci approach search set possibl featur mine one frequent predict redund adapt scalabl diskbas data mine algorithm abl perform search effici howev one three domain studi search practic due prune rule incorpor search algorithm experi sever domain show featur produc appli select criteria significantli improv classif accuraci particular shown construct problem classifi perform better random guess use origin featur perform near perfect accuraci use featur produc featuremin furthermor shown featur produc featuremin improv perform much 20 simul fireplan domain spell correct data gener work show appli classif algorithm domain obviou small set featur describ exampl larg space combin primit featur probabl contain use featur futur work could involv appli idea classif exampl imag audio signal r learn decis list use homogen rule integr classif associ rule mine mine audit data build intrus detect model greedi attribut select effici enumer frequent sequenc learn quickli irrelev attribut abound new linearthreshold algorithm pattern classif scene analysi beyond independ condit optim simpl bayesian cla sifier predict explain success task durat phoenix planner appli winnow contextsensit spell correct comput analysi presentday american english featur gener sequenc categor tr ctr xiaonan ji jame bailey guozhu dong mine minim distinguish subsequ pattern gap constraint knowledg inform system v11 n3 p259286 april 2007 florenc duchn catherin garbay vincent riall learn recurr behavior heterogen multivari timeseri arifici intellig medicin v39 n1 p2547 januari 2007 sanyih hwang chihp wei wanshiou yang discoveri tempor pattern process instanc comput industri v53 n3 p345364 april 2004 sbastien ferr ross king dichotom search algorithm mine learn domainspecif logic fundamenta informatica v66 n12 p132 januari 2005 moham j zaki charu c aggarw xrule effect algorithm structur classif xml data machin learn v62 n12 p137170 februari 2006 chihm chen increment person web page mine util selforgan hcmac neural network web intellig agent system v2 n1 p2138 januari 2004 chihm chen increment person web page mine util selforgan hcmac neural network web intellig agent system v2 n1 p2138 august 2004