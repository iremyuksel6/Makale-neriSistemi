trust region algorithm timestep select unconstrain optim problem close relat system ordinari differenti equat ode gradient structur work prove result appli area analyz converg properti trust region levenbergmarquardt algorithm optim algorithm may also regard linear implicit euler method adapt timestep gradient ode optim viewpoint algorithm driven directli levenbergmarquardt paramet rather trust region radiu approach discuss exampl r fletcher practic method optim 2nd ed john wiley new york 1987 converg theori develop give rigor error analysi algorithm establish global converg unusu extrem rapid type superlinear converg precis form superlinear converg exhibitedth ratio success displac limit point bound geometr decreas sequenc also show inexpens chang algorithm lead quadrat converg ode viewpoint work contribut theori gradient stabil present algorithm reproduc correct global dynam give rapid local converg stabl steadi state b introduct work involv idea two area numer anal ysi optim numer solut ordinari differenti equat ode begin point connect underli mathemat problem given smooth function f r algorithm unconstrain optim seek find local minim point x fx x neighborhood x follow standard result give necessari condit suffici condit x local minim proof may found exampl 5 6 7 theorem 11 condit rfx posit semidefinit necessari x local minim whilst condit rfx posit definit suffici hand given smooth function f may consid ode system suppos f 11 form fx j gammarf x chain rule solv 11 dt f dt 12 see along solut ode quantiti fxt decreas euclidean norm increas moreov strictli decreas unless henc solv ode larg valu may regard attempt comput local minimum f condit given theorem 11 may interpret necessari condit suffici condit x linearli stabl fix point ode possibl write fx form gammarf x ode 11 said gradient structur see exampl 19 sever author note depart mathemat univers strathclyd glasgow g1 1xh uk support engin physic scienc research council uk grant grk80228 manuscript appear univers strathclyd mathemat research report 3 1998 connect optim gradient ode schropp 18 examin fix timestep rungekutta rk method dynam system viewpoint found condit numer solut gradient ode converg stationari point f schropp also gave numer evid suggest certain problem class ode formul prefer optim analogu book 11 show mani problem express optim term also written ode often gradient structur chu exploit idea order obtain theoret result numer method particular problem see 3 review optim literatur gradient ode connect also mention see exampl discuss unconstrain optim 17 relat work 1 2 look use ode method solv system nonlinear algebra equat studi numer method appli ode gradient form lead concept gradient stabil 14 20 21 gradient structur aris mani applic area provid use framework analysi ode algo rithm contrast classic linear strictli contract test problem gradient system allow multipl equilibria 14 20 posit result prove abil rk method preserv gradient structur henc captur correct long term dynam small fix timestep result requir extra assumpt f impos either onesid lipschitz condit form dissip adapt rk method method vari timestep dynam analyz 21 author consid special class rk formula pair show tradit error control approach forc good behavior suffici small valu error toler independ initi data would regard global converg proof optim litera ture result requir onesid lipschitz condit f similar result prove 12 gener ode method success control local error perunitstep case error toler must chosen way depend initi data work present two main contribut ffl first note close similar trust region levenberg marquadt algorithm optim adapt linear implicit euler method gradient ode analyz optim algorithm establish new result converg properti also add theori gradient stabil ode mild assumpt f show method global converg enjoy rapid form superlinear converg notion rate converg equilibrium wide studi optim appear consid gradient ode context easili seen fix timestep rk formula approach equilibrium gener linear rate term timestep number ffl second use idea gradient analysi construct timestep method gener ode give rapid superlinear local converg stabl fix point present organ follow next section introduc new ton method simpl numer ode method section 3 concern specif trust region algorithm unconstrain optim algorithm essenti one found 6 defin x31 nonrigor discuss converg properti given x32 main converg theorem prove x33 algorithm may also regard timestep process gradient ode algorithm analog result state x4 x5 develop timestep scheme gener ode give superlinear local converg stabl fix point 2 numer method numer method find local minim f begin initi guess x 0 gener sequenc fx k g similarli onestep method ode 11 produc sequenc fx k g x k xt k timelevel ft k g determin dynam mean timestep deltat k steepest descent method optim form ff k scalar may aris exampl line search equival explicit euler method appli correspond gradient ode timestep deltat k j ff k note pass poor perform steepest descent presenc steepsid narrow valley analog poor perform euler method stiff problem inde figur 4j 7 figur 12 10 illustr essenti behavior view two differ perspect newton method optim base local quadrat model note q k ffi quadrat approxim fx k ffi aris taylor seri expans x k r 2 fx k posit definit q k ffi uniqu minim thu arriv newton method follow result concern local quadrat converg newton method may found exampl 5 6 7 theorem 21 suppos f 2 c 2 r 2 f satisfi lipschitz condit neighborhood local minim x x 0 suffici close x posit definit newton method well defin k converg second order implicit euler method appli 11 fx j gammarf x use timestep deltat k produc equat gener nonlinear equat must solv x k1 appli one inter newton method newton method solv nonlinear equat initi guess x method sometim refer linear implicit euler method see exampl 22 note larg valu deltat k ode method look like newton method 23 hand small deltat k correspond small step direct steepest descent 21 henc extrem larg small deltat k ode method behav like wellknown optim method howev show much valu deltat k method 25 identifi trust region process optim connect point goldfarb discuss unconstrain optim 17 relev optim theori develop next section 3 trust region algorithm 31 algorithm seen newton method base idea minim local quadrat model q k ffi 22 step sinc model valid local make sens restrict increment seek increment ffi minim q k ffi subject constraint kffik h k h k paramet reflect much trust prepar place model throughout work use k delta k denot euclidean vector norm correspond induc matrix norm case solut local constrain quadrat model problem character follow lemma one half 6 theorem 521 weaker version prove 8 complet give proof lemma 31 given g 2 r mthetam g 2 r 0 gammag g posit semidefinit b ffi solut min subject kffik k b ffik furthermor g posit definit b ffi uniqu solut 32 proof case g posit semidefinit straightforward show b ffi minim henc ffi b solv problem 32 g posit definit inequ strict ffi 6 b ffi henc solut uniqu note lemma 31 show comput increment b ffi given trust region constraint kffik h k increment may comput approxim use iter techniqu see exampl 6 page 103107 5 page 131143 howev mention 6 reason regard 31 paramet drive algorithmhav chosen valu check gi posit definit may solv linear system 31 posteriori obtain trust region radiu h k k b ffik easili shown g posit definit increas 31 decreas k b ffik remark motiv algorithm 32 use min denot smallest eigenvalu symmetr matrix let ffl 0 small constant given x 0 0 0 gener step trust region algorithm proce follow algorithm 32 comput solv comput comput comput use 33 els set r r k 0 set x els set x algorithm involv function note r k record ratio reduct f x k x reduct predict local quadrat model r k significantli less 1 model overoptimist inform use 33 updat trust region paramet case local quadrat model perform poorli doubl paramet correspond reduc trust region radiu next step perform reason retain valu case good perform halv valu therebi indirectli increas trust region radiu emphas algorithm 32 trust region algorithm sens step ffi k solv local restrict problem min subject kffik kffi k k also remark algorithm essenti describ 6 page 102103 underli idea ad multipl ident matrix ensur posit definit first appli case f sumofsquar form lead levenbergmarquadt algorithm goldfeld et al 8 extend approach gener object function gave theoret justif theorem 511 512 6 provid gener converg theori wide class trust region method howev result appli immedi algorithm 32 sinc algorithm directli control radiu h k kffi k k rather control indirectli via adapt k fact see behavior establish theorem 512 6 local quadrat converg hold algorithm 32 awar exist converg analysi appli directli algorithm 32 except gener result form encapsul dennismor character theorem superlinear converg 4 5 6 strongli consist approxim hessian theori given 16 refer discuss remark follow theorem 34 32 motiv converg analysi proof x33 appendix rather technic henc help orient reader give heurist discuss key point theorem 33 establish global converg proof use argument standard optim literatur essenti global converg follow fact local quadrat model inaccur algorithm choos direct close steepest descent perhap interest rate local converg suppos x k posit definit suppos k b k r k 34 henc follow constant c 1 note also g k g gamma1 bound larg k given larg k let ffi newt k denot correct would aris newton method appli x k newt expand 36 use 37 newt let k x henc 38 newt use 35 find newt constant c 2 sinc x newt k newton step x k theorem 21 newt constant c 3 triangl inequ give newt newt insert 39 310 arriv key inequ constant c 4 first term righthand side 311 distinguish algorithm newton method domin rate converg proceed conveni consid shift sequenc let b e k e kn fix n determin 311 k choos n 2 n c 4 neglect obe 2 lead addit ignor obe 2 313 also assum equal hold get equal 314 0 0 see 315 error sequenc quadrat converg howev 316 correspond rapid form superlinear converg although analysi use sever simplifi assumpt main conclus made rigor show next subsect type superlinear converg establish like good quadrat converg practic matter discuss proof theorem 34 33 converg analysi trust region algorithm follow theorem show algorithm 32 satisfi global converg result structur proof similar 6 theorem 511 theorem 33 suppos algorithm 32 produc infinit sequenc x k 2 b ae r g k 6 0 k b bound f 2 c 2 b accumul point x 1 satisfi necessari condit local minim theorem 11 proof sequenc b must converg subsequ henc collect indic converg subsequ conveni distinguish two case sup case form v r 33 must infinit subsequ whose indic form set b 4 also use bounded g k g k henc suppos gradient limit exist descent direct normal ksk 1 sinc ffi k solv local restrict subproblem 34 q k kffi k ks ks also taylor expans fx conclud 318 320 321 r contradict r k 1 henc suppos g 1 gx 1 posit semidefinit direct v pick k b k sinc solv local restrict subproblem 34 henc follow 318 321 323 r contradict 4 henc g 1 posit semidefinit case ii form v r 33 must infinit subsequ whose indic form set henc gmax sup x2b give henc remov earlier indic necessari h k kffi k k min deltaf r k 1 4 follow deltaq k 0 let kffik h set x henc feasibl subproblem solv ffi k let follow 325 q k ffi f also minim q 1 ffi kffik h sinc constraint inact necessari condit theorem 11 must satisfi henc g 1 6 0 contradict case ii suppos g 1 posit semidefinit argument give 322323 may appli conclud r follow 33 k 0 sinc min must g 1 posit semidefinit give requir contradict note mention 6 sinc algorithm comput nonincreas sequenc f k bound region b requir theorem exist level set bound theorem 33 assum g k 6 0 k g b algorithm essenti termin give x howev case conclud r 2 fx k posit semidefinit next theorem quantifi local converg rate algorithm 32 first part proof base 6 theorem 512 theorem 34 accumul point x 1 theorem 33 also satisfi suffici condit local minim theorem 11 main sequenc 1 displac error e k constant c e k 0 k e constant e c ratio e k1 e 2 k unbound proof first show case 317 proof theorem 33 rule suppos case aris r k 1 b posit definit matrix g k also posit definit larg k b case newton correct ffi newt newt gammag k well defin give global minimum local quadrat model q k defin ff ffkffi newt note sinc ffi k solv local restrict subproblem 34 ff 1 newt newt newt newt newt henc use f newt newt min 0 lower bound smallest eigenvalu g k larg k b follow may conclud 321 r k 1 henc case aris case ii k 1 k 2 sinc lower bound smallest eigenvalu g k larg k b follow 321 k 1 must establish k 0 know correct use algorithm look like newton correct ffi newt k satisfi g k ffi newt gammag k let x newt newt k also let k x k 1 triangl inequ quadrat converg properti newton method given theorem 21 impli x k suffici close x 1 constant 1 expand term 331 find newt k find use 332 333 331 give larg k 2 e k1 2 constant repeat argument gener inequ 329 330 show neighborhood n around x 1 x r k 34 2 henc 334 k 2 x k 2 n main sequnc lie n k k main sequenc x larg k henc 334 may extend bound 3 4 constant lemma a1 give 326 obtain lower bound e k1 use triangl inequ form 332 333 5 constant 5 0 6 lemma a1 give requir result list number remark theorem 34 1 theorem show algorithm 32 achiev quadrat local converg rate caus fact k approach zero quickli enough reflect first term righthand side 335 straightforward adapt proof show increas rate k 0 possibl make second term righthand side 335 signific quadrat converg recov exampl occur alter strategi chang k otherwis howev explain item 4 would expect chang improv perform practic quadrat converg also discuss item 5 2 power k 2 3 appear 326 327 chosen partli basi simplicityit clear proof lemma a1 theorem 34 replac ak 2 12 cours caus constant c chang 3 also clear proof result independ precis numer valu appear algorithm valu 14 34 33 replac ff fi respect factor 2 33 replac factor greater uniti factor 12 33 replac 1k k 1 statement theorem remain true power 2 replac power k chang mention cours alter constant c e c b c 4 theorem 34 show e k1 e k 0 henc converg rate superlinear howev geometr decreas upper lower bound e k1 e k 328 give us much inform asymptot whilst newton method give twice mani bit accuraci per step bound 328 correspond k bit accuraci kth step case asymptot regim e k small enough make converg rate observ small round error signific like consist small number step 5 sever author found condit suffici necessari suffici superlinear converg algorithm optim rootfind comprehens result form dennismor character theorem 4 5 theorem 824 6 theorem 623 also section 112 16 analyz class rootfind algorithm employ consist approxim hessian approach may use establish superlinear converg algorithm 32 howev refer cover gener class algorithm deriv sharp upper lower bound rate superlinear converg type given theorem 34 terminolog 16 x112 algorithm 32 use strongli consist approxim hessian superlinear converg impli k 0 also follow 16 result 1127 quadrat converg aris ensur k ckg k k converg rorder least 1 52 occur k ckx constant c 4 timestep gradient system identifi trust region paramet k invers timestep deltat k linear implicit euler method 25 ident updat formula algorithm 32 henc algorithm 32 regard adapt linear implicit euler method gradient ode converg analysi x3 appli complet rewrit algorithm 32 timestep algorithm given deltat 0 0 x 0 x init gener step algorithm gradient system 11 fx j gammarf x proce follow algorithm 41 comput solv comput comput comput use 41 els set r r k 0 set x els set x appropri analogu 33 function deltat 1 r 3 follow result restat theorem 33 34 context theorem 42 suppos algorithm 41 11 fx j gammarf x produc infinit sequenc x bound f 2 c 2 b accumul point x 1 satisfi necessari condit local minim theorem 11 accumul point x 1 also satisfi suffici condit local minim theorem 11 main sequenc 1 displac error e k constant c e k 0 k e constant e c ratio e k1 e 2 k unbound addit remark end x3 follow point note 1 algorithm 41 requir check posit definit symmetr unusu requir timestep algorithm howev point inexpens numer stabl test perform cours choleski factor 13 page 225 test min omit algorithm 41 local converg rate unaffect global converg proof break 2 rule chang timestep differ spirit usual local error control philosophi ode 9 10 expect sinc aim reach equilibrium quickli possibl odd aim follow particular trajectori accur time timestep control polici algorithm 41 base measur close linear ode idea gener next section also note local error control algorithm typic involv usersuppli toler paramet understand smaller choic toler produc accur solut algorithm 41 hand involv fix paramet 3 12 shown certain assumpt use local error control gradient ode forc numer solut close equilibrium typic solut remain within equilibrium point toler paramet suggest local error control may form altern posit definit test mean ensur global converg driven solut close equilibrium local error control close linear test could use give superlinear converg 5 timestep gener stabl steadi state motiv x4 develop algorithm give rapid local converg stabl equilibrium gener ode let f 0 denot jacobian f defin f k fx k k symmetr gener ratio l k indic close f behav linearli region contain x k x k1 given deltat 0 0 x 0 x init gener step algorithm 11 proce follow algorithm 51 comput solv comput use 51 deltat els arbitrari sinc concern local converg properti action taken affect analysi theorem bfl z denot open ball radiu fl 0 z flg theorem 52 suppos fx neighborhood x f 0 strictli neg real part given algorithm 51 fl 0 x 0 2 displac error e k constant c e k 0 k e constant e c ratio e k1 e 2 k unbound proof exist b fl 0 f 0 x nonsingular x 2 let 1 upper bound kf 51 l k follow 55 reduc b fl necessari jl f k small e k exist deltat 0 deltat continu reduc b fl necessari deltat henc larg deltat contract 56 show x 0 suffici close x deltat k increas beyond deltat x k remain bbfl x let deltatdeltat deltat 56 x k 2 bbfl x let b k 2 b k deltat 0 deltat 58 may choos suffici small 56 57 sinc deltat k deltat k b k henc e k 0 k 1 deltat deltat 0 k f deltat k f sinc f 0 k f bound 56 give k e k1 5 constant complet result straightforward show fix timestep rk linear multistep method produc linear rate converg equilibrium gener theorem 52 see algorithm 51 provid systemat mean increas timestep order achiev rapid form superlinear converg mani applic particularli area comput fluid dynam ic common solv discret steadi partial differenti equat introduc artifici time deriv drive solut equilibrium see exampl 22 clear proof theorem 52 suffici larg deltat 0 algorithm permit local converg unstabl fix point regard consequ fact implicit euler method overst sens absolut stabil region contain infinit strip fz righthalf complex plane see exampl 15 page 229 anoth explan newton method optim f ident newton method algebra equat appli see exampl 5 page 100 henc unless measur taken reason stabl fix point prefer algorithm 41 gradient ode check min help forc numer solut stabl fix point like tradit ode error control would also direct solut away unstabl fix point henc idea combin optim ode idea form attract area futur work acknowledg work benefit convers number optim timestepp notabl roger fletcher david griffith appendix converg rate lemma lemma a1 let k k constant c e k 0 k addit r k k e ratio e k1 e 2 k unbound proof choos first prove result restrict circumst gener full result assum 3 induct hypothesi note a7 hold 3 a8 true use a1 use a6 a7 therefor induct a8 true k a7 hold consid shift sequenc b e k e kn fix n possibl choos n 3 a9 a10 result a8 hold shift sequenc k translat result origin sequenc find relabel c c2 n 2 n let b n henc clearli increas c necessari result also hold finit sequenc n henc a2 prove inequ a3 follow divid e k a1 use a2 a2 suffici larg k 2 k e k r2 r c clearli reduc c necessari result must hold k reduc necessari 1 a12 let e e e inequ a12 a13 give a5 requir final use a2 a5 find e r fast local converg singl multistep method nonlinear equat solut nonlinear system equat astabl integr tech niqu list matrix flow applic practic method optim practic optim maximis quadrat hillclimb solv ordinari differenti equat solv ordinari differenti equat ii optim dynam system analysi dynam local error control via piecewis continu residu accuraci stabil numer algorithm numer method ordinari differenti system iter solut nonlinear equat sever variabl nonlinear optim use dynam system method solv minim problem nonlinear dynam chao model problem numer stabil theori initi valu problem essenti stabil local error control dynam system global asymptot behaviour iter implicit scheme tr