synerget effect compil architectur manual optim perform cfd multiprocessor paper discuss comprehens perform profil improv benchmark comput fluid dynam code one grand challeng applic three popular multiprocessor process analyz perform consid languag compil architectur algorithm chang quantifi increment contribut bottomlin perform demonstr parallel alon result signific gain granular parallel thread effect parallel data local taken account unlik benchmark studi often focu perform effect parallel compil specif loop kernel use entir cfd code measur global effect compil parallel architectur probe perform bottleneck case deriv solut elimin neutral perform inhibit factor major conclus work overal perform extrem sensit synerget effect compil optim algorithm code tune architectur idiosyncrasi b introduct despit continu quest achiev high perform complet scientif applic obtain fraction expect speedup modern multiprocessor hand prolifer parallel architectur throughout spectrum comput system indisput would argu signific parallel even fewer would suggest parallel machin deliv perform user come expect paper mean grand challeng applic show compil architectur limi tation algorithm characterist restrict perform sever amdahl law suggest even case parallel may abund result indic synerget approach simultan address limit result signific perform payback work focus comprehens multilevel analysi complet commerci scientif applic comput fluid dynam cfd code base simpl semiimplicit method pressurelink equat 8 paper report perform bottleneck hardwar architectur compil oper system import manual optim code tune hand optim use work improv perform well isol hardwar bottleneck point possibl architectur softwar improv allevi perform limit multiprocessor machin experi use three commerci multiprocessor sgi challeng alliant fx2800 alliant fx80 use two commerci two experiment parallel compil result suggest user cfd applic expert code optim andor comput architectur expect see littl perform improv run code multiprocessor true even presenc power automat parallel compil tool effect expert intervent even though result singl commerci applic gener across spectrum scientif applic size type code make cfd program repres converg time iteration24solv continu equat solv nseqz compon solv nseqi compon solv nseqx compon boundari condit boundari condit boundari condit boundari condit set time input data output result coefv coefv coefv corect coefp solv system set coeffici system set coeffici system set coeffici system set coeffici system solv system solv system solv system add p p6 figur 1 algorithm cfd applic simpl linear system solver pde solver core major numer applic mani perform evalu benchmark studi employ select kernel complet applic may amen automat parallel parallel execut resist approach work consid perform entir applic profil perform compon cfd code weight contribut overal speedup result hand optim target compil code tune avoid architectur bottleneck signific improv overal perform find also underscor need predict maximum possibl theoret perform gain given applic upper bound perform could use refer point automat manual parallel come surpris runtim overhead play import role perform serial bottleneck amdahl law 2 cfd code experiment environ inflow1m x z densiti 0001kgm 5 figur 2 model cube divid 40 mesh direct cfd program base simpl method 8 outlin figur 1 algorithm first increment time step step 1 figur 1 iter solv navierstok equat comput veloc step 24 continu equat step 5 converg step 2 5 figur 1 consist three modul assembl system linear equat discret ii modifi equat accord boundari condit iii solv system linear equat employ miccg modifi incomplet choleski conjug gradient 5 solv continu equat modul solvep ilucr incomplet lu conjug residu 6 solv navierstok equat modul solvev perform evalu use 3dimension space shown figur 2 experi measur entir cfd code except input output data identifi step 0 6 figur 1 perform result code measur compar three multiprocessor system alliant fx2800 alliant fx80 sgi challeng alliant fx80 8processor mimd system processor vector unit processor share 4quadrant cach 2 alliant fx2800 next gener mimd machin alliant 20processor machin use intel i860 processor final sgi system use experi sgi challeng configur 12 8 processor machin use measur specifi explicitli experiment section execut time paper measur dedic mode three machin measur repeat sever time averag taken case standard deviat equival 1 experi repeat thu measur report standard deviat almost zero serial parallel version cfd code use measur machin use term serial parallel refer serial parallel execut time respect serial parallel version cfd compil use two experiment parallel compil manufacturersuppli parallel machin explain serial serial version cfd code use measur serial execut time compil use nativ nonparallel compil optim option turn parallel case parallel execut time comput run parallel version cfd obtain follow origin code compil system nativ parallel compil alliant use alliant compil automat parallelizationvector option 1 sgi challeng use sgi parallel fortran acceler pfa 10 parafrase2 polari origin code compil experiment sourcetosourc parallel compil parafrase2 7 polari 9 parallel sourc output two parallel compil backend fortran compil machin sgi alliant backend compil parallel loop explicitli indic follow section increment effect compil system architectur manual optim limit overal perform discuss 3 effect compil parallel optim section discuss effect automat parallel cfd code moreov consid specif limit compil test identifi sever area potenti improv allt coefv coefp corect normal execut serial parallel ppolari alliant fx280016161616135789 90serial parallel ppolari alliant fx8016161616 serial parallel ppolari figur 3 perform automat parallel execut 8 processor parallel indic execut time run applic use comput nativ compil term function perform four compil test cfd code machin figur 3 show normal execut time cfd code machin use four compil took serial execut time defin normal time nativ parallel system use comput time label parallel figur 3 differ shade bar correspond execut time modul cfd code illustr figur 1 first clear observ none four compil improv perform significantli best case speedup automat parallel cfd 119 dismal perform circumst cours could due serial natur underli algorithm howev shown later case cfd code expos signific amount parallel none parallel compil abl exploit due number reason figur 3 evid four compil perform uniformli poorli hardli signific differ observ closer observ output code reveal parafrase2 polari local variabl els endif b statement f reduct figur 4 code sampl illustr compil bottleneck fact parallel signific number loop howev much expos parallel expens exploit three machin although experiment compil power pfa alliant compil tend extract maxim parallel regardless impact perform result parallel execut small loop result execut time wors serial time clearli point need compiletim determin exploit nonexploit paral lelism exist compil provid even rudimentari support determin qualiti expos parallel group four compil pfa provid capabl comput tradeoff runtim overhead amount parallel although cfd loop parallel experiment compil perform sgi challeng notic wors two alliant due mostli architectur bottleneck sgi challeng whose effect profound alliant examin architectur bottleneck later section order better understand character poor perform compil use cfd code isol largest loop character serial parallel undetermin serial undetermin version examin loop hand determin caus serial partial parallel follow discuss limit compil identifi highyield optim significantli improv perform tabl character parafrase2 polari term import optim give percentag improv serial execut time 1 cfd 8processor sgi challeng time normal serial execut time taken 100 observ signific payoff due local variabl recognit alloc loop follow comparison limit analysi sgi consid two experiment compil sgi pfa local variabl loop present parafrase2 parallel loop localiz variabl one shown figur 4a unless invok scalar expans pass howev scalar expans pass power enough handl mani loop code polari effect identifi local variabl result parallel simpl loop privatar localiz variabl b statement loop parafrase2 much effect parallel loop whose bodi contain statement loop figur 4b polari howev parallel loop sinc larg loop local variabl branch neither parafrase2 polari could parallel loop branch local variabl although experiment compil deal effect either local variabl recognit branch insid loop neither could handl combin local variabl control flow statement insid loop bodi result appli optim manual origin code code involv index express order two miss compil pfa alliant compil even weaker respect depend analysi power depend analysi scheme necessari order improv effect automat parallel previous fals tabl 1 characterist parafrase2 polari bottleneck parafrase2 polari impact local variabl loop weak ye b statement loop ye c index express higher order e distribut strongli connect compon reduct optim 52 depend due higher order index express manual remov loop distribut although parafrase2 effect distribut loop appli loop distribut possibl case result larg number rel small loop even though may desir gener vector code may counter product case parallel loop ideal distribut loop enabl parallel loop figur 4d typic case reason distribut pass use experi handoptim version distribut loop manual help distribut strongli connect compon loop shown figur 4e parallel polari parafrase2 howev two statement bodi loop distribut find distribut loop paralleliz current way determin legal distribut automat compil would abl execut loop symbol order determin legal distribut thu automat parallel loop typic reduct shown figur 4f loop reduct parallel parafrase2 polari parallel back end compil handl reduct reduct oper parallel break loop sever part sum part final calcul total sum 1 1 parallel version code add element togeth differ order sequenti version roundoff error accumul differ two version code thu answer may differ slightli impact optim shown tabl 1 express improv 1 relat optim thu aggreg improv appli optim necessarili equal sum individu improv exampl first row tabl show 30 improv execut time specifi local variabl parallel loop includ loop branch contribut improv shown second row tabl incorpor optim discuss section perform cfd code improv 52 achiev speedup 21 automat parallel prove ineffect case cfd code especi sgi challeng incorpor improv particular transform may result signific payoff implementationimprov transform would necessari achiev improv suggest tabl 1 perhap one least look issu parallel compil use versu useless parallel equival coars fine grain parallel compil need abil quantit analyz section code determin tradeoff payoff cost particular tran format symbol program analysi 3 provid power mean comput symbol size code section howev except parafrase2 compil provid capabl 4 architectur bottleneck compil transform manual incorpor code perform parallel version compar sgi challeng alliant machin impact architectur bottleneck profound sgi multiprocessor shown section 6 alliant mostli due cost enforc cach coher nonexist problem alliant use share cach limit bu bandwidth therefor experi solut architectur bottleneck focus sgi challeng 41 runtim overhead tabl 2 cost schedul synchron oper sgi oper initi subsequ use createus thread 446741 20 barrier entri 103 63 barrier exit 17 7 sec order put follow experiment result perspect first measur overhead associ primit oper bookkeep function sgi challeng cost issu parallel loop iter barrier synchron set thread use parallel loop execut use sgisuppli timer make detail perform measur tabl 2 show cost creat thread cost reus exist thread loop iter assign empti thread cost 20 sec cost creat thread extrem high indic tabl 2 approach 05sec howev cost paid per thread thread recycl subsequ parallel loop nevertheless accumul runtim overhead thread creation thread assign loop iter high detriment perform applic small number loop andor loop small loop bodi barrier synchron overhead measur pair number barrier entri exit former comput time differ complet last first processor includ skew due load balanc latter measur differ time last iter complet execut time loop exit figur 5 show spacetim diagram execut parallel loop 8 iter larg loop bodi figur show startup phase exist thread complet phase processor assign one iter parallel loop top horizont bar indic time execut enter loop time loop complet execut although right part figur 5 show notic unbal processor complet within interv 57 total execut time loop although sgi support gang schedul parallel loop processor start loop simultan observ notic differ among processor start execut differ due l iter number time sec 1000 1010 iter number time sec figur 5 diagram 8 processor cdoacross localj i18 j12000000 program emul fals share cdoacross localj r i18 j12000000 air b elimin local variabl dimens ad8 j12000000 c elimin keep array separ figur share synchron overhead associ exclus access loop index case 8 processor total approxim 10sec spent lock updat loop index 1sec lock oper approxim term total overhead associ processor particip execut parallel loop lower bound 60sec equival approxim 10000 clock cycl therefor parallel execut start pay loop whose bodi contain 10000 instruct 42 fals share fals share occur multipl processor access cach small section memori although memori access may truli independ may treat access share data figur 6a show loop give rise fals share like mani complic loop cfd code fals l timesec iter number time stamp figur 6a proc local time sec b execut time figur 6b c figur 7 perform share fals share enforc cach line level byte word level thu processor write byte cach line entir line invalid modifi byte discuss two techniqu avoid fals share measur effect perform sampl code first solut fals share use local variabl wherev possibl shown figur 6b loop manual rewritten order make explicit use local variabl execut time loop figur 6b vari number processor shown second column figur 7b header local second approach spread alloc share data memori separ address differ cach line size improv illustr code exampl 6c last three column figur 7b show execut time loop figur 6c three differ alloc share array distanc number array element variabl access success loop iter notic worst perform observ d1 correspond maximum amount fals share sinc cach line size sgi challeng 128 byte elimin fals share keep element thread number shown ital display poor perform share array spread wide enough avoid fals share worth note execut time local variabl version better share array version due effect local variabl whose valu written back memori suspect regist effect use local variabl allow support write back memori dimens anmax8 store data local cach c cdoacross localjji sharea 100 j18 110 i1nmax2 execut time loop figur 8 program emul bu content iadd switch paramet iadd0 bu content iadd1 bu content valu thu reduc perform implicitli suggest 10 although avoid fals share either method use local variabl appear effect possibl due opportun extens regist reus none compil test abl handl effect problem fals share 43 bu content clearli local data import cach perform also minim memori access network traffic busbas multiprocessor sgi challeng bu content seriou perform bottleneck modul cfd code perform poorli due combin fals share bu content bu content measur compar perform two almost ident loop kernel figur 8 first version loop need data local cach iadd0 iadd1 loop access data present local cach processor request signific amount data share memori remot cach anticip bu content vari number processor attempt data transfer read local cach read also caches1 proc time msec 16kb read local cach read also cach 1 proc time msec b 4mb figur 9 influenc bu content perform simultan measur perform effect bu content chang size array number processor use execut kernel figur 8 size array nmax taken 4096 1048576 element equival 16kb 4mb respect execut time parallel loop shown figur 9 array size 16kb worst case scenario 30 increas execut time 8 processor cach miss account differ array size 4mb execut time 900 longer compar case cach entir array local cach perform differ attribut cach miss alon fals share play role case sinc data skew appropri share memori order avoid fals share thu bulk slow due bu content although attempt separ perform loss due cach miss due bu content possibl measur event level clock period softwar timer alliant avoid network content due fals share coher gener sinc neither applic perform alliant limit raw bu bandwidth satur larg array access cach simultan differ processor x z b line execut parallel allow execut serial parallel loop execut serial c plane execut parallel figur 10 comput order origin serial code b 3dimension hyperplan method c 2dimension hyperplan project method 5 algorithm chang section discuss extens hand recod cfd code border algorithm chang although current compil technolog insuffici perform type code restructur futur parallel compil could potenti perform restructur comput languag level order improv degre qualiti exploit parallel order improv perform timeconsum modul cfd code chang order calcul perform without violat algorithm depend addit exploit nonloop function parallel comput veloc latter involv chang algorithm simpl among seven modul shown figur 1 3 solvep solvev coefv timeconsum modul coefv extens parallel compil optim discuss section 3 structur calcul solvep solvev similar thu limit discuss solvep similar approach use solvev detail handrestructur code given 4 paper outlin chang highest possibl level comput solvep sweep 3dimension structur shown figur 10a parallel difficult case due depend point comput depend three immedi neighbor x z dimens figur 10b show one alter order comput respect converg time iter set time input data output result solv continu equat solv nseq solv nseq z compon solv nseq compon figur parallel simpl algorithm veloc certain subcomput step 5 distribut step 24 three dimens without chang underli algorithm order shown figur 10b yield maximum amount parallel sinc element within crossdiagon plane comput parallel refer 3dimension hyperplan method howev plane close begin end cube contain element translat parallel loop iter provid littl opportun exploit cach local sensit runtim overhead figur 10c show altern order calcul solvep organ comput across diagon plane adopt optim cfd code refer approach 2dimension hyperplan project method although parallel less case 10b result parallel loop longer bodi sweep across element plane direct arrow thu parallel loop iter perform comput element local vector local data profound effect perform case addit larger granular parallel loop iter contribut amort overhead result restructur base figur 10c outperform one base 10b speedup achiev solvep version figur 10b c 8 processor sgi challeng 17 74 respect final manual chang code target exploit nonloop parallel figur 11 show altern order perform comput within iter algorithm illustr figur 11 code restructur order take advantag simultan comput across x tabl 3 perform improv parallel compon veloc part serial parallel speedup 1000 625 16 24 23 10 coefv coefp corect normal execut serial parallel ppolari mcom mcomalg mall alliant fx2800161616161 serial parallel ppolari mcom mcomalg mall alliant fx80161616161 100 969841serial parallel ppolari mcom mcomalg mall sgi challenge16040471611 figur 12 perform 8 processor parallel refer parallel nativ compil z compon model done structur calcul across dimens shown figur 11 addit highlevel parallel result simultan execut three solver parallel loop level still exploit within compon approach expect yield better perform due significantli higher degre data local tabl 3 show speedup new cfd code nonloop parallel exploit unabl exploit function loop parallel sgi challeng due fact system allow one level parallel nest parallel support pfa compil runtim librari 6 perform analysi figur 12 give comprehens account perform cfd code three multiprocessor set automat manual optim incorpor three group execut time bar one three multiprocessor use experi alliant fx2800 fx80 sgi challeng respect shadeskey right handsid figur 12 show correspond variou shade bar major modul cfd code defin figur 1 case seven perform bar shown follow data left right leftmost bar group correspond normal serial execut time cfd code machin serial optim turn execut time normal respect serial execut time next three bar label parallel p 2 polari correspond parallel execut time code machin code compil manufacturersuppli parallel parafrase2 polari respect ident time shown figur 3 illustr figur 3 automat parallel fail major way worth note compil effect parallel specif loop howev combin bia toward specif transform lack quantit analysi result bottomend improv exampl loop parallel miss cach iter hardli benefit parallel execut bar label mcom correspond parallel execut time code manual compil optim parallel techniqu describ section 3 carri reflect optim restructur techniqu automat integr exist parallel compil notic signific improv manual parallel three machin result speedup 2 3 bar label mcomalg show result execut time compil optim algorithm code chang discuss section 5 incorpor case alliant algorithm chang result yet signific improv correspond addit speedup approxim 3 howev algorithm chang increas parallel eg 3dimension hyperplan method section 5 result littl improv sgi challeng case latter case perform top due lack addit number processor speed figur 13 scalabl cfd code parallel due cach miss satur bu bandwidth interfer coher overhead bu satur challeng becom evid rightmost bar figur 12 bar label mall show parallel execut time cfd code addit automat manual optim algorithm chang code alter elimin interfer architectur bottleneck fals share bu bandwidth fact 2 dimension hyperplan project method outlin section 5 restrict amount parallel promot data local elimin fals share mall bar sgi data figur 12 reflect improv achiev due elimin bottleneck obtain 2dimension hyperplan project major improv came case sgi addit speedup almost three result elimin fals share increas data local reduct bu traffic optim discuss section 4 cfd code achiev total speedup approxim 7 three system figur 13 show speedup cfd benchmark sgi three differ problem size case comput speedup took serial execut time execut time parallel code singl processor optim sequenti code thu speedup report fall conserv side least sgi fx2800 2 figur 13 attest scalabl cfd code problem size 2 sequenti execut time alliant fx80 obtain run parallel version code singl processor without vector vector use parallel run discuss labori timeconsum analysi optim cfd code result total speedup approxim 7 howev result tell us anyth regard maximum potenti parallel maximum perform attain cfd benchmark machin test order determin posit deliv speedup respect ideal use two ap proach first use amdahl law comput maximum speedup measur serial parallel part code actual execut sgi measur execut time cfd sever time differ number processor use least squar approxim estim parallel serial fraction code use estim upper bound perform use amdahl law tabl 4 show maximum attain speedup estim measur sgi challeng three problem size indic speedup 156 correspond problem size use obtain measur report figur 12 deliv speedup approxim half amdahl upper bound maximum speedup believ factor two differ attribut network bandwidth interfer cach miss addit estim maximum speedup use properti underli algorithm handcarri analysi code amdahl law use obtain upper bound howev serial parallel fraction code estim inspect code static analysi approach yield maximum speedup 40 100 3dimension 2dimension hyperplan project method respect problem size fix 40x40x40 factor 6 ideal maximum measur maximum speedup discrep attribut architectur bottleneck thu power parallelizerbackend combin multiprocessor architectur without bottleneck would expect deliv speedup 40100 cfd applic factor almost highli optim cfd version optim version run bottleneckfre architectur infinit number processor tabl 4 scalabl maximum speedup element maximum speedup 7 conclus paper present comprehens perform profil analysi optim tune commerci comput fluid dynam code cfd one import applic run highperform comput one demand term comput resourc find underscor sever limit commerci experiment parallel compil well architectur bottleneck perform implic popular highperform multiprocessor sgi challeng importantli find stress import synerget effect compil algorithm optim overal perform prowess compil individu transform optim littl effect bottomlin perform howev global approach optim consid interdepend among variou optim result signific perform improv experi base perform complet cfd code oppos select kernel although individu compil perform excel specif loop perform entir applic prove dismal true deliv perform perform cfd code sgi challeng strike case mismatch compil optim architectur idiosyncrasi parallel may result far less expect deliv perform attempt custom parallel underli architectur altern order parallel work effect architectur bottleneck elimin taken consider compil final sophist program restructur captur alter order type comput result certain case improv similar parallel code optim r alliant comput system corpor alliant comput system corpor symbol analysi parallel compil parallel cfd code guidelin usag incomplet decomposit solv set linear equat occur practic problem new gener parallel compil mpp numer heat transfer fluid flow silicon graphic inc tr symbol analysi parallel compil