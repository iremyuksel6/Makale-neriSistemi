featur select neural network present neural network base approach identifi salient featur classif feedforward neural network approach involv neural network train augment crossentropi error function augment error function forc neural network keep low deriv transfer function neuron learn classif task approach reduc output sensit input chang featur select base reaction crossvalid data set classif error due remov individu featur demonstr use propos approach one artifici three realworld classif problem compar approach five featur select method bank differ concept algorithm develop outperform method achiev higher classif accuraci problem test b introduct learn system primari sourc inform data numer system like neural network nn data usual repres vector subspac r k whose compon featur may correspond exampl measur perform physic system inform gather observ phenomenon usual featur equal inform may noisi meaningless correl irrelev task featur select aim select subset featur relev given problem often import issu amount data gather process may reduc train may easier better estim obtain use relev featur case small data set sophist process method may use smaller dimension space origin measur space perform may increas non relev inform interfer etc featur select subject intens research statist applic domain like pattern recognit process identif time seri model econometr recent began investig machin learn commun develop method whatev domain featur select remain difficult problem time non monoton problem ie best subset p variabl alway contain best subset q variabl q p also best subset variabl depend model use process data usual two step treat sequenti method variabl select reli heurist perform limit explor whole set variabl combin field nn featur select studi last ten year classic well origin method employ discuss problem featur select specif nn review origin method develop field certainli exhaust sinc literatur domain alreadi import main idea propos describ describ section 2 3 basic ingredi featur select method notat briefli present section 4 statist method use regress classif use baselin techniqu describ section 5 famili method develop specif neural network may easili implement either regress classif task repres method compar differ test problem section 6 basic ingredi featur select method featur select techniqu typic requir follow ingredi featur evalu criterion compar variabl subset use select one subset search procedur explor subspac possibl variabl combin stop criterion model select strategi 211 featur evalu depend task eg predict classif model linear logist neural network sever evalu criteria base either statist ground heurist propos measur import variabl subset classif classic criteria use probabilist distanc entropi measur often replac practic simpl interclass distanc measur regress classic candid predict error measur survey classic statist method may found thomson 1978 regress mclachlan 1992 classif method reli data comput relev variabl take consider model use process data select step may reli hypothesi data distribut parametr method non parametr method method take account simultan model data usual case nn variabl select 212 search gener sinc evalu criteria non monoton comparison featur subset amount combinatori problem 2 k 1 possibl subset k variabl rapidli becom comput unfeas even moder input size branch bound explor narendra fukunaga 1977 allow reduc search monoton criteria howev complex procedur still prohibit case due limit algorithm base upon heurist perform measur evalu suboptim search suboptim search method follow one follow sequenti search techniqu see eg kittler start empti set variabl add variabl alreadi select variabl set forward method start full set variabl elimin variabl select variabl set backward method start empti set altern forward backward step stepwis method plu l take away r algorithm generalis basic stepwis method altern l forward select r backward delet 213 subset select stop criterion let given featur subset evalu criterion search procedur sever method examin subset provid search eg 2 k 1 exhaust search k simpl backward search select relev accord evalu criterion empir distribut evalu measur relat statist known test may perform irrelev hypothesi input variabl classic sequenti select procedur use stop criterion examin variabl sequenti stop soon variabl found irrelev accord statist test classic parametr method distribut characterist eg estim evalu measur varianc easili deriv see section 41 42 non parametr flexibl method like nn distribut difficult obtain confid interv would allow perform signific test might comput via mont carlo simul bootstrap extrem prohibit practic use except particular case eg baxt white 1996 hypothesi test thu seldom use model mani author use instead heurist stop criteria better methodolog whose complex still reason applic comput success variabl subset provid search algorithm estim gener error predict risk obtain subset select variabl give best perform gener error estim may comput use valid set crossvalid algebra method although latter easi obtain non linear model note strategi involv retrain nn subset 3 notat denot k g realiz random variabl pair xy probabl distribut p x th compon x x l l th pattern given data set cardin n follow restrict one hidden layer nn number input output unit denot respect k g transfer function network denot f train perform accord mean squar error criterion mse although restrict consid select method classif regress task 4 model independ featur select introduc method perform select classif regress step sequenti ie take account classif regress model select method nn orient use experiment comparison nn specif select techniqu section 6 first two basic statist techniqu aim respect regress classif method well fit nn sinc hypothesi reli correspond situat nn might use howev sinc nn specif method heurist use baselin comparison third one develop recent gener select techniqu data hypothesi free might use system either regress classif base probabilist depend measur two set variabl 41 featur select linear regress consid linear regress approach describ may trivial extend multipl regress let x 1 x 2 x k real variabl suppos center let us denot current approxim p select variabl x renumb p first select variabl correspond number 1 p residu x assum ident independ distribut let us denot l l 1 forward select choic p th variabl usual base r p 2 partial correl coeffici tabl 1 regressor f p adjust coeffici 1 coeffici repres proport total varianc explain regressor f p p th variabl select one f p maxim coeffici import new variabl usual measur via fisher test thompson 1978 compar model p1 p variabl fsp forward tabl 1 select stop 1 adjust coeffici r often use instead r p fsp forward f1npa fisher statist 1np degre freedom confid level choic stop l 2n backward ssr l 1 tabl 1 choic stop criteria use statist forward backward method note f could also use place r p 2 choic criterion forward p1 variabl alreadi select r p1 2 constant valu 01 maxim f similar maxim r p 2 equat 413 select variabl order r p 2 backward elimin variabl elimin remain p less signific term fisher test ie one smallest valu ssr p1 equival fsp backward tabl 1 select stop backward f1npa 42 featur select classif classif shall select variabl subset allow best separ data variabl select usual perform consid class separ criterion choic criterion associ ftest stop criterion regress forward backward stepwis method may use data separ usual comput interclass distanc measur kittler 1986 frequent discrimin measur wilk lambda wilk 1963 l sv p defin follow w intraclass matrix dispers correspond select variabl set sv p b correspond interclass matrix 2 determin matrix determin covari matrix measur volum occupi data w measur mean volum differ class wb volum whole data set quantiti comput select variabl good discrimin power correspond small valu l sv p differ class repres compact cluster well separ criterion well suit case multinorm distribut equal covari class meaningless eg multimod distribut clearli restrict hypothesi measur statist f defin fg1ngp1a distribut mclachlan 1992 use wilk lambda estim discrimin power variabl stop select forward backward habbema herman 1977 stepwis method comparison section 6 use stepdisc stepwis method base 422 95 confid level 43 mutual inform data consid realiz random process probabilist inform measur may use order comput relev set two quantiti defin x l class j g number class n j number sampl class j j mean class j global mean variabl respect variabl mutual inform measur defin ab b two variabl probabl densiti pa pb mutual inform independ invers differenti transform variabl measur uncertainti reduct b known also known kullbakleibl distanc joint distribut pab margin distribut product papb method describ make use restrict assumpt data therefor gener attract one describ section 41 42 especi hypothesi correspond data process model usual case nn may use either regress discrimin hand non parametr method comput intens main practic difficulti estim joint densiti pab margin densiti pa pb non parametr densiti estim method costli high dimens necessit larg amount data algorithm present use shannon entropi denot h comput mutual inform possibl use entropi measur like quadrat cubic entropi kittler 1986 battiti 1994 propos use mutual inform forward select algorithm call mif mutual inform base featur select pab estim fraser algorithm fraser swinney 1986 recurs partit space use c 2 test data distribut algorithm comput mutual inform two variabl order comput mutual inform x p select variabl set sv p1 belong sv p1 battiti use simplifi assumpt moreov number variabl select fix select algorithm use forward search variabl x p one maximis valu sv p1 set p 1 alreadi select variabl bonnland weigend 1994 use epanechnikov kernel densiti estim hrdle 1990 branchbound bb algorithm search narendra fukunaga 1977 bb warrant optim search criterion use monoton less comput intens exhaust search search algorithm one also consid suboptim float search techniqu propos pudil et al 1994 offer good compromis sequenti method simplic rel comput cost branchbound algorithm comparison section 6 use epanechnikov kernel densiti estim 432 forward search select stop mi increas fall fix threshold 099 5 model depend featur select neural network model depend featur select attempt perform simultan select process data featur select process part train process featur sought optim model select criterion global optim look attract modelindepend select adequaci two step user howev sinc valu choic criterion depend model paramet might necessari train nn differ set variabl select procedur altern variabl select retrain model paramet forbid use sophist search strategi would comput prohibit specif nn also taken consider deriv featur select algorithm nn usual non linear model sinc mani parametr modelindepend techniqu base hypothesi inputoutput variabl depend linear input variabl redund well measur linear correl variabl method clearli ill fit nn search space usual mani local minima relev measur depend minimum nn converg measur averag sever run applic prohibit consid except white 1989 deriv result weight distribut work nn commun might use hypothesi test nn featur select algorithm choic criteria mainli base heurist individu featur evalu function sever propos literatur made attempt classifi accord similar distinguish zero order method use network paramet valu first order method use first deriv network paramet second order method use second deriv network paramet featur evalu criteria allow rank variabl given time valu criterion non inform howev see method work reason well featur select method neural network use mostli backward search although forward method also propos moodi 1994 goutt 1997 sever method use individu evalu featur rank take consider depend correl may problemat select minim relev set variabl use correl simpl depend measur enough sinc nn captur non linear relationship variabl hand measur non linear depend trivial author simpli ignor problem other propos select one variabl time retrain network new select set evalu relev remain variabl allow take account depend network discov among variabl critic difficulti defin sound stop criterion model choic mani method use crude techniqu stop select eg threshold choic criterion valu rank differ subset use estim gener error latter expect error perform futur data defin case rxi euclidean error desir comput output estim comput use valid set crossvalid algebra approxim risk like final predict 1970 sever estim propos statist gustafson hajlmarsson 1995 nn moodi 1991 larsen hansen 1994 literatur comparison section 6 use simpl threshold author gave indic stop criterion valid set approxim risk otherwis 51 zero order method linear regress model partial correl coeffici express simpl function weight although sound non linear model attempt use input weight valu comput variabl relev observ ineffici heurist weight easili interpret model sophist heurist propos yacoub bennani 1997 exploit weight valu network structur multilay perceptron deriv follow criterion h denot respect input hidden output layer better understand measur let us suppos hidden output unit incom weight vector unitari l 1 norm equat written 512 inner term product weight input hidden unit j j output import variabl output sum absolut valu product path nn unit unit import variabl defin sum valu output denomin 511 oper normal factor import use squash function sinc function limit effect weight magnitud note measur depend magnitud input differ variabl similar rang two weight layer differ role mlp reflect 511 exampl output linear normal suppress inner summat 511 use backward search nn retrain variabl delet stop criterion base evolut perform valid set elimin stop soon perform decreas 52 first order method sever method propos evalu relev variabl deriv error output respect variabl evalu criteria easi comput lead similar result deriv measur local chang output wrt given input input fix sinc deriv constant like linear model must averag train set measur fulli meaning input independ sinc measur averag local sensit valu train set repres input space 521 salienc base prune sbp backward method moodi utan 1992 use evalu criterion variat learn error variabl x replac empir mean sinc variabl assum center mse x l l l l l direct measur use variabl comput output larg valu n comput costli linear approxim may use f x l l l l l x variabl elimin increas order featur set nn train estim gener error gener final predict error criterion comput model minimum gener error select chang mse ambigu input correl variabl relev comput method take account possibl correl variabl relev could comput success nn sequenc comput extracost ok 2 comput instead ok present method 522 method use comput output deriv linear model output deriv wrt input constant case non linear nn sever author propos measur sensit network transfer function respect input x comput mean valu output deriv respect x whole train set case multilay perceptron deriv comput progress learn hashem 1992 sinc deriv may take posit neg valu may compens produc averag near zero measur use averag squar absolut deriv tenth measur base deriv propos mani other could defin thu give repres sampl measur sum deriv absolut valu use eg ruck et al l 1 classif priddi et al 1993 remark sinc error decis j x may estim 1 f j x 523 may interpret absolut valu error probabl deriv averag decis output data squar deriv may use instead absolut valu refen et al 1996 exampl propos regress normal sum x f f x l l x x var hold varianc also propos seri relat criteria among normal standard deviat deriv f x f x f x l l l l x weight averag deriv absolut valu weight reflect rel magnitud x fx f x x f l l l x x measur sensit input space repres sampl set sever author propos use subset sampl order increas signific relev measur order obtain robust method nonpatholog train exampl discard regress radial basi function network dorizzi et al 1996 propos use 95 percentil deriv absolut valu f aberr point elimin contribut robust measur note idea could use relev measur propos paper follow line czernichow 1996 propos heurist criterion regress estim set non patholog exampl whose cardin n propos choic criterion f l f l classif rossi 1996 follow proposit made priddi et al 1993 consid pattern near class frontier propos follow relev measur f x f x l frontier l x x x frontier defin set point x l f x e e fix threshold sever author also consid rel contribut partial deriv gradient 529 method use simpl backward search stop criteria author use heurist rule except refen et al 1996 defin statist test relev measur non linear nn necessit estim relev measur distribut costli opinion usual prohibit approach even look attract 523 link method method use simpl relev measur depend upon gradient network output respect input variabl difficult rank differ criteria said wise use reason rule like discard aberr point robust retrain nn discard variabl comput new relev measur nn sequenc order take account depend variabl practic method give similar result shown section 6 summar tabl 2 main characterist relev measur differ method deriv use task cr data use moodi 521 f cr refen 525 f cr dorizzi 527 f cr non patholog data refen 526 f cr czernichow 528 f cr non patholog data refen 524 f ruck rossi c frontier class tabl 2 comput relev variabl differ method use deriv network function c r denot respect classif regress task 53 second order method sever method propos evalu relev variabl comput weight prune criteria set weight input node present three method first one bayesian approach comput weight varianc two use hessian cost function comput cost function depend upon input unit weight 531 automat relev determin ard method propos mackay 1994 framework bayesian learn approach weight consid random variabl regular term take account input includ cost function assum prior probabl distribut group weight th input gaussian input posterior varianc 2 estim help hessian matrix ard success time seri predict learn regular term improv predict perform howev ard realli use featur select method sinc variabl prune train 532 optim cell damag sever neural select method inspir weight prune techniqu latter decis prune weight made accord relev criterion often name weight salienc weight prune salienc low similarli salienc input cell usual defin sum weight salienc fanouti set weight input optim cell damag ocd propos ciba et al 1994a 1996 similar method also propos mao et al 1994 featur select method inspir optim brain damag obd weight prune techniqu develop lecun 1990 obd connect salienc defin order two taylor expans mse variat around local minimum hessian matrix h easili comput use gradient descent may comput intens larg network obd author use diagon approxim hessian comput salienc input variabl defin accordingli ciba et al 1994 propos use 535 choic criterion elimin variabl nn train reach local minimum variabl whose salienc given threshold elimin threshold valu fix cross valid process repeat variabl found threshold method test sever problem gave satisfi result difficulti lie select adequ threshold furthermor sinc sever variabl elimin simultan wherea individu variabl pertin measur use signific set depend variabl may elimin stop gener perform nn sequenc estim via valid set variabl set correspond nn best perform chosen hessian diagon approxim question sever author hassibi stork 1993 exampl propos weight prune algorithm optim brain surgeon ob similar obd use whole hessian comput weight salienc stahlberg riedmil 1997 propos featur select method similar ocd except take account non diagon term hessian method salienc comput use perform measur error variat train set weight estim model select use data set optim pedersen et al 1996 propos two weight prune method gobd gob comput weight salienc accord estim gener error final predict error akaik 1970 similarli obd ob method could also transform featur select method 533 earli cell damag ecd use second order taylor expans obd famili method justifi local minimum reach cost local quadrat minimum hypothesi bare met practic tresp et al 1997 propos two weight prune techniqu famili coin ebd earli brain damag eb earli brain surgeon use heurist justif take account earli stop ad new term salienc comput method extend featur rank call ecd earli cell damag ebd extens ecd salienc input defin algorithm propos slightli differ ocd one variabl elimin time nn retrain delet choos best set variabl use variat select accord estim gener error method estim comput use valid set sinc perform may oscil significantli differ sever subset may perform see eg figur 1 use fisher test compar model perform best model select set network whose perform similar best one choos among network one smallest number input variabl 6 experiment comparison present compar perform differ featur select method compar method difficult task uniqu measur character import input select accuraci also depend search techniqu variabl subset choic criterion case nn differ step reli heurist could exchang one method nn use multilay perceptron one hidden layer 10 neuron comparison provid intend definit rank differ method illustr gener behavior method describ use two synthet classif problem illustr differ difficulti variabl select first one frontier nearli linear depend variabl well pure nois variabl second problem non linear frontier variabl chosen independ correl first problem origin propos breiman et al 1984 three class waveform classif problem 19 noisi depend featur also use variat problem 21 pure nois variabl ad 19 initi variabl 40 input variant train set 300 pattern test set 4300 descript problem provid appendix perform optim bay classifi estim test set 86 correct classif perform comparison appear tabl 3 4 two instanc method p select variabl perf stepdisc 422 14 000110111111111011100 0000000000000000000 bonnland 432 12 000011101111111110000 0000000000000000000 moodi ruck 523 dorizzi 527 czernichow 528 17 010111111111111111100 0000000000000000000 ciba 535 9 000001111110111000000 0000000000000000000 8226 leray 536 11 000001111111111100000 0000000000000000000 tabl 3 perform comparison differ variabl select noisi wave problem noisi problem method elimin pure nois variabl except two method bottom tabl 3 give slightli lower perform select fewer variabl give similar valu around 85 correct stepdisc also give good perform sinc problem data unimod distribut frontier nearli linear non noisi problem perform method order chang two techniqu bottom tabl 4 give slightli better perform method p select variabl perf none 21 111111111111111111111 stepdisc 422 14 001110101111111011100 bonnland 432 8 000001100111101010000 moodi 521 ruck 523 dorizzi czernichow ciba 535 15 001011111111111110100 leray tabl 4 perform comparison differ variabl select method origin wave problem number remain variabl ecd ocd figur 1 perform comparison two variabl select method ocd ecd accord number remain variabl noisi wave problem figur show perform curv two method ocd ecd estim valid set sinc use singl valid set small fluctuat perform form cross valid use order get better estim test strategi propos ecd look also attract case seen problem perform less similar backward elimin slightli rise quickli drop relev variabl removed842060100 none yacoub moodi ciba leray ruck stepdisc bonnland czernichow figur 2 perform comparison differ variabl select method vs percentag select variabl origin wave problem x axi percentag variabl select axi percentag correct classif figur 2 give repartit differ variabl select method origin wave problem accord perform axi percentag select variabl x axi best method best perform lower number variabl problem leray satisfi see figur 2 yacoub delet enough variabl bonnland delet much variabl second problem two class problem 20 dimension space class distribut accord two gaussian respect 1 00 chosen 1 2 problem variabl relev order accord index x 1 useless x i1 relev x method p select variabl perf stepdisc 422 17 10001111111111111111 bonnland 432 5 00010000000000011011 9060 9486 moodi 521 9 01000100011000110111 9294 ruck 9486 dorizzi 527 11 00000000101111111111 czernichow 528 9 00000000001101111111 ciba leray 536 15 01011011101110111111 tabl 5 perform comparison differ variabl select method two gaussian problem uncorrel variables9193954080 none yacoub stepdisc leray ciba dorizzi ruck czernichow moodi bonnland figur 3 perform comparison differ variabl select method vs percentag select variabl two gaussian problem uncorrel variabl x axi percentag variabl select axi percentag correct classif tabl 5 show stepdisc adapt non linear frontier method select x 1 useless problem remark figur 3 bonnland method delet mani variabl wherea yacoub stop criterion rough delet enough variabl experi replac matrix 1 2 block diagon matrix block 5x5 four group five success correl variabl new problem method p select variabl perf 9058 stepdisc 422 11 00001101011010110111 bonnland 432 5 00001001010000100001 ruck 9106 leray 9072 tabl 6 perform comparison differ variabl select method two gaussian problem correl variabl tabl 6 give result repres method problem stepdisc still give model good perform select mani correl variabl bonnland method select 5 variabl give significantli lower result ruck method obtain good perform select correl variabl leray method thank retrain variabl delet find model good perform variabl 7 compar 10 11 ruck stepdisc 7 conclus review variabl select method develop field neural network main difficulti nn non linear system make use explicit parametr hypothesi consequ select method reli heavili heurist three step variabl select relev criterion search procedur nn variabl select use mainli backward search choic final model first discuss main difficulti develop step introduc differ famili method discuss strength weak believ variabl select method must remain comput feasibl use consid techniqu reli comput intens method like eg bootstrap step select instead propos seri rule could use order enhanc sever method describ reason extra comput cost eg retrain nn sequenc comput relev nn allow take account correl variabl simpl estim gener error may use evalu variabl subset simpl test estim allow choos minim variabl set section 533 final perform comparison repres nn select techniqu synthet problem r statist predictor identif use mutual inform select featur supervis neural net learn bootstrap confid interv clinic input variabl effect network train identifi presenc acut myocardi infract select input variabl use mutual inform nonparametr densiti evalu classif regress tree fogelman souli fogelman souli architectur select statist sensit analysi independ coordin strang attractor mutual inform extract relev decay time seri model gustafson hajlmarsson select variabl discrimin analysi fstatist error rate appli nonparametr regress econometr societi monograph n sensit analysi feedforward artifici neural network differenti activ function second order deriv network prune featur select extract gener perform regular neural network model bayesian nonlinear model energi predict competit discrimin analysi statist pattern recognit note generl principl architectur select neural network applic corpor bond rate predict predict risk architectur select neural network statist neural network theori pattern recognit applic branch bound algorithm featur subset select float search method featur select pattern recognit letter attribut suppress multilay perceptron fast network prune featur extract use unitob algorithm select variabl multipl regress learn artifici neural network mathemat statist hv heurist variabl select multilay artifici neural network classifi tr featur select automat classif nongaussian data imag enhanc threshold optim fuzzi compact introduct statist pattern recognit 2nd ed float search method featur select merg backpropag hebbian learn rule robust classif featur select neural network pattern recognit ctr e gasca j snchez r alonso rapid brief commun elimin redund irrelev use new mlpbase featur select method pattern recognit v39 n2 p313315 februari 2006 rajen b bhatt gopal fuzzyrough set approach featur select pattern recognit letter v26 n7 p965975 15 may 2005 bacauskien verika select salient featur classif base neural network committe pattern recognit letter v25 n16 p18791891 decemb 2004 chaoton su longsheng chen tailin chiang neural network base inform granul approach shorten cellular phone test process comput industri v57 n5 p412423 june 2006 franoi f rossi v wertz verleysen resampl method parameterfre robust featur select mutual inform neurocomput v70 n79 p12761288 march 2007 r e abdela gmdhbase featur rank select improv classif medic data journal biomed informat v38 n6 p456468 decemb 2005